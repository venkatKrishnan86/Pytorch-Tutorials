{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "from torchtext.data.metrics import bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    p = np.array([])\n",
    "    for s in text.split(','):\n",
    "        s1 = s.split(' ')\n",
    "        for s2 in s1:\n",
    "            s2 = s2.split('.')\n",
    "            if s2!=['']:\n",
    "                p = np.append(p, s2)\n",
    "    if p[-1]=='':\n",
    "        return list(p[:-1])\n",
    "    else:\n",
    "        return list(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "english = Field(\n",
    "    sequential=True, \n",
    "    use_vocab=True, \n",
    "    tokenize=tokenize, \n",
    "    lower=True,\n",
    "    init_token='<sos>',\n",
    "    eos_token='<eos>'\n",
    ")\n",
    "german = Field(\n",
    "    sequential=True, \n",
    "    use_vocab=True, \n",
    "    tokenize=tokenize, \n",
    "    lower=True,\n",
    "    init_token='<sos>',\n",
    "    eos_token='<eos>'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = Multi30k.splits(\n",
    "    exts = ('.de', '.en'), # (Source language, Target Language)\n",
    "    fields = (german, english) # And then map the source and target to the respective variables\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a vocabulary\n",
    "english.build_vocab(train_data, max_size = 10000, min_freq = 2) # We won't add words used ONLY once, should occur atleast twice\n",
    "german.build_vocab(train_data, max_size = 10000, min_freq = 2) # We won't add words used ONLY once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, val_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, val_data, test_data),\n",
    "    batch_sizes=(batch_size, batch_size, batch_size),\n",
    "    sort_within_batch = True, # The batches are formed based on the length of the sentences\n",
    "    sort_key = lambda x: len(x.src), # This would prioritise the similar length sentences in the batch\n",
    "    device = device\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0],\n",
       "         [1],\n",
       "         [2],\n",
       "         [3],\n",
       "         [4]]),\n",
       " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "         [3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
       "         [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To understand some functions used in masking\n",
    "ss1 = (\n",
    "    torch.arange(0, 5).unsqueeze(1) # (5, 1) --> Added one dimension in index 1\n",
    ")\n",
    "ss2 = (\n",
    "    torch.arange(0, 5).unsqueeze(1).expand(5, 10)\n",
    ") # For 10 sentences\n",
    "ss1, ss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        source_vocab_size,\n",
    "        target_vocab_size,\n",
    "        src_pad_idx,\n",
    "        trg_pad_idx,\n",
    "        num_heads,\n",
    "        num_encoder_layers,\n",
    "        num_decoder_layers,\n",
    "        embedding_size,\n",
    "        forward_expansion,\n",
    "        dropout_prob,\n",
    "        max_length,\n",
    "        device\n",
    "        ) -> None:\n",
    "        super(Transformer, self).__init__()\n",
    "        self.src_word_embedding = nn.Embedding(source_vocab_size, embedding_size, device=device)\n",
    "        self.src_position_embedding = nn.Embedding(max_length, embedding_size, device=device)\n",
    "        self.trg_word_embedding = nn.Embedding(target_vocab_size, embedding_size, device=device)\n",
    "        self.trg_position_embedding = nn.Embedding(max_length, embedding_size, device=device)\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.transformer = nn.Transformer(\n",
    "            embedding_size,\n",
    "            num_heads,\n",
    "            num_encoder_layers,\n",
    "            num_decoder_layers,\n",
    "            dim_feedforward = forward_expansion*embedding_size,\n",
    "            dropout = dropout_prob,\n",
    "            device = self.device\n",
    "        )\n",
    "\n",
    "        self.fc_out = nn.Linear(embedding_size, target_vocab_size, device = device)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "\n",
    "    def make_src_mask(self, src):\n",
    "        # src shape: (src_len, batch_size)\n",
    "        # But Pytorch takes (batch_size, src_len)\n",
    "        src_mask = (src.transpose(0,1) == self.src_pad_idx).to(self.device)\n",
    "        # src_mask shape: (batch_size, src_len)\n",
    "        return src_mask\n",
    "    \n",
    "    def forward(self, src, tgt):\n",
    "        src_seq_len, batch_size = src.shape\n",
    "        trg_seq_len, batch_size = tgt.shape\n",
    "\n",
    "        # Create positions for Position Embeddings\n",
    "        src_positions = (\n",
    "            torch.arange(0, src_seq_len)\n",
    "            .unsqueeze(1)\n",
    "            .expand(src_seq_len, batch_size)\n",
    "            .to(self.device)\n",
    "        )\n",
    "        # All positions of words would be labelled as 0, 1, 2,...src_length\n",
    "        # When inputted into a trainable position embedding, the value would represent a certain vector for that position, which will be added to the word_emebdding\n",
    "\n",
    "        trg_positions = (\n",
    "            torch.arange(0, trg_seq_len)\n",
    "            .unsqueeze(1)\n",
    "            .expand(trg_seq_len, batch_size)\n",
    "            .to(self.device)\n",
    "        )\n",
    "\n",
    "        embed_src = self.dropout(\n",
    "            (self.src_word_embedding(src) + self.src_position_embedding(src_positions)) \n",
    "        ) # output: (sequence_length, batch_size, embedding_dimension)\n",
    "\n",
    "        embed_trg = self.dropout(\n",
    "            (self.trg_word_embedding(tgt) + self.trg_position_embedding(trg_positions))\n",
    "        )\n",
    "\n",
    "        src_padding_mask = self.make_src_mask(src) # (batch_size, sequence_length)\n",
    "        trg_mask = self.transformer.generate_square_subsequent_mask(trg_seq_len).to(self.device)\n",
    "\n",
    "        out = self.transformer(\n",
    "            embed_src,\n",
    "            embed_trg,\n",
    "            src_key_padding_mask = src_padding_mask,\n",
    "            tgt_mask = trg_mask\n",
    "        )\n",
    "\n",
    "        out = self.fc_out(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the training phase\n",
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = False\n",
    "save_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "learning_rate = 3e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'german' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/19/ltb_35_s78j73zmsywmqs_wc0000gn/T/ipykernel_62187/1042306415.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msrc_vocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgerman\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrg_vocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menglish\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0membedding_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnum_heads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum_encoder_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'german' is not defined"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(german.vocab)\n",
    "trg_vocab_size = len(english.vocab)\n",
    "embedding_size = 512\n",
    "num_heads = 8\n",
    "num_encoder_layers = 3\n",
    "num_decoder_layers = 3\n",
    "dropout_prob = 0.1\n",
    "max_length = 100 # For max length of positional embedding\n",
    "forward_expansion = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_pad_idx = german.vocab.stoi[\"<pad>\"]\n",
    "trg_pad_idx = english.vocab.stoi[\"<pad>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"runs/Transformer_Loss_Plot/\")\n",
    "step = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    src_vocab_size,\n",
    "    trg_vocab_size,\n",
    "    src_pad_idx,\n",
    "    trg_pad_idx,\n",
    "    num_heads,\n",
    "    num_encoder_layers,\n",
    "    num_decoder_layers,\n",
    "    embedding_size,\n",
    "    forward_expansion,\n",
    "    dropout_prob,\n",
    "    max_length,\n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(transformer.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    factor=0.1, \n",
    "    patience=10, \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=trg_pad_idx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename=\"models_state_dict/Seq2Seq_Transformer_checkpoint.pth.tar\"):\n",
    "    print(\"Saving Checkpoint...\")\n",
    "    torch.save(state, filename)\n",
    "    print(\"Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint, model, optimizer):\n",
    "    print(\"Loading checkpoint...\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "    print(\"Successfully loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(model, sentence, source, target, device, max_length=50):\n",
    "    # Load source tokenizer\n",
    "    if type(sentence) == str:\n",
    "        tokens = [token.lower() for token in tokenize(sentence)]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    # Add <SOS> and <EOS> in beginning and end respectively\n",
    "    tokens.insert(0, source.init_token)\n",
    "    tokens.append(source.eos_token)\n",
    "\n",
    "    # Go through each source token and convert to an index\n",
    "    text_to_indices = [source.vocab.stoi[token] for token in tokens]\n",
    "\n",
    "    # Convert to Tensor\n",
    "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
    "\n",
    "    outputs = [target.vocab.stoi[\"<sos>\"]]\n",
    "    for i in range(max_length):\n",
    "        trg_tensor = torch.LongTensor(outputs).unsqueeze(1).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(sentence_tensor, trg_tensor)\n",
    "\n",
    "        best_guess = output.argmax(2)[-1, :].item()\n",
    "        outputs.append(best_guess)\n",
    "\n",
    "        if best_guess == target.vocab.stoi[\"<eos>\"]:\n",
    "            break\n",
    "\n",
    "    translated_sentence = [target.vocab.itos[idx] for idx in outputs]\n",
    "    # remove start token\n",
    "    return translated_sentence[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu(data, model, source, target, device):\n",
    "    targets = []\n",
    "    outputs = []\n",
    "\n",
    "    for example in data:\n",
    "        src = vars(example)[\"src\"]\n",
    "        trg = vars(example)[\"trg\"]\n",
    "\n",
    "        prediction = translate_sentence(model, src, german, english, device)\n",
    "        prediction = prediction[:-1] # Removing <eos> token\n",
    "\n",
    "        targets.append([trg])\n",
    "        outputs.append(prediction)\n",
    "    \n",
    "    return bleu_score(outputs, targets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trainable parameters = 54352204\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    total_params = sum(p.numel() for p in transformer.parameters() if p.requires_grad) # Number of Parameters\n",
    "    print(f'Total number of trainable parameters = {total_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_model:\n",
    "    load_checkpoint(torch.load(\"models_state_dict/Seq2Seq_Transformer_checkpoint.pth.tar\"), transformer, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"ein boot mit mehreren männern darauf wird von einem großen pferdegespann ans ufer gezogen.\"\n",
    "max1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7805\n",
      "5964\n"
     ]
    }
   ],
   "source": [
    "print(src_vocab_size)\n",
    "print(trg_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Saving Checkpoint...\n",
      "Saved!\n",
      "Translated Example Sentence: \n",
      " sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks tuba sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks sparks \n",
      "Time taken: 3m 45s\n",
      "Epoch 2/50\n",
      "Saving Checkpoint...\n",
      "Saved!\n",
      "Translated Example Sentence: \n",
      " a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    if save_model:\n",
    "        checkpoint = {\n",
    "            \"state_dict\": transformer.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict()\n",
    "        }\n",
    "        save_checkpoint(checkpoint)\n",
    "    \n",
    "    transformer.eval() # Will turn off dropout\n",
    "    translated_sentence = translate_sentence(transformer, sentence, german, english, device, max_length=100)\n",
    "    translated_sentence_final = ''\n",
    "    for i, word in enumerate(translated_sentence[:-1]):\n",
    "        if i != len(translated_sentence)-1:\n",
    "            translated_sentence_final+=word+' '\n",
    "        else:\n",
    "            translated_sentence_final+=word+'.'\n",
    "    print(f\"Translated Example Sentence: \\n {translated_sentence_final}\")\n",
    "\n",
    "    transformer.train()\n",
    "\n",
    "    tic = time.time()\n",
    "    for batch_idx, batch in enumerate(train_iterator):\n",
    "        input_data = batch.src.to(device) # (sequence_length, batch_size)\n",
    "        target = batch.trg.to(device) # (sequence_length, batch_size)\n",
    "\n",
    "        # Forward Propagation\n",
    "        output = transformer(input_data, target[:-1, :]) # The output must be shifted by ONE step right - so the <eos> token will be removed\n",
    "        # output shape: (sequence_length, batch_size, target_vocab_size)\n",
    "        # Output is of shape (trg_len, batch_size, output_dim) but Cross Entropy Loss\n",
    "        # doesn't take input in that form. For example if we have MNIST we want to have\n",
    "        # output to be: (N, 10) and targets just (N). Here we can view it in a similar\n",
    "        # way that we have output_words * batch_size that we want to send in into\n",
    "        # our cost function, so we need to do some reshaping.\n",
    "\n",
    "        output = output.reshape(-1, output.shape[2])\n",
    "        target = target[1:].reshape(-1) # Now we will remove the first word\n",
    "        # So the input is the FIRST word to the SECOND LAST word\n",
    "        # The output we want to compare it with is SECOND word to LAST word\n",
    "        # We need to combine the batch with the trg_length to put into the loss function\n",
    "        loss = criterion(output, target)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(transformer.parameters(), max_norm = 1)\n",
    "        optimizer.step()\n",
    "\n",
    "        writer.add_scalar(\"Training Loss\", loss, global_step = step)\n",
    "        step+=1\n",
    "    \n",
    "    mean_loss = sum(losses) / len(losses)\n",
    "    # scheduler.step(mean_loss)\n",
    "    \n",
    "    print(f\"Time taken: {(time.time() - tic)//60:.0f}m {(time.time() - tic)%60:.0f}s\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_model:\n",
    "    load_checkpoint(torch.load(\"models_state_dict/Seq2Seq_Attention_checkpoint.pth.tar\"), transformer, optimizer)\n",
    "transformer.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = bleu(test_data, transformer, german, english, device)\n",
    "print(f\"Bleu Score for test data = {score*100:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Es gibt so viele verschiedene Möglichkeiten für Eiscreme\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected translation**: *There is so much variety in the options for icecream available*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    translated_sentence = translate_sentence(transformer, sentence, german, english, device, max_length=100)\n",
    "    translated_sentence_final = ''\n",
    "    for i, word in enumerate(translated_sentence[:-1]):\n",
    "        if i != len(translated_sentence)-1:\n",
    "            translated_sentence_final+=word+' '\n",
    "        else:\n",
    "            translated_sentence_final+=word+'.'\n",
    "    print(f\"Translated Example Sentence: \\n {translated_sentence_final}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "193f6b5c64d175a70f8bc370a8e28557b54eddf9787b8dde324aa4d68183bc16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

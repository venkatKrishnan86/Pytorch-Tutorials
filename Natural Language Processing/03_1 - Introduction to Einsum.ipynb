{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einsum\n",
    "Why?\n",
    "- Extremely Convenient and Compact\n",
    "- It can combine multiple tensor operations in one\n",
    "\n",
    "Cons\n",
    "- Can be confusing\n",
    "- We might lose some performance\n",
    "    - As it is not optimized as compared for a specific function call\n",
    "    - Sometimes it can be faster as we can replace multiple function calls to one function call\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"../images/Einsum.png\" style=\"width:450px;height:250px;\">\n",
    "</p>\n",
    "\n",
    "### Important Definitions\n",
    "1. **Free indices**: Are the indices specified in the output\n",
    "2. **Summation indices**: All other indices. Those that appear in the input argument and NOT in the output specification\n",
    "\n",
    "E.g. \n",
    "\n",
    "i,j --> Free indices, \n",
    "\n",
    "k--> Summation index in the previous example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.44730454, 0.79820593, 0.35652261, 0.97361289, 0.49218272]),\n",
       " array([0.22222346, 0.25200656, 0.0286736 ]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.random.rand(5)\n",
    "B = np.random.rand(3)\n",
    "A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09940156, 0.11272368, 0.01282583],\n",
       "       [0.17738008, 0.20115313, 0.02288744],\n",
       "       [0.07922769, 0.08984604, 0.01022279],\n",
       "       [0.21635962, 0.24535684, 0.02791699],\n",
       "       [0.10937454, 0.12403328, 0.01411265]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outer_product = np.einsum('i,j->ij', A, B) # i,j --> Free indices\n",
    "outer_product"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "<img src=\"../images/Einsum 2.png\" style=\"width:450px;height:250px;\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.ones(3)\n",
    "sum_x = np.einsum('i->', x)\n",
    "sum_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1.] [2. 2. 2.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.ones(3)*2\n",
    "print(x,y)\n",
    "inner_product = np.einsum('i,i->',x,y)\n",
    "inner_product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation of Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.ones((5,4,3))\n",
    "np.einsum('ijk->kji',x).shape # Will transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5580, 0.2671, 0.3252],\n",
       "        [0.9512, 0.4847, 0.1854]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand((2,3))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5580, 0.9512],\n",
       "        [0.2671, 0.4847],\n",
       "        [0.3252, 0.1854]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('ij->ji', x) # Transpose"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.7716)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('ij->',x) \n",
    "# Returns sum of all the 6 elements\n",
    "# Happens as we did not specify the output dimension, hence all input dimensions are summation indices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5092, 0.7518, 0.5106])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('ij->j',x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Row Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1503, 1.6213])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('ij->i',x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix-Vector Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.rand((1,3)) # Row vector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For matrix multiplication between x (2,3) and v(1,3), we would have done $xv^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8530],\n",
       "        [1.2412]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('ij,kj->ik', x, v) # It has reshaped by itself"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix-Matrix Multiplication\n",
    "Lets do x (2,3) with x(2,3) itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4885, 0.7205],\n",
       "        [0.7205, 1.1741]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('ij,kj->ik',x,x) # For (2,3) x (3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2161, 0.6101, 0.3578],\n",
       "        [0.6101, 0.3063, 0.1767],\n",
       "        [0.3578, 0.1767, 0.1401]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('ij,ik->jk',x,x) # For (3,2) x (2,3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dot product 1st row with 1st row of matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5580, 0.2671, 0.3252])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4885)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dot product of 1st row of x with itself\n",
    "torch.einsum(\"i,i->\",x[0],x[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dot product with matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6625)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum(\"ij,ij->\",x,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6625)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sum(x*x)) # Sum of all the elements in the element wise multiplied x with x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Element-wise multiplication (Hadamard Product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3114, 0.0713, 0.1057],\n",
       "        [0.9047, 0.2350, 0.0344]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum(\"ij,ij->ij\",x,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3114, 0.0713, 0.1057],\n",
       "        [0.9047, 0.2350, 0.0344]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x*x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outer Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand((3))\n",
    "b = torch.rand((5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0597, 0.0088, 0.0661, 0.0332, 0.1593],\n",
       "         [0.0339, 0.0050, 0.0376, 0.0189, 0.0906],\n",
       "         [0.2717, 0.0402, 0.3008, 0.1512, 0.7250]]),\n",
       " tensor([[0.0597, 0.0339, 0.2717],\n",
       "         [0.0088, 0.0050, 0.0402],\n",
       "         [0.0661, 0.0376, 0.3008],\n",
       "         [0.0332, 0.0189, 0.1512],\n",
       "         [0.1593, 0.0906, 0.7250]]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum(\"i,j->ij\",a,b), torch.einsum(\"i,j->ji\",a,b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand((3,2,5))\n",
    "b = torch.rand((3,5,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1.9635, 0.8899, 2.4917],\n",
       "          [1.3289, 0.8420, 1.6077]],\n",
       " \n",
       "         [[1.5425, 1.1133, 0.9360],\n",
       "          [1.9515, 1.4296, 1.2584]],\n",
       " \n",
       "         [[1.6735, 0.9525, 1.2178],\n",
       "          [1.0512, 0.8327, 0.7687]]]),\n",
       " torch.Size([3, 2, 3]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum(\"ijk,ikl->ijl\",a,b), torch.einsum(\"ijk,ikl->ijl\",a,b).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1.9635, 0.8899, 2.4917],\n",
       "          [1.3289, 0.8420, 1.6077]],\n",
       " \n",
       "         [[1.5425, 1.1133, 0.9360],\n",
       "          [1.9515, 1.4296, 1.2584]],\n",
       " \n",
       "         [[1.6735, 0.9525, 1.2178],\n",
       "          [1.0512, 0.8327, 0.7687]]]),\n",
       " torch.Size([3, 2, 3]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bmm(a,b), torch.bmm(a,b).shape # bmm: Batch Matrix Multiplication"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2410, 0.0923, 0.4613],\n",
       "        [0.1305, 0.0871, 0.5266],\n",
       "        [0.3240, 0.7481, 0.3638]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand((3,3))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2410, 0.0871, 0.3638])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('ii->i',x) # ii => Diagonal values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6919)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('ii->',x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6919)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(torch.einsum('ii->i',x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are way more **advanced** operations which can be done easily using `einsum`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:41:22) [Clang 13.0.1 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "193f6b5c64d175a70f8bc370a8e28557b54eddf9787b8dde324aa4d68183bc16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Language Model\n",
    "Lets say we have this as training: \"sample text\", and a window_size = 3\n",
    "\n",
    "We shall split this to -\n",
    "- \"sam\" --> \"p\"\n",
    "- \"amp\" --> \"l\"\n",
    "- \"mpl\" --> \"e\"\n",
    "- \"ple\" --> \" \"\n",
    "- \"le \" --> \"t\"\n",
    "- \"e t\" --> \"e\"\n",
    "- \" te\" --> \"x\"\n",
    "- \"tex\" --> \"t\"\n",
    "\n",
    "Each character will have its own embedding, and given three characters in a sequence, we shall predict the next character - making this equivalent to a classifcation problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterDataset(Dataset):\n",
    "    \"\"\"Custom Dataset\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        Input text that will be used to create the entire database.\n",
    "    \n",
    "    window_size : int\n",
    "        Number of characters to use as input features. Default = 3\n",
    "        \n",
    "    vocab_size : int\n",
    "        Number of characters in the vocabulary. Note that the \n",
    "        last character is always reserved for a special \"~\" \n",
    "        out-of-vocabulary character (<UNK> token). Default = 50\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    ch2ix : default_dict\n",
    "        Mapping from the character to the position of that \n",
    "        character in the vcabulary. Note that all characters\n",
    "        that are not in the vocabulary  will get mapped into \n",
    "        the index `vocab_size - 1`.\n",
    "    \n",
    "    ix2ch : dict\n",
    "        Mapping from the character position in the vocabulary\n",
    "        to te actual character.\n",
    "    \n",
    "    vocabulary : list\n",
    "        List of all characters. `len(vocabulary) == vocab_size`.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, text, window_size = 3, vocab_size = 50) -> None:\n",
    "        self.text = text.replace(\"\\n\", \" \") # Replacing next line to a space\n",
    "        self.window_size =window_size\n",
    "        self.ch2ix = defaultdict(lambda: vocab_size - 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "193f6b5c64d175a70f8bc370a8e28557b54eddf9787b8dde324aa4d68183bc16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

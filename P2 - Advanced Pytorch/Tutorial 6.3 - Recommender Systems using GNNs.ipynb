{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems Using GNNs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credits: Machine Learning Alchemy\n",
    "\n",
    "Playlist: https://www.youtube.com/watch?v=h1zxhx815Fk&list=PLcLdsfpLufYCJ_eg7VWuI7ROQT7SxUDGj&index=2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Supervised Learning for generating Graphs\n",
    "\n",
    "### How do we construct the graph?\n",
    "- We use **3.5** as the threshold for a positive rating.\n",
    "- Any interaction above rating 3.5 is considered an **edge**\n",
    "\n",
    "### What loss function do we use?\n",
    "- Since this is self-supervised learning, we cannot rely on the rating labels to compute the loss function, hence we will **not** use RMSE\n",
    "- We can use Bayesian Personalized Ranking (BPR) Loss -\n",
    "    - A pairwise objective, which **encourages** the predictions of *positive* samples to be **higher** than the *negative* samples for each user \n",
    "\n",
    "$$L_{BPR} = -\\sum_{u=1}^M\\sum_{i \\in N_u}\\sum_{j \\notin N_u} \\ln \\sigma(\\hat y_{ui} - \\hat y_{uj}) + \\lambda \\|E^{(0)}\\|^2$$\n",
    "\n",
    "where -\n",
    "- $\\hat y_{ui}$: Predicted score of a **positive** sample\n",
    "- $\\hat y_{uj}$: Predicted score of a **negative** sample\n",
    "- $\\lambda$: Regularizer parameter\n",
    "- $E^{(0)}$: Node Feature Embedding/Matrix at Layer 0 for **all** the nodes\n",
    "\n",
    "Finally, we aim to maximise $\\hat y_{ui} - \\hat y_{uj}$ (Score difference of positive and negative samples), hence the negative sign in the overall loss, as we will minimise the loss."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, metrics, preprocessing\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim, Tensor\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "import torch_geometric as pyg\n",
    "from torch_geometric.utils import degree, structured_negative_sampling\n",
    "from torch_geometric.data import download_url, extract_zip\n",
    "from torch_geometric import nn as pyg_nn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset link: https://grouplens.org/datasets/movielens/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using existing file ml-latest-small.zip\n",
      "Extracting ../datasets/MovieLens/ml-latest-small.zip\n"
     ]
    }
   ],
   "source": [
    "url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
    "extract_zip(download_url(url, '../datasets/MovieLens/'), '../datasets/MovieLens/')\n",
    "\n",
    "movie_path = '../datasets/MovieLens/ml-latest-small/movies.csv'\n",
    "rating_path = '../datasets/MovieLens/ml-latest-small/ratings.csv'\n",
    "user_path_path = '../datasets/MovieLens/ml-latest-small/users.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating  timestamp\n",
      "0       1        1     4.0  964982703\n",
      "1       1        3     4.0  964981247\n",
      "2       1        6     4.0  964982224\n",
      "3       1       47     5.0  964983815\n",
      "4       1       50     5.0  964982931\n"
     ]
    }
   ],
   "source": [
    "rating_df = pd.read_csv(rating_path)\n",
    "print(rating_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique movies = 9724\n",
      "Unique users = 610\n"
     ]
    }
   ],
   "source": [
    "print('Unique movies =',len(rating_df['movieId'].unique()))\n",
    "print('Unique users =',len(rating_df['userId'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0    26818\n",
       "3.0    20047\n",
       "5.0    13211\n",
       "3.5    13136\n",
       "4.5     8551\n",
       "2.0     7551\n",
       "2.5     5550\n",
       "1.0     2811\n",
       "1.5     1791\n",
       "0.5     1370\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df.rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100836.000000</td>\n",
       "      <td>100836.000000</td>\n",
       "      <td>100836.000000</td>\n",
       "      <td>1.008360e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>326.127564</td>\n",
       "      <td>19435.295718</td>\n",
       "      <td>3.501557</td>\n",
       "      <td>1.205946e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>182.618491</td>\n",
       "      <td>35530.987199</td>\n",
       "      <td>1.042529</td>\n",
       "      <td>2.162610e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.281246e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>177.000000</td>\n",
       "      <td>1199.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.019124e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>325.000000</td>\n",
       "      <td>2991.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.186087e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>477.000000</td>\n",
       "      <td>8122.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.435994e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>610.000000</td>\n",
       "      <td>193609.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.537799e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              userId        movieId         rating     timestamp\n",
       "count  100836.000000  100836.000000  100836.000000  1.008360e+05\n",
       "mean      326.127564   19435.295718       3.501557  1.205946e+09\n",
       "std       182.618491   35530.987199       1.042529  2.162610e+08\n",
       "min         1.000000       1.000000       0.500000  8.281246e+08\n",
       "25%       177.000000    1199.000000       3.000000  1.019124e+09\n",
       "50%       325.000000    2991.000000       3.500000  1.186087e+09\n",
       "75%       477.000000    8122.000000       4.000000  1.435994e+09\n",
       "max       610.000000  193609.000000       5.000000  1.537799e+09"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that **user** and **movie ids'** max values are very large, while the total values are way lesser, hence preprocessing is required and we will use `sklearn.preprocessing.LabelEncoder()`, which will normalize the ids to the length."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_user = preprocessing.LabelEncoder()\n",
    "lbl_movie = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df.userId = lbl_user.fit_transform(rating_df.userId.values)\n",
    "rating_df.movieId = lbl_user.fit_transform(rating_df.movieId.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100836.000000</td>\n",
       "      <td>100836.000000</td>\n",
       "      <td>100836.000000</td>\n",
       "      <td>1.008360e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>325.127564</td>\n",
       "      <td>3101.735561</td>\n",
       "      <td>3.501557</td>\n",
       "      <td>1.205946e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>182.618491</td>\n",
       "      <td>2627.050983</td>\n",
       "      <td>1.042529</td>\n",
       "      <td>2.162610e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.281246e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>176.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.019124e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>324.000000</td>\n",
       "      <td>2252.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.186087e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>476.000000</td>\n",
       "      <td>5095.250000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.435994e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>609.000000</td>\n",
       "      <td>9723.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.537799e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              userId        movieId         rating     timestamp\n",
       "count  100836.000000  100836.000000  100836.000000  1.008360e+05\n",
       "mean      325.127564    3101.735561       3.501557  1.205946e+09\n",
       "std       182.618491    2627.050983       1.042529  2.162610e+08\n",
       "min         0.000000       0.000000       0.500000  8.281246e+08\n",
       "25%       176.000000     900.000000       3.000000  1.019124e+09\n",
       "50%       324.000000    2252.000000       3.500000  1.186087e+09\n",
       "75%       476.000000    5095.250000       4.000000  1.435994e+09\n",
       "max       609.000000    9723.000000       5.000000  1.537799e+09"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load edges between users\n",
    "Load edges between users and movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_edges_from_csv(\n",
    "        df, \n",
    "        src_index_col = 'userId', \n",
    "        dst_index_col = 'movieId',\n",
    "        link_index_col = 'rating',\n",
    "        rating_threshold = 3.5\n",
    "    ):\n",
    "    \"\"\"\n",
    "        Loads csv containing edges between users and items\n",
    "\n",
    "        Arguments:\n",
    "            src_index_col (str): column name of users\n",
    "            dst_index_col (str): column name of items\n",
    "            link_index_col (str): column name of user item interaction\n",
    "            rating_threshold (int, optional): Threshold to determine positivity of \n",
    "            edge. Defaults to 3.5\n",
    "\n",
    "        Returns:\n",
    "            edge_index (list of list) --> (2 x N) matrix containing the node ids of\n",
    "            N user-item edges N here is the number of interactions\n",
    "    \"\"\"\n",
    "    \n",
    "    edge_index = None\n",
    "\n",
    "    # Constructing COO format edge_index from input rating events\n",
    "\n",
    "    src = [user_id for user_id in df[src_index_col]]\n",
    "    dst = [(movie_id) for movie_id in df[dst_index_col]]\n",
    "\n",
    "    # Apply rating threshold\n",
    "    # link_index_col: Rating column\n",
    "    edge_attr = torch.from_numpy(df[link_index_col].values).view(-1, 1) >= rating_threshold\n",
    "    # edge_attrs = torch.from_numpy(df[link_index_col].values).view(-1, 1)\n",
    "\n",
    "    edge_index = [[],[]]\n",
    "    for i in range(edge_attr.shape[0]): # Iterate the rows\n",
    "        if edge_attr[i]: # Create edge between USER and MOVIE only if rating is >= threshold\n",
    "            edge_index[0].append(src[i])\n",
    "            edge_index[1].append(dst[i])\n",
    "    return edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 61716])\n"
     ]
    }
   ],
   "source": [
    "edge_index = load_edges_from_csv(rating_df)\n",
    "edge_index = torch.LongTensor(edge_index)\n",
    "print(edge_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(610, 9724)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_users = len(rating_df['userId'].unique())\n",
    "num_movies = len(rating_df['movieId'].unique())\n",
    "num_users, num_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61716"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_interactions = edge_index.shape[1]\n",
    "all_indices = [i for i in range(num_interactions)]\n",
    "num_interactions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the edges of the graph using a 80/10/10 train/validation/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, test_indices = train_test_split(\n",
    "    all_indices,\n",
    "    test_size=0.2,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "val_indices, test_indices = train_test_split(\n",
    "    test_indices,\n",
    "    test_size=0.5,\n",
    "    random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 49372])\n",
      "torch.Size([2, 6172])\n",
      "torch.Size([2, 6172])\n"
     ]
    }
   ],
   "source": [
    "train_edge_index = edge_index[:, train_indices]\n",
    "val_edge_index = edge_index[:, val_indices]\n",
    "test_edge_index = edge_index[:, test_indices]\n",
    "print(train_edge_index.shape, val_edge_index.shape, test_edge_index.shape, sep ='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([608])\n",
      "torch.Size([6682])\n"
     ]
    }
   ],
   "source": [
    "print(torch.unique(train_edge_index[0]).size())\n",
    "print(torch.unique(train_edge_index[1]).size())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bipartite Graph Representation\n",
    "A Graph which has two sets, where individual elements of one set ($U$) is only connected to an element of the other set ($V$) and never to itself. E.g. User nodes connected to movie nodes, but they won't be connected to each other, hence bipartite.\n",
    "\n",
    "How do we get the adjacency matrix from a bipartite graph?\n",
    "- We start from the interaction matrix $R$, where\n",
    "    - Row index: Represents node $U$\n",
    "    - Column index: Represents node $V$\n",
    "- Here is how we convert an interaction matrix to an adjacency matrix $A$ -\n",
    "$$A=\\begin{pmatrix}\n",
    "\\mathbf{0} & \\mathbf{R}\\\\\n",
    "\\mathbf{R^T} & \\mathbf{0}\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "$$\\mathbf{R} \\in \\mathbb{R}^{M \\times N}$$\n",
    "\n",
    "where $\\mathbf{R}$ is the interaction matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse and Dense examples\n",
    "Let us first understand how sparse functions work in **PyTorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3,\n",
       "                        3, 4, 4, 4, 4, 4],\n",
       "                       [0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3,\n",
       "                        4, 0, 1, 2, 3, 4]]),\n",
       "       values=tensor([ 0.0045,  0.6369,  1.3144, -0.4025, -0.3675,  1.8789,\n",
       "                       0.6708,  1.3912, -0.8439, -0.6128,  1.2500, -0.5788,\n",
       "                       0.3349, -0.2484,  0.5485, -2.8863, -0.1045,  0.0095,\n",
       "                       0.0864, -0.9890, -0.9143,  0.0922, -0.0992, -0.8831,\n",
       "                       1.8689]),\n",
       "       size=(5, 5), nnz=25, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense = torch.randn(5, 5)\n",
    "sparse = dense.to_sparse_coo()\n",
    "sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [0, 1],\n",
       "        [0, 2],\n",
       "        [0, 3],\n",
       "        [0, 4],\n",
       "        [1, 0],\n",
       "        [1, 1],\n",
       "        [1, 2],\n",
       "        [1, 3],\n",
       "        [1, 4],\n",
       "        [2, 0],\n",
       "        [2, 1],\n",
       "        [2, 2],\n",
       "        [2, 3],\n",
       "        [2, 4],\n",
       "        [3, 0],\n",
       "        [3, 1],\n",
       "        [3, 2],\n",
       "        [3, 3],\n",
       "        [3, 4],\n",
       "        [4, 0],\n",
       "        [4, 1],\n",
       "        [4, 2],\n",
       "        [4, 3],\n",
       "        [4, 4]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse.indices().t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0045,  0.6369,  1.3144, -0.4025, -0.3675],\n",
       "        [ 1.8789,  0.6708,  1.3912, -0.8439, -0.6128],\n",
       "        [ 1.2500, -0.5788,  0.3349, -0.2484,  0.5485],\n",
       "        [-2.8863, -0.1045,  0.0095,  0.0864, -0.9890],\n",
       "        [-0.9143,  0.0922, -0.0992, -0.8831,  1.8689]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse.to_dense()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `SparseTensor` is more easy for calculating the adjacency matrix $A$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SparseTensor(\n",
    "    row = sparse.indices()[0],\n",
    "    col = sparse.indices()[1],\n",
    "    sparse_sizes = sparse.size()\n",
    ").to_dense()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When zeros, it saves the space by not storing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([], size=(2, 0)),\n",
       "       values=tensor([], size=(0,)),\n",
       "       size=(5, 5), nnz=0, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense = torch.zeros(5, 5)\n",
    "sparse = dense.to_sparse_coo()\n",
    "sparse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The conversion functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interaction2adjacency(input_edge_index, num_users = num_users, num_movies = num_movies):\n",
    "    # input_edge_index.shape: (2, num_edges)\n",
    "    R = torch.zeros((num_users, num_movies))\n",
    "    for i in range(input_edge_index.shape[1]):\n",
    "        row_idx = input_edge_index[0][i]\n",
    "        col_idx = input_edge_index[1][i]\n",
    "        R[row_idx][col_idx] = 1\n",
    "    \n",
    "    R_transpose = torch.transpose(R, 0, 1)\n",
    "    adj_mat = torch.zeros((num_users+num_movies, num_users+num_movies))\n",
    "    adj_mat[:num_users, num_users:] = R.clone() # Returns a copy of the tensor\n",
    "    adj_mat[num_users:, :num_users] = R_transpose.clone()\n",
    "    adj_mat_edge_index = adj_mat.to_sparse_coo()\n",
    "    adj_mat_edge_index = adj_mat_edge_index.indices()\n",
    "    return adj_mat_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjacency2interaction(input_edge_index, num_users = num_users, num_movies = num_movies):\n",
    "    sparse_input_edge_index = SparseTensor(\n",
    "        row = input_edge_index[0],\n",
    "        col = input_edge_index[1],\n",
    "        sparse_sizes = (num_users+num_movies, num_users+num_movies)\n",
    "    )\n",
    "    adj_mat = sparse_input_edge_index.to_dense()\n",
    "    interact_mat = adj_mat[:num_users, num_users:]\n",
    "    r_mat_edge_index = interact_mat.to_sparse_coo().indices()\n",
    "    return r_mat_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_edge_index = interaction2adjacency(train_edge_index)\n",
    "val_edge_index = interaction2adjacency(val_edge_index)\n",
    "test_edge_index = interaction2adjacency(test_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     0,     0,  ..., 10330, 10331, 10333],\n",
      "        [  610,   612,   615,  ...,   183,   183,   330]])\n",
      "torch.Size([2, 98744])\n",
      "\n",
      "tensor([[    0,     0,     0,  ..., 10278, 10301, 10327],\n",
      "        [  794,   811,  1120,  ...,   248,   330,   183]])\n",
      "torch.Size([2, 12344])\n",
      "\n",
      "tensor([[    0,     0,     0,  ..., 10301, 10324, 10332],\n",
      "        [ 1161,  1399,  1465,  ...,   304,   183,   183]])\n",
      "torch.Size([2, 12344])\n"
     ]
    }
   ],
   "source": [
    "print(train_edge_index)\n",
    "print(train_edge_index.shape, end='\\n\\n')\n",
    "# Doubled as the edges are now bi-direectional/undirected\n",
    "print(val_edge_index)\n",
    "print(val_edge_index.shape, end='\\n\\n')\n",
    "print(test_edge_index)\n",
    "print(test_edge_index.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function to compute BPR Loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`structured_negative_sampling` is a **PyG** library\n",
    "- Samples a negative edge :obj: `(i,k)` for every positive edge\n",
    "- :obj: `(i,j)` in the graph given by :attr: `edge_index`, and returns it as a tuple of the form :obj:`(i,j,k)`\n",
    "- Example - \n",
    "    ```\n",
    "    edge_index = torch.as_tensor([[0, 0, 1, 2],\n",
    "                                [0, 1, 2, 3]])\n",
    "    structured_negative_sampling(edge_index)\n",
    "    Output: (tensor([0, 0, 1, 2]), tensor([0, 1, 2, 3]), tensor([2, 3, 0, 2]))\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_mini_batch(batch_size, edge_index):\n",
    "    \"\"\"\n",
    "        Randomly samples indices of a minibatch given an adjacency matrix\n",
    "\n",
    "        Args:\n",
    "            batch_size (int): mini-batch size\n",
    "            edge_index (torch.Tensor): (2 x N) list of edges\n",
    "\n",
    "        Returns:\n",
    "            tuple: (user indices, positive item indices, negative_item_indices)\n",
    "    \"\"\"\n",
    "    edges = structured_negative_sampling(edge_index)\n",
    "    # edges (tuple): (node1, node2, node3)\n",
    "    # node1: size = num_edges\n",
    "    # node2: size = num_edges\n",
    "    # node3: size = num_edges\n",
    "    # node1 --> node2: Is an actual edge (positive edge)\n",
    "    # node1 --> node3: Is a negative sampled edge (Does not exist edge)\n",
    "\n",
    "    edges = torch.stack(edges, dim = 0) # Tuple --> Tensor\n",
    "    # New shape of edges (Tensor): (3 x num_edges)\n",
    "\n",
    "    indices = random.choices([i for i in range(edges[0].shape[0])], k = batch_size)\n",
    "    # Randomly samples 'batch_size' number of values from a list [0, 1, 2, .... num_edges]\n",
    "\n",
    "    batch = edges[:, indices]\n",
    "    # We obtain `batch_size` number of user to real (positive) edges and fake (negative) edges \n",
    "    return batch[0], batch[1], batch[2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([490]) tensor([3042]) tensor([4660])\n",
      "User 490 --> Item 3042 : Actual Edge\n",
      "User 490 --> Item 4660 : Fake Edge\n"
     ]
    }
   ],
   "source": [
    "user, pos, neg = sample_mini_batch(1, train_edge_index)\n",
    "print(user, pos, neg)\n",
    "print('User',user.item(),'--> Item',pos.item(),': Actual Edge')\n",
    "print('User',user.item(),'--> Item',neg.item(),': Fake Edge')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing LightGCN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light Graph Convolution\n",
    "Between each layer, LightGCN uses the following propagation rule for user and item embeddings\n",
    "\n",
    "$$e_u^{(k+1)} = \\sum_{i \\in N_u}\\frac{1}{\\sqrt{|N_u|}\\sqrt{|N_i|}}e_i^{(k)}$$\n",
    "\n",
    "$$e_i^{(k+1)} = \\sum_{u \\in N_i}\\frac{1}{\\sqrt{|N_i|}\\sqrt{|N_u|}}e_u^{(k)}$$\n",
    "\n",
    "where -\n",
    "- $N_u$: Set of all neighbours of user $u$ (**Items** LIKED by **user** $u$)\n",
    "- $N_i$: Set of all neighbours of item $i$ (**Users** who LIKED **item** $i$)\n",
    "- $e_u^{(k)}$: $k^{th}$ layer user-embedding\n",
    "- $e_i^{(k)}$: $k^{th}$ layer item-embedding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Combination and Model Prediction\n",
    "The only trainable parameters of LightGCN are the 0th layer embeddings $e_u^{(0)}$ and $e_i^{(0)}$ for each user and item. We combine the embeddings obtained at each layer of propagation to form the final embeddings for all users and items, $e_u$ and $e_i$ via the following equation -\n",
    "\n",
    "$$e_u=\\sum_{k=0}^K \\alpha_k e_u^{(k)}$$\n",
    "$$e_i=\\sum_{k=0}^K \\alpha_k e_i^{(k)}$$\n",
    "\n",
    "where -\n",
    "- $\\alpha_k$: Hyperparameter which weights the contribution of the $k^{th}$ layer embedding to the final embedding\n",
    "\n",
    "The model prediction is obtained by taking the inner product of the final user and item embeddings\n",
    "\n",
    "$$\\hat y_{ui} = <e_u, e_i> = e_u^Te_i$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Form\n",
    "In our implementation, we utilize the matrix form of LightGCN. We perform multi-scale diffusion to obtain the final embedding, which sums embeddings diffused across multi-hop scales. ($K$ layers)\n",
    "\n",
    "$$E^{(K)}=\\alpha_0E^{(0)} + \\alpha_1\\tilde AE^{(0)} + \\alpha_2\\tilde A^2E^{(0)} + ... + \\alpha_K\\tilde A^KE^{(0)}$$\n",
    "\n",
    "where\n",
    "- $E^{(0)} \\in \\mathbb{R}^{(M \\times N)} \\times T$: Stacked initial item and user embeddings where -\n",
    "    - $M$: Number of users\n",
    "    - $N$: Number of items\n",
    "    - $T$: Dimension of each embedding\n",
    "- $\\tilde A = D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}$: Is a symmetrically normalized adjacency matrix, where $D$ is a degree matrix\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The operation $D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}$ is performed by `torch_geometric.nn.conv.gcn_conv.gcn_norm()`\n",
    "\n",
    "`gcn_norm()` returns a tuple - \n",
    "\n",
    "(original edge_index Tensor, Normalization values: Root of Degree Neighbours x Root of Degree of itself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[    0,     0,     0,  ..., 10330, 10331, 10333],\n",
       "         [  610,   612,   615,  ...,   183,   183,   330]]),\n",
       " tensor([0.0070, 0.0204, 0.0101,  ..., 0.1140, 0.1140, 0.1078]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyg_nn.conv.gcn_conv.gcn_norm(edge_index=train_edge_index,\n",
    "                            add_self_loops=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGCN(pyg_nn.MessagePassing):\n",
    "    def __init__(self,\n",
    "                 num_users,\n",
    "                 num_items,\n",
    "                 embedding_dim = 64,\n",
    "                 K = 3,\n",
    "                 add_self_loops = False):\n",
    "        \"\"\"\n",
    "            Initialises the LightGCN Model\n",
    "\n",
    "            Args:\n",
    "                num_users (int): Number of users\n",
    "                num_items (int): Number of items\n",
    "                embedding_dim (int, optional): Dimensionality of embeddings (Default = 64)\n",
    "                K (int, optional): Number of message passing layers (Default = 3)\n",
    "                add_self_loops (bool, optional): Whether to add self-loops for message passing (Default = False)\n",
    "        \"\"\"\n",
    "        super(LightGCN, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.K = K\n",
    "        self.add_self_loops = add_self_loops\n",
    "\n",
    "        self.users_emb = nn.Embedding(num_embeddings = self.num_users, \n",
    "                                      embedding_dim = self.embedding_dim) # e_u^0\n",
    "        self.items_emb = nn.Embedding(num_embeddings = self.num_items,\n",
    "                                      embedding_dim = self.embedding_dim) # e_i^0\n",
    "        \n",
    "        # Filling the input tensor with values drawn from a normal distribution\n",
    "        # According to the LightGCN paper, this performs better\n",
    "        nn.init.normal_(self.users_emb.weight, std=0.1)\n",
    "        nn.init.normal_(self.items_emb.weight, std=0.1)\n",
    "\n",
    "    def forward(self, edge_index):\n",
    "        \"\"\"\n",
    "            Forward pass of LightGCN model\n",
    "\n",
    "            Args:\n",
    "                edge_index (SparseTensor): Adjacency Matrix\n",
    "            \n",
    "            Returns:\n",
    "                tuple (Tensor): e_u_k, e_u_0, e_i_k, e_i_0\n",
    "        \"\"\"\n",
    "        # GCN Norm returns a tuple \n",
    "        # (original edge_index Tensor, Normalization values: Root of Degree Neighbours x Root of Degree of itself)\n",
    "        edge_index_norm = pyg_nn.conv.gcn_conv.gcn_norm(edge_index=edge_index,\n",
    "                                                        add_self_loops=self.add_self_loops)\n",
    "        \n",
    "        # Concat the user_embedding and item_embedding as the layer0 embedding matrix\n",
    "        # Size will be (n_users + n_items) x embedding_dimension\n",
    "        emb_0 = torch.cat([self.users_emb.weight, self.items_emb.weight]) # E^0\n",
    "        \n",
    "        # Save the layer0 embedding to the embs list\n",
    "        embs = [emb_0]\n",
    "\n",
    "        # emb_k is the embedding that we are actually going to push it through the graph layers\n",
    "        # as described the LightGCN paper formula\n",
    "        emb_k = emb_0\n",
    "\n",
    "        # Push the embedding of all users and items through the Graph Model K times\n",
    "        # K here is the number of layers\n",
    "        # This performs the \"Matrix Form\" formula mentioned before\n",
    "        for i in range(self.K):\n",
    "            # `propagate()` is a function from `MessagePassing` superclass\n",
    "            # Calls the message() function when we call `propagate()`\n",
    "            emb_k = self.propagate(edge_index=edge_index_norm[0],\n",
    "                                   x = emb_k,\n",
    "                                   norm = edge_index_norm[1])\n",
    "            embs.append(emb_k)\n",
    "        \n",
    "        # Stacked embs is a LIST of embedding matrices at each layer\n",
    "        # Shape: num_nodes x (n_layers + 1) x embedding_dim\n",
    "        # Converts the list to Tensor format\n",
    "        embs = torch.stack(embs, dim = 1)\n",
    "\n",
    "        # In experiments, setting alpha_k = 1/(K+1) gives best results, so we take mean\n",
    "        emb_final = torch.mean(embs, dim = 1) # E^K\n",
    "\n",
    "        # Splits to e_u^k and e_i^k\n",
    "        users_emb_final, items_emb_final = torch.split(emb_final, [self.num_users, self.num_items])\n",
    "\n",
    "        return users_emb_final, self.users_emb.weight, items_emb_final, self.items_emb.weight\n",
    "    \n",
    "    def message(self, x_j: torch.Tensor, norm) -> torch.Tensor:\n",
    "        # When we call `propagate()`, we call message\n",
    "        # x_j shape: edge_index_len x embedding length\n",
    "        # x_j is the embedding of all the neighbours based on the src_list in coo_edge_index\n",
    "        # element-wise multiply by the symmetical norm\n",
    "        # Here we are using edge_index instead of adjacency matrix\n",
    "        return norm.view(-1,1) * x_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = 3\n",
    "light_gcn = LightGCN(num_users=num_users,\n",
    "                     num_items=num_movies,\n",
    "                     K=layers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function\n",
    "\n",
    "\n",
    "\n",
    "We utilize a Bayesian Personalized Ranking (BPR) loss, a pairwise objective which encourages the predictions of *positive* samples to be **higher** than *negative* samples for each user.\n",
    "\n",
    "\\begin{equation}\n",
    "L_{BPR} = -\\sum_{u = 1}^M \\sum_{i \\in N_u} \\sum_{j \\notin N_u} \\ln{\\sigma(\\hat{y}_{ui} - \\hat{y}_{uj})} + \\lambda ||E^{(0)}||^2 \n",
    "\\end{equation}\n",
    "\n",
    "$\\hat{y}_{ui}$: predicted score of a positive sample\n",
    "\n",
    "$\\hat{y}_{uj}$: predicted score of a negative sample\n",
    "\n",
    "$\\lambda$: hyperparameter which controls the L2 regularization strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

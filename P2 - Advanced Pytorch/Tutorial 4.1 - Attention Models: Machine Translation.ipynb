{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "Data for this project is a set of thousands of English to French translation pairs\n",
    "\n",
    "One hot encoding will be done as follows -\n",
    "<p align=\"center\">\n",
    "<img src=\"../images/word-encoding.png\" style=\"width:450px;height:250px;\">\n",
    "\n",
    "Where -\n",
    "\n",
    "**SOS**: Start of Sentence token\n",
    "\n",
    "**EOS**: End of Sentence token"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to achieve it?\n",
    "We will need a unique index per word to use as the inputs and targets of the network later. To keep track of all this, we will use a helper class called `Lang`, which has word → index (`word2index`) and index → word (`index2word`) dictionaries, as well as a count of each word `word2count` which will be used to replace **rare** words later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name) -> None:\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"} # Setting SOS to be 0, and EOS to be 1\n",
    "        self.n_words = 2 # Count SOS and EOS\n",
    "    \n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:             # Checks if the word is already used in the sentence\n",
    "            self.word2index[word] = self.n_words    # Adds the word and gives the index of the word in the sentence \n",
    "            self.index2word[self.n_words] = word    # Adds the index of the word and the word based on the figure two cells above  \n",
    "            self.word2count[word] = 1               # Counts number of times the word is used in a sentence (Shows rarity of word) \n",
    "            self.n_words += 1                       # Increases index pointer by 1\n",
    "        else:\n",
    "            self.word2count[word] +=1               # Increases count of a particular word which has been repeated\n",
    "    \n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)                      # For every word in the sentence, call addWord() method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Unicode literals to ASCII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowercase, trim and removing non-letter characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip()) # Send the string characterwise to unicodeToAscii()\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse = False):\n",
    "    print('Reading Lines...')\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('../datasets/english-french data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n') # reads the eng-fre.txt file\n",
    "    \n",
    "    # Split every line into pairs of english and french text and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "    \n",
    "    # Reverse pairs if reverse = True\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "    \n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "193f6b5c64d175a70f8bc370a8e28557b54eddf9787b8dde324aa4d68183bc16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

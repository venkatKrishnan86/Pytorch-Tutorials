{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Tutorial\n",
    "#### Tensors Basics\n",
    "A tensor is a generalization of vectors and matrices and is easily understood as a multidimensional array. It is a term and set of techniques known in machine learning in the training and operation of deep learning models can be described in terms of tensors.\n",
    "In many cases tensors are used as a replacement for NumPy to use the power of GPUs. GPUs are way more faster for all operations, matrix operations etc. than a CPU. The main source for GPUs are CUDA by NVIDIA. Tensors can use CUDA to use the GPU, but NumPy arrays are written for CPUs. \n",
    "\n",
    "Tensors are a type of data structure used in linear algebra, and like vectors and matrices, you can calculate arithmetic operations with tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[3.,4,5,6]\n",
    "arr=np.array(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0, 4, 5, 6] [3. 4. 5. 6.]\n"
     ]
    }
   ],
   "source": [
    "print(lst, arr) # We can see arr converts everything to float unlike the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[3,4,5,6]\n",
    "arr=np.array(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Numpy To Pytorch Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 5, 6])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors=torch.from_numpy(arr)\n",
    "tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Indexing similar to numpy\n",
    "tensors[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5, 6])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Advantage/Disadvantage of from_numpy. The array and tensor uses the same memory location\n",
    "tensors[3]=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  3,   4,   5, 100])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3,   4,   5, 100])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  3,   4,   5, 100])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Prevent this by using torch.tensor\n",
    "tensor_arr=torch.tensor(arr)\n",
    "tensor_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  3,   4,   5, 120])\n",
      "[  3   4   5 100]\n"
     ]
    }
   ],
   "source": [
    "tensor_arr[3]=120\n",
    "print(tensor_arr)\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([3.,4,5]) # Similar to numpy arrays, tensors also convert all the elements to the highest priority data type in the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.dtype # default dtype for numbers with decimals: 3.0, 4.2 etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##zeros and ones\n",
    "torch.zeros(2,3,dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(2,3,dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.tensor(np.arange(0,15).reshape(5,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [ 6,  7,  8],\n",
       "        [ 9, 10, 11],\n",
       "        [12, 13, 14]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1],\n",
       "        [ 3,  4],\n",
       "        [ 6,  7],\n",
       "        [ 9, 10],\n",
       "        [12, 13]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:,0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors, also like numpy arrays, need to have same number of elements 'a' per row and same number of elements 'b' per column (unlike lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Tensors to Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  3,   4,   5, 100])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3   4   5 100]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "new_arr = tensors.numpy() # Both the tensor and numpy array will point to the same memory location in the CPU (Not for GPU)\n",
    "print(new_arr)\n",
    "print(type(new_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  4,   5,   6, 101])\n",
      "[  4   5   6 101]\n"
     ]
    }
   ],
   "source": [
    "tensors.add_(1)\n",
    "print(tensors)\n",
    "print(new_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arithmetic Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 7.,  9., 11.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([3,4,5], dtype=torch.float)\n",
    "b = torch.tensor([4,5,6], dtype=torch.float)\n",
    "print(a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7.,  9., 11.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=torch.zeros(3) #same shape is required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7.,  9., 11.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(a,b,out=c) #c must be of same shape as a and b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7.,  9., 11.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 7.,  9., 11.])\n"
     ]
    }
   ],
   "source": [
    "b.add_(a) # _ is inplace addition: b is changed to b+a\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Some more operations\n",
    "a = torch.tensor([3,4,5], dtype=torch.float)\n",
    "b = torch.tensor([4,5,6], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(27.)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### tensor[7,9,15]\n",
    "torch.add(a,b).sum() #sum(torch.add(a,b)) - will also work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1., -1., -1.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a - b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1., -1., -1.])\n"
     ]
    }
   ],
   "source": [
    "c = torch.sub(a,b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1., -1., -1.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.zeros(3)\n",
    "torch.sub(a,b, out=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "b.sub_(a) # b = b - a\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For multiplication and division\n",
    "- `torch.mul` and `torch.div` is used for element-wise multiplication and division, similar to `*` and `/`\n",
    "- `a.mul_(b)` is for implace multiplication, similiar to `a = a * b`\n",
    "- `a.div_(b)` is for implace multiplication, similiar to `a = a / b`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4066, 0.9277, 0.5862],\n",
      "        [0.6793, 0.4024, 0.1121],\n",
      "        [0.3090, 0.0849, 0.9140],\n",
      "        [0.2457, 0.8656, 0.9987],\n",
      "        [0.4261, 0.8874, 0.5731]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(5,3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4066, 0.6793, 0.3090, 0.2457, 0.4261])\n"
     ]
    }
   ],
   "source": [
    "print(a[:,0]) # All rows and column 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6793, 0.4024, 0.1121])\n"
     ]
    }
   ],
   "source": [
    "print(a[1,:]) # Row 2 and all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9277, 0.4024])\n"
     ]
    }
   ],
   "source": [
    "print(a[0:2,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.item()` is used is tensor has only one value in it.\n",
    "\n",
    "<span style=\"color: red;\">Cannot be used if there is more than 1 value</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1121)\n",
      "0.11210417747497559\n"
     ]
    }
   ],
   "source": [
    "print(a[1,2])\n",
    "print(a[1,2].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.reshape()` or `.view()` is used to reshape tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9826, 0.7057, 0.4725, 0.5816, 0.1636, 0.2196, 0.8620, 0.4628],\n",
      "        [0.6589, 0.4870, 0.9997, 0.5431, 0.7703, 0.2417, 0.3230, 0.6452],\n",
      "        [0.5115, 0.5316, 0.7312, 0.6976, 0.4326, 0.5961, 0.5460, 0.3598],\n",
      "        [0.4004, 0.4848, 0.0859, 0.1078, 0.2560, 0.1734, 0.7836, 0.5910],\n",
      "        [0.4561, 0.6876, 0.0162, 0.1736, 0.4072, 0.4348, 0.3791, 0.9949],\n",
      "        [0.6514, 0.0893, 0.0150, 0.7559, 0.6124, 0.8414, 0.7062, 0.7631],\n",
      "        [0.7246, 0.1353, 0.6749, 0.0330, 0.7088, 0.1843, 0.4360, 0.4048],\n",
      "        [0.9638, 0.7500, 0.8151, 0.9616, 0.0503, 0.0070, 0.4145, 0.2156]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(8,8)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9826, 0.7057, 0.4725, 0.5816, 0.1636, 0.2196, 0.8620, 0.4628, 0.6589,\n",
       "        0.4870, 0.9997, 0.5431, 0.7703, 0.2417, 0.3230, 0.6452, 0.5115, 0.5316,\n",
       "        0.7312, 0.6976, 0.4326, 0.5961, 0.5460, 0.3598, 0.4004, 0.4848, 0.0859,\n",
       "        0.1078, 0.2560, 0.1734, 0.7836, 0.5910, 0.4561, 0.6876, 0.0162, 0.1736,\n",
       "        0.4072, 0.4348, 0.3791, 0.9949, 0.6514, 0.0893, 0.0150, 0.7559, 0.6124,\n",
       "        0.8414, 0.7062, 0.7631, 0.7246, 0.1353, 0.6749, 0.0330, 0.7088, 0.1843,\n",
       "        0.4360, 0.4048, 0.9638, 0.7500, 0.8151, 0.9616, 0.0503, 0.0070, 0.4145,\n",
       "        0.2156])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.reshape(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9826, 0.7057, 0.4725, 0.5816],\n",
       "        [0.1636, 0.2196, 0.8620, 0.4628],\n",
       "        [0.6589, 0.4870, 0.9997, 0.5431],\n",
       "        [0.7703, 0.2417, 0.3230, 0.6452],\n",
       "        [0.5115, 0.5316, 0.7312, 0.6976],\n",
       "        [0.4326, 0.5961, 0.5460, 0.3598],\n",
       "        [0.4004, 0.4848, 0.0859, 0.1078],\n",
       "        [0.2560, 0.1734, 0.7836, 0.5910],\n",
       "        [0.4561, 0.6876, 0.0162, 0.1736],\n",
       "        [0.4072, 0.4348, 0.3791, 0.9949],\n",
       "        [0.6514, 0.0893, 0.0150, 0.7559],\n",
       "        [0.6124, 0.8414, 0.7062, 0.7631],\n",
       "        [0.7246, 0.1353, 0.6749, 0.0330],\n",
       "        [0.7088, 0.1843, 0.4360, 0.4048],\n",
       "        [0.9638, 0.7500, 0.8151, 0.9616],\n",
       "        [0.0503, 0.0070, 0.4145, 0.2156]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.reshape(16,-1) # if we put -1, it automatically captures the required number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9826, 0.7057, 0.4725, 0.5816],\n",
       "        [0.1636, 0.2196, 0.8620, 0.4628],\n",
       "        [0.6589, 0.4870, 0.9997, 0.5431],\n",
       "        [0.7703, 0.2417, 0.3230, 0.6452],\n",
       "        [0.5115, 0.5316, 0.7312, 0.6976],\n",
       "        [0.4326, 0.5961, 0.5460, 0.3598],\n",
       "        [0.4004, 0.4848, 0.0859, 0.1078],\n",
       "        [0.2560, 0.1734, 0.7836, 0.5910],\n",
       "        [0.4561, 0.6876, 0.0162, 0.1736],\n",
       "        [0.4072, 0.4348, 0.3791, 0.9949],\n",
       "        [0.6514, 0.0893, 0.0150, 0.7559],\n",
       "        [0.6124, 0.8414, 0.7062, 0.7631],\n",
       "        [0.7246, 0.1353, 0.6749, 0.0330],\n",
       "        [0.7088, 0.1843, 0.4360, 0.4048],\n",
       "        [0.9638, 0.7500, 0.8151, 0.9616],\n",
       "        [0.0503, 0.0070, 0.4145, 0.2156]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(16,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9826, 0.7057, 0.4725, 0.5816, 0.1636, 0.2196, 0.8620, 0.4628, 0.6589,\n",
      "         0.4870, 0.9997, 0.5431, 0.7703, 0.2417, 0.3230, 0.6452, 0.5115, 0.5316,\n",
      "         0.7312, 0.6976, 0.4326, 0.5961, 0.5460, 0.3598, 0.4004, 0.4848, 0.0859,\n",
      "         0.1078, 0.2560, 0.1734, 0.7836, 0.5910],\n",
      "        [0.4561, 0.6876, 0.0162, 0.1736, 0.4072, 0.4348, 0.3791, 0.9949, 0.6514,\n",
      "         0.0893, 0.0150, 0.7559, 0.6124, 0.8414, 0.7062, 0.7631, 0.7246, 0.1353,\n",
      "         0.6749, 0.0330, 0.7088, 0.1843, 0.4360, 0.4048, 0.9638, 0.7500, 0.8151,\n",
      "         0.9616, 0.0503, 0.0070, 0.4145, 0.2156]])\n",
      "torch.Size([8, 8])\n"
     ]
    }
   ],
   "source": [
    "print(a.view(-1,32))\n",
    "print(a.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9826, 0.7057, 0.4725, 0.5816, 0.1636, 0.2196, 0.8620, 0.4628, 0.6589,\n",
      "         0.4870, 0.9997, 0.5431, 0.7703, 0.2417, 0.3230, 0.6452, 0.5115, 0.5316,\n",
      "         0.7312, 0.6976, 0.4326, 0.5961, 0.5460, 0.3598, 0.4004, 0.4848, 0.0859,\n",
      "         0.1078, 0.2560, 0.1734, 0.7836, 0.5910],\n",
      "        [0.4561, 0.6876, 0.0162, 0.1736, 0.4072, 0.4348, 0.3791, 0.9949, 0.6514,\n",
      "         0.0893, 0.0150, 0.7559, 0.6124, 0.8414, 0.7062, 0.7631, 0.7246, 0.1353,\n",
      "         0.6749, 0.0330, 0.7088, 0.1843, 0.4360, 0.4048, 0.9638, 0.7500, 0.8151,\n",
      "         0.9616, 0.0503, 0.0070, 0.4145, 0.2156]])\n",
      "torch.Size([2, 32])\n"
     ]
    }
   ],
   "source": [
    "a = a.view(-1,32)\n",
    "print(a)\n",
    "print(a.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.numel() # For number of elements in the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9826, 0.4561],\n",
      "        [0.7057, 0.6876],\n",
      "        [0.4725, 0.0162],\n",
      "        [0.5816, 0.1736],\n",
      "        [0.1636, 0.4072],\n",
      "        [0.2196, 0.4348],\n",
      "        [0.8620, 0.3791],\n",
      "        [0.4628, 0.9949],\n",
      "        [0.6589, 0.6514],\n",
      "        [0.4870, 0.0893],\n",
      "        [0.9997, 0.0150],\n",
      "        [0.5431, 0.7559],\n",
      "        [0.7703, 0.6124],\n",
      "        [0.2417, 0.8414],\n",
      "        [0.3230, 0.7062],\n",
      "        [0.6452, 0.7631],\n",
      "        [0.5115, 0.7246],\n",
      "        [0.5316, 0.1353],\n",
      "        [0.7312, 0.6749],\n",
      "        [0.6976, 0.0330],\n",
      "        [0.4326, 0.7088],\n",
      "        [0.5961, 0.1843],\n",
      "        [0.5460, 0.4360],\n",
      "        [0.3598, 0.4048],\n",
      "        [0.4004, 0.9638],\n",
      "        [0.4848, 0.7500],\n",
      "        [0.0859, 0.8151],\n",
      "        [0.1078, 0.9616],\n",
      "        [0.2560, 0.0503],\n",
      "        [0.1734, 0.0070],\n",
      "        [0.7836, 0.4145],\n",
      "        [0.5910, 0.2156]])\n",
      "tensor([[0.9826, 0.4561],\n",
      "        [0.7057, 0.6876],\n",
      "        [0.4725, 0.0162],\n",
      "        [0.5816, 0.1736],\n",
      "        [0.1636, 0.4072],\n",
      "        [0.2196, 0.4348],\n",
      "        [0.8620, 0.3791],\n",
      "        [0.4628, 0.9949],\n",
      "        [0.6589, 0.6514],\n",
      "        [0.4870, 0.0893],\n",
      "        [0.9997, 0.0150],\n",
      "        [0.5431, 0.7559],\n",
      "        [0.7703, 0.6124],\n",
      "        [0.2417, 0.8414],\n",
      "        [0.3230, 0.7062],\n",
      "        [0.6452, 0.7631],\n",
      "        [0.5115, 0.7246],\n",
      "        [0.5316, 0.1353],\n",
      "        [0.7312, 0.6749],\n",
      "        [0.6976, 0.0330],\n",
      "        [0.4326, 0.7088],\n",
      "        [0.5961, 0.1843],\n",
      "        [0.5460, 0.4360],\n",
      "        [0.3598, 0.4048],\n",
      "        [0.4004, 0.9638],\n",
      "        [0.4848, 0.7500],\n",
      "        [0.0859, 0.8151],\n",
      "        [0.1078, 0.9616],\n",
      "        [0.2560, 0.0503],\n",
      "        [0.1734, 0.0070],\n",
      "        [0.7836, 0.4145],\n",
      "        [0.5910, 0.2156]])\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "print(a.T)\n",
    "print(a.t())\n",
    "print((a.t()!=a.T).sum()) # If 0, it means they are equal\n",
    "# Both print transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dot Products and Mult Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= torch.tensor([3,4,5], dtype=torch.float)\n",
    "y = torch.tensor([4,5,6], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12., 20., 30.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mul(y) #x*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12., 20., 30.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(62.)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dot(y) ### 3*4+5*4+6*5 = 12 + 20 + 30 = 62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(62.)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(62.)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dot(y).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix Multiplication\n",
    "x = torch.tensor([[1,4,2],[1,5,5]], dtype=torch.float)\n",
    "y = torch.tensor([[5,7],[8,6],[9,11]], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 4., 2.],\n",
      "        [1., 5., 5.]])\n",
      "tensor([[ 5.,  7.],\n",
      "        [ 8.,  6.],\n",
      "        [ 9., 11.]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[55., 53.],\n",
       "        [90., 92.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[55., 53.],\n",
       "        [90., 92.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[55., 53.],\n",
       "        [90., 92.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x@y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[55., 53.],\n",
       "        [90., 92.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.matmul(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU and GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available() # Checks if GPU is available in your machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.has_mps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If cuda is True\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    x = torch.rand(5, device=device) # Will store the tensor in the GPU\n",
    "    \n",
    "    # For changing location from CPU to GPU\n",
    "    y = torch.rand(5) # Creates a tensor in the CPU\n",
    "    y = y.to(device) # Shifts it to GPU\n",
    "\n",
    "    z = x * y # z will be a tensor in the GPU as x and y are in the GPU\n",
    "    # z.numpy() would return an error as z will be in the GPU\n",
    "    z = z.to('cpu')\n",
    "    a = z.numpy() # This will work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The MPS backend is supported on MacOS 12.3+.Current OS version can be queried using `sw_vers`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/venkatakrishnanvk/Desktop/ML & DL/Deep Learning/Pytorch-Tutorial/Tutorial 2- Understanding Tensors In Pytorch.ipynb Cell 80\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/venkatakrishnanvk/Desktop/ML%20%26%20DL/Deep%20Learning/Pytorch-Tutorial/Tutorial%202-%20Understanding%20Tensors%20In%20Pytorch.ipynb#ch0000079?line=1'>2</a>\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mhas_mps:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/venkatakrishnanvk/Desktop/ML%20%26%20DL/Deep%20Learning/Pytorch-Tutorial/Tutorial%202-%20Understanding%20Tensors%20In%20Pytorch.ipynb#ch0000079?line=2'>3</a>\u001b[0m     device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mmps\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/venkatakrishnanvk/Desktop/ML%20%26%20DL/Deep%20Learning/Pytorch-Tutorial/Tutorial%202-%20Understanding%20Tensors%20In%20Pytorch.ipynb#ch0000079?line=3'>4</a>\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mrand(\u001b[39m5\u001b[39;49m, device\u001b[39m=\u001b[39;49mdevice) \u001b[39m# Will store the tensor in the GPU\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/venkatakrishnanvk/Desktop/ML%20%26%20DL/Deep%20Learning/Pytorch-Tutorial/Tutorial%202-%20Understanding%20Tensors%20In%20Pytorch.ipynb#ch0000079?line=5'>6</a>\u001b[0m     \u001b[39m# For changing location from CPU to GPU\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/venkatakrishnanvk/Desktop/ML%20%26%20DL/Deep%20Learning/Pytorch-Tutorial/Tutorial%202-%20Understanding%20Tensors%20In%20Pytorch.ipynb#ch0000079?line=6'>7</a>\u001b[0m     y \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand(\u001b[39m5\u001b[39m) \u001b[39m# Creates a tensor in the CPU\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The MPS backend is supported on MacOS 12.3+.Current OS version can be queried using `sw_vers`"
     ]
    }
   ],
   "source": [
    "#If mps is true for Mac M1 chip\n",
    "if torch.has_mps:\n",
    "    device = torch.device(\"mps\")\n",
    "    x = torch.rand(5, device=device) # Will store the tensor in the GPU\n",
    "    \n",
    "    # For changing location from CPU to GPU\n",
    "    y = torch.rand(5) # Creates a tensor in the CPU\n",
    "    y = y.to(device) # Shifts it to GPU\n",
    "\n",
    "    z = x * y # z will be a tensor in the GPU as x and y are in the GPU\n",
    "    # z.numpy() would return an error as z will be in the GPU\n",
    "    z = z.to('cpu')\n",
    "    a = z.numpy() # This will work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(10)\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 0.5\n",
    "std_dev = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform1 = transforms.Compose([\n",
    "    transforms.AutoAugment(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean,std_dev)\n",
    "])\n",
    "transform2 = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=(-20, 20)),\n",
    "    transforms.RandomPerspective(distortion_scale=0.3, p=1.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean,std_dev)\n",
    "])\n",
    "transform3 = transforms.Compose([\n",
    "    transforms.AugMix(),\n",
    "    # transforms.RandomCrop(28, 3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean,std_dev)\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean,std_dev)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='../datasets',\n",
    "    train = True,\n",
    "    transform=transform1 #download is False in default\n",
    ")\n",
    "train_data2 = torchvision.datasets.MNIST(\n",
    "    root='../datasets',\n",
    "    train = True,\n",
    "    transform=transform2 #download is False in default\n",
    ")\n",
    "train_data3 = torchvision.datasets.MNIST(\n",
    "    root='../datasets',\n",
    "    train = True,\n",
    "    transform=transform3 #download is False in default\n",
    ")\n",
    "\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root='../datasets',\n",
    "    train = False,\n",
    "    transform=transform_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.__add__(train_data2)\n",
    "train_data = train_data.__add__(train_data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "batch_size = 256\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset = train_data,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset = test_data,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "704"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, label):\n",
    "    img = img * std_dev + mean  # unnormalize\n",
    "    plt.imshow(img.reshape(img.shape[1],img.shape[2],img.shape[0]))\n",
    "    plt.title(f'Label {label}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "imshow(images[2],labels[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 1, 28, 28])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyInceptionNetwork(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(MyInceptionNetwork, self).__init__()\n",
    "        self.conv11 = nn.Conv2d(1,16,3,1,'same')\n",
    "        self.conv12 = nn.Conv2d(1,20,5,1,'same')\n",
    "        self.conv13 = nn.Conv2d(1,12,7,1,'same')\n",
    "\n",
    "        # Adding a Batch norm at every point, brings a HUGE IMPROVEMENT in ACCURACY \n",
    "        self.norm11 = nn.BatchNorm2d(12+20+16)\n",
    "        self.conv1 = nn.Conv2d(12+20+16, 12+20+16, 1, 1) # 28, 28, 48\n",
    "        self.norm12 = nn.BatchNorm2d(12+20+16)\n",
    "\n",
    "        self.conv21 = nn.Conv2d(12+20+16, 64, 3, 2, 1)\n",
    "        self.conv22 = nn.Conv2d(12+20+16, 32, 5, 2, 2)\n",
    "        self.conv23 = nn.Conv2d(12+20+16, 16, 7, 2, 3)\n",
    "\n",
    "        self.conv1to21 = nn.Conv2d(1, 64, 3, 2, 1)\n",
    "        self.conv1to22 = nn.Conv2d(1, 32, 5, 2, 2)\n",
    "        self.conv1to23 = nn.Conv2d(1, 16, 7, 2, 3)\n",
    "        self.norm1to2 = nn.BatchNorm2d(64+32+16)\n",
    "\n",
    "        self.norm21 = nn.BatchNorm2d(64+32+16)\n",
    "        self.conv2 = nn.Conv2d(64+32+16, 64+32+16, 1, 1) # 14, 14, 112\n",
    "        self.norm22 = nn.BatchNorm2d(64+32+16)\n",
    "\n",
    "        self.conv31 = nn.Conv2d(64+32+16, 100, 1, 1, 0)\n",
    "        self.conv32 = nn.Conv2d(64+32+16, 100, 3, 1, 1)\n",
    "        self.conv33 = nn.Conv2d(64+32+16, 50, 5, 1, 2)\n",
    "        self.conv34 = nn.Conv2d(64+32+16, 50, 7, 1, 3)\n",
    "        self.maxpool1 = nn.MaxPool2d(3,1,padding = 1) # Stride = 1\n",
    "        self.conv_maxpool = nn.Conv2d(64+32+16, 32, 1, 1, 0)\n",
    "\n",
    "        self.conv1to31 = nn.Conv2d(1, 116, 3, 2, 1)\n",
    "        self.conv1to32 = nn.Conv2d(1, 116, 5, 2, 2)\n",
    "        self.conv1to33 = nn.Conv2d(1, 100, 7, 2, 3)\n",
    "        self.norm1to3 = nn.BatchNorm2d(332)\n",
    "\n",
    "        self.norm31 = nn.BatchNorm2d(332)\n",
    "        self.conv3 = nn.Conv2d(332, 332, 7, 2) # 4, 4, 332\n",
    "        self.norm32 = nn.BatchNorm2d(332)\n",
    "\n",
    "        self.conv1to4 = nn.Conv2d(1, 332, 9, 5, 0)\n",
    "        self.norm1to4 = nn.BatchNorm2d(332)\n",
    "\n",
    "        self.maxpool_final = nn.MaxPool2d(2,2) # 2, 2, 332\n",
    "\n",
    "        self.linear1 = nn.Linear(332*4,500)\n",
    "        self.norm4 = nn.BatchNorm1d(500)\n",
    "        self.linear2 = nn.Linear(500,100)\n",
    "        self.norm5 = nn.BatchNorm1d(100)\n",
    "        self.linear3 = nn.Linear(100,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_temp = x\n",
    "\n",
    "        x1 = torch.relu(self.conv11(x))\n",
    "        x2 = torch.relu(self.conv12(x))\n",
    "        x3 = torch.relu(self.conv13(x))\n",
    "        x = x1\n",
    "        x = torch.cat((x,x2),1)\n",
    "        x = torch.cat((x,x3),1)\n",
    "\n",
    "        x = self.norm12(torch.relu(self.conv1(self.norm11(x))))\n",
    "\n",
    "        x1 = torch.relu(self.conv21(x))\n",
    "        x2 = torch.relu(self.conv22(x))\n",
    "        x3 = torch.relu(self.conv23(x))\n",
    "        x = x1\n",
    "        x = torch.cat((x,x2),1)\n",
    "        x = torch.cat((x,x3),1)\n",
    "\n",
    "        x_temp1 = torch.relu(self.conv1to21(x_temp))\n",
    "        x_temp1 = torch.cat((x_temp1, torch.relu(self.conv1to22(x_temp))),1)\n",
    "        x_temp1 = torch.cat((x_temp1, torch.relu(self.conv1to23(x_temp))),1)\n",
    "\n",
    "        x = self.norm22(torch.relu(self.conv2(self.norm21(x) + self.norm1to2(x_temp1))))\n",
    "\n",
    "        x1 = torch.relu(self.conv31(x))\n",
    "        x2 = torch.relu(self.conv32(x))\n",
    "        x3 = torch.relu(self.conv33(x))\n",
    "        x4 = torch.relu(self.conv34(x))\n",
    "        x5 = torch.relu(self.conv_maxpool(self.maxpool1(x)))\n",
    "        x = x1\n",
    "        x = torch.cat((x,x2),1)\n",
    "        x = torch.cat((x,x3),1)\n",
    "        x = torch.cat((x,x4),1)\n",
    "        x = torch.cat((x,x5),1)\n",
    "\n",
    "        x_temp1 = torch.relu(self.conv1to31(x_temp))\n",
    "        x_temp1 = torch.cat((x_temp1, torch.relu(self.conv1to32(x_temp))),1)\n",
    "        x_temp1 = torch.cat((x_temp1, torch.relu(self.conv1to33(x_temp))),1)\n",
    "\n",
    "        x = self.maxpool_final(self.norm32(torch.relu(self.conv3(self.norm31(x) + self.norm1to3(x_temp1)))) + self.norm1to4(torch.relu(self.conv1to4(x_temp))))\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.norm4(torch.relu(self.linear1(x)))\n",
    "        x = self.norm5(torch.relu(self.linear2(x)))\n",
    "        x = torch.relu(self.linear3(x))\n",
    "\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "incresnet = MyInceptionNetwork().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(incresnet.parameters(), lr = learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 6, gamma = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 28, 28]             160\n",
      "            Conv2d-2           [-1, 20, 28, 28]             520\n",
      "            Conv2d-3           [-1, 12, 28, 28]             600\n",
      "       BatchNorm2d-4           [-1, 48, 28, 28]              96\n",
      "            Conv2d-5           [-1, 48, 28, 28]           2,352\n",
      "       BatchNorm2d-6           [-1, 48, 28, 28]              96\n",
      "            Conv2d-7           [-1, 64, 14, 14]          27,712\n",
      "            Conv2d-8           [-1, 32, 14, 14]          38,432\n",
      "            Conv2d-9           [-1, 16, 14, 14]          37,648\n",
      "           Conv2d-10           [-1, 64, 14, 14]             640\n",
      "           Conv2d-11           [-1, 32, 14, 14]             832\n",
      "           Conv2d-12           [-1, 16, 14, 14]             800\n",
      "      BatchNorm2d-13          [-1, 112, 14, 14]             224\n",
      "      BatchNorm2d-14          [-1, 112, 14, 14]             224\n",
      "           Conv2d-15          [-1, 112, 14, 14]          12,656\n",
      "      BatchNorm2d-16          [-1, 112, 14, 14]             224\n",
      "           Conv2d-17          [-1, 100, 14, 14]          11,300\n",
      "           Conv2d-18          [-1, 100, 14, 14]         100,900\n",
      "           Conv2d-19           [-1, 50, 14, 14]         140,050\n",
      "           Conv2d-20           [-1, 50, 14, 14]         274,450\n",
      "        MaxPool2d-21          [-1, 112, 14, 14]               0\n",
      "           Conv2d-22           [-1, 32, 14, 14]           3,616\n",
      "           Conv2d-23          [-1, 116, 14, 14]           1,160\n",
      "           Conv2d-24          [-1, 116, 14, 14]           3,016\n",
      "           Conv2d-25          [-1, 100, 14, 14]           5,000\n",
      "      BatchNorm2d-26          [-1, 332, 14, 14]             664\n",
      "      BatchNorm2d-27          [-1, 332, 14, 14]             664\n",
      "           Conv2d-28            [-1, 332, 4, 4]       5,401,308\n",
      "      BatchNorm2d-29            [-1, 332, 4, 4]             664\n",
      "           Conv2d-30            [-1, 332, 4, 4]          27,224\n",
      "      BatchNorm2d-31            [-1, 332, 4, 4]             664\n",
      "        MaxPool2d-32            [-1, 332, 2, 2]               0\n",
      "           Linear-33                  [-1, 500]         664,500\n",
      "      BatchNorm1d-34                  [-1, 500]           1,000\n",
      "           Linear-35                  [-1, 100]          50,100\n",
      "      BatchNorm1d-36                  [-1, 100]             200\n",
      "           Linear-37                   [-1, 10]           1,010\n",
      "================================================================\n",
      "Total params: 6,810,706\n",
      "Trainable params: 6,810,706\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 4.49\n",
      "Params size (MB): 25.98\n",
      "Estimated Total Size (MB): 30.47\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(copy.deepcopy(incresnet).to('cpu'), (1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30; Loss = 0.015077; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Dev Accuracy: 99.32%\n",
      "--------------------\n",
      "Epoch 2/30; Loss = 0.014864; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Dev Accuracy: 99.40%\n",
      "--------------------\n",
      "Epoch 3/30; Loss = 0.025940; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Dev Accuracy: 99.47%\n",
      "--------------------\n",
      "Epoch 4/30; Loss = 0.011238; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Dev Accuracy: 99.53%\n",
      "--------------------\n",
      "Epoch 5/30; Loss = 0.002295; LR = [0.001]\n",
      "Dev Accuracy: 99.47%\n",
      "--------------------\n",
      "Epoch 6/30; Loss = 0.003049; LR = [0.0005]\n",
      "SAVED MODEL WEIGHTS\n",
      "Dev Accuracy: 99.62%\n",
      "--------------------\n",
      "Epoch 7/30; Loss = 0.003358; LR = [0.0005]\n",
      "SAVED MODEL WEIGHTS\n",
      "Dev Accuracy: 99.62%\n",
      "--------------------\n",
      "Epoch 8/30; Loss = 0.003144; LR = [0.0005]\n",
      "Dev Accuracy: 99.57%\n",
      "--------------------\n",
      "Epoch 9/30; Loss = 0.001278; LR = [0.0005]\n",
      "Dev Accuracy: 99.58%\n",
      "--------------------\n",
      "Epoch 10/30; Loss = 0.001100; LR = [0.0005]\n",
      "Train Accuracy: 99.58%\n",
      "Dev Accuracy: 99.59%\n",
      "--------------------\n",
      "Epoch 11/30; Loss = 0.001459; LR = [0.0005]\n",
      "Dev Accuracy: 99.60%\n",
      "--------------------\n",
      "Epoch 12/30; Loss = 0.109643; LR = [0.00025]\n",
      "Dev Accuracy: 99.57%\n",
      "--------------------\n",
      "Epoch 13/30; Loss = 0.000228; LR = [0.00025]\n",
      "SAVED MODEL WEIGHTS\n",
      "Dev Accuracy: 99.68%\n",
      "--------------------\n",
      "Epoch 14/30; Loss = 0.017753; LR = [0.00025]\n",
      "Dev Accuracy: 99.64%\n",
      "--------------------\n",
      "Epoch 15/30; Loss = 0.000563; LR = [0.00025]\n",
      "Dev Accuracy: 99.61%\n",
      "--------------------\n",
      "Epoch 16/30; Loss = 0.000136; LR = [0.00025]\n",
      "Dev Accuracy: 99.66%\n",
      "--------------------\n",
      "Epoch 17/30; Loss = 0.000092; LR = [0.00025]\n",
      "Dev Accuracy: 99.66%\n",
      "--------------------\n",
      "Epoch 18/30; Loss = 0.008177; LR = [0.000125]\n",
      "Dev Accuracy: 99.65%\n",
      "--------------------\n",
      "Epoch 19/30; Loss = 0.000110; LR = [0.000125]\n",
      "Dev Accuracy: 99.66%\n",
      "--------------------\n",
      "Epoch 20/30; Loss = 0.000270; LR = [0.000125]\n",
      "Train Accuracy: 99.82%\n",
      "Dev Accuracy: 99.67%\n",
      "--------------------\n",
      "Epoch 21/30; Loss = 0.000109; LR = [0.000125]\n",
      "Dev Accuracy: 99.63%\n",
      "--------------------\n",
      "Epoch 22/30; Loss = 0.000146; LR = [0.000125]\n",
      "SAVED MODEL WEIGHTS\n",
      "Dev Accuracy: 99.68%\n",
      "--------------------\n",
      "Epoch 23/30; Loss = 0.000088; LR = [0.000125]\n",
      "Dev Accuracy: 99.67%\n",
      "--------------------\n",
      "Epoch 24/30; Loss = 0.009569; LR = [6.25e-05]\n",
      "Dev Accuracy: 99.60%\n",
      "--------------------\n",
      "Epoch 25/30; Loss = 0.000273; LR = [6.25e-05]\n",
      "Dev Accuracy: 99.66%\n",
      "--------------------\n",
      "Epoch 26/30; Loss = 0.010382; LR = [6.25e-05]\n",
      "Dev Accuracy: 99.66%\n",
      "--------------------\n",
      "Epoch 27/30; Loss = 0.007748; LR = [6.25e-05]\n",
      "Dev Accuracy: 99.66%\n",
      "--------------------\n",
      "Epoch 28/30; Loss = 0.000804; LR = [6.25e-05]\n",
      "Dev Accuracy: 99.62%\n",
      "--------------------\n",
      "Epoch 29/30; Loss = 0.002411; LR = [6.25e-05]\n",
      "Dev Accuracy: 99.66%\n",
      "--------------------\n",
      "Epoch 30/30; Loss = 0.000969; LR = [3.125e-05]\n",
      "Train Accuracy: 99.87%\n",
      "Dev Accuracy: 99.63%\n",
      "--------------------\n",
      "Finished Training!\n",
      "Best Test Accuracy = 99.68%\n",
      "Time Taken = 1014.0m 16.875693798065186s\n"
     ]
    }
   ],
   "source": [
    "best_weights = copy.deepcopy(incresnet.state_dict())\n",
    "max = 0\n",
    "val_acc = 0\n",
    "train_acc = 0\n",
    "tic = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    incresnet.train()\n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        preds = incresnet.forward(images)\n",
    "        loss = criterion(preds, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step() # Decaying learning rate per 25 epochs by 0.2 times\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}; Loss = {loss.item():.6f}; LR = {scheduler.get_last_lr()}')\n",
    "    with torch.no_grad():\n",
    "        n_samples = 0\n",
    "        n_correct = 0\n",
    "        incresnet.eval()\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device) # From 128, 1, 28, 28 ---> 128, 784\n",
    "            labels = labels.to(device)\n",
    "            pred_outputs1 = incresnet(images)\n",
    "            _, actual_preds1 = torch.max(pred_outputs1, 1) # Returns value, index\n",
    "            n_samples += labels.shape[0]\n",
    "            n_correct += (actual_preds1 == labels).sum().item()\n",
    "        val_acc = n_correct/n_samples * 100\n",
    "\n",
    "        if (max <= (n_correct/n_samples * 100)):\n",
    "            print('SAVED MODEL WEIGHTS')\n",
    "            max = val_acc\n",
    "            best_weights = copy.deepcopy(incresnet.state_dict())\n",
    "        \n",
    "        if((epoch+1) % 10 == 0):\n",
    "            n_samples = 0\n",
    "            n_correct = 0\n",
    "            \n",
    "            for images, labels in train_loader:\n",
    "                images = images.to(device) # From 128, 1, 28, 28 ---> 128, 784\n",
    "                labels = labels.to(device)\n",
    "                pred_outputs1 = incresnet(images)\n",
    "                _, actual_preds1 = torch.max(pred_outputs1, 1) # Returns value, index\n",
    "                n_samples += labels.shape[0]\n",
    "                n_correct += (actual_preds1 == labels).sum().item()\n",
    "            train_acc = n_correct/n_samples * 100\n",
    "            print(f'Train Accuracy: {train_acc:.2f}%')\n",
    "    print(f'Dev Accuracy: {val_acc:.2f}%')\n",
    "    print(\"-\"*20)\n",
    "print('Finished Training!')\n",
    "print(f'Best Test Accuracy = {max}%')\n",
    "print(f'Time Taken = {(time.time()-tic)//60}m {(time.time()-tic)%60}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No big improvement as such. slight reduction in performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "incresnet.load_state_dict(best_weights)\n",
    "torch.save(incresnet, 'models/newincresnet_with_data_augmentation_mnist.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "193f6b5c64d175a70f8bc370a8e28557b54eddf9787b8dde324aa4d68183bc16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

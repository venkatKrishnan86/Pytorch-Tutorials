{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(10)\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 0.5\n",
    "std_dev = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform1 = transforms.Compose([\n",
    "    transforms.AutoAugment(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean,std_dev)\n",
    "])\n",
    "transform2 = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=(-20, 20)),\n",
    "    transforms.RandomPerspective(distortion_scale=0.3, p=1.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean,std_dev)\n",
    "])\n",
    "transform3 = transforms.Compose([\n",
    "    transforms.AugMix(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean,std_dev)\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean,std_dev)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='../datasets',\n",
    "    train = True,\n",
    "    transform=transform1 #download is False in default\n",
    ")\n",
    "train_data2 = torchvision.datasets.MNIST(\n",
    "    root='../datasets',\n",
    "    train = True,\n",
    "    transform=transform2 #download is False in default\n",
    ")\n",
    "train_data3 = torchvision.datasets.MNIST(\n",
    "    root='datasets',\n",
    "    train = True,\n",
    "    transform=transform3 #download is False in default\n",
    ")\n",
    "\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root='datasets',\n",
    "    train = False,\n",
    "    transform=transform_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.__add__(train_data2)\n",
    "train_data = train_data.__add__(train_data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "batch_size = 512\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset = train_data,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset = test_data,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, label):\n",
    "    img = img * std_dev + mean  # unnormalize\n",
    "    plt.imshow(img.reshape(img.shape[1],img.shape[2],img.shape[0]), cmap = 'gray')\n",
    "    plt.title(f'Label {label}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "imshow(images[2],labels[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 1, 28, 28])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myResNet(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(myResNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1,4,5,1,'same') # 4, 28, 28\n",
    "        # self.act1_1 = nn.ReLU() \n",
    "        self.norm1 = nn.BatchNorm2d(4)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(4,16,5,1,'same') # 16, 28, 28\n",
    "        self.conv1to2 = nn.Conv2d(1,16,3,1,'same') # 16, 28, 28\n",
    "        # self.act1_2 = nn.ReLU()\n",
    "        self.norm2 = nn.BatchNorm2d(16)\n",
    "            \n",
    "        self.pool1 = nn.MaxPool2d(2, 2) # 16, 28, 28 --> 16, 14, 14\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(16,64,3,1,'same') # 64, 14, 14\n",
    "        self.conv1to3 = nn.Conv2d(1,64,3,2,1) # 64, 14, 14\n",
    "        # self.act2_1 = nn.ReLU()\n",
    "        self.norm3 = nn.BatchNorm2d(64)\n",
    "            \n",
    "        self.conv4 = nn.Conv2d(64,256,3,1,'same')  # 256, 14, 14\n",
    "        self.conv1to4 = nn.Conv2d(1,256,3,2,1) # 256, 14, 14\n",
    "        # self.act2_2 = nn.ReLU()\n",
    "        self.norm4 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.pool2 = nn.MaxPool2d(2, 2) # 256, 14, 14 --> 256, 7, 7\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.lin5 = nn.Linear(256*7*7, 200)\n",
    "        self.lin1to5 = nn.Linear(28*28*1, 200)\n",
    "        # self.act4 = nn.ReLU()\n",
    "        self.norm5 = nn.BatchNorm1d(200)\n",
    "\n",
    "        self.lin6 = nn.Linear(200, 85)\n",
    "        self.lin1to6 = nn.Linear(28*28*1, 85)\n",
    "        # self.act5 = nn.ReLU()\n",
    "        self.norm6 = nn.BatchNorm1d(85)\n",
    "\n",
    "        self.lin_fin = nn.Linear(85,10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_temp1 = x\n",
    "        x = self.norm1(torch.relu(self.conv1(x)))\n",
    "        \n",
    "        x_temp2 = x\n",
    "        x = self.norm2(torch.relu(self.conv2(x)+self.conv1to2(x_temp1))) # Residual\n",
    "\n",
    "        x_temp3 = x\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.norm3(torch.relu(self.conv3(x)+self.conv1to3(x_temp1)))\n",
    "\n",
    "        x_temp4 = x\n",
    "        x = self.norm4(torch.relu(self.conv4(x)+self.conv1to4(x_temp1))) # Residual\n",
    "\n",
    "        x_temp5 = x\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.norm5(torch.relu(self.lin5(x)+self.lin1to5(self.flatten(x_temp1))))\n",
    "\n",
    "        x_temp6 = x\n",
    "        x = self.norm6(torch.relu(self.lin6(x)+self.lin1to6(self.flatten(x_temp1))))\n",
    "        x = self.lin_fin(x)\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = myResNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(resnet.parameters(), lr = learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 9, gamma = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "The operator 'aten::_slow_conv2d_forward' is not current implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/venkatakrishnanvk/Desktop/ML & DL/Deep Learning/Pytorch-Tutorial/Tutorial 13.2 - FN-Residual Networks with Data Augmentation.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/venkatakrishnanvk/Desktop/ML%20%26%20DL/Deep%20Learning/Pytorch-Tutorial/Tutorial%2013.2%20-%20FN-Residual%20Networks%20with%20Data%20Augmentation.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m summary(resnet, (\u001b[39m1\u001b[39;49m,\u001b[39m28\u001b[39;49m,\u001b[39m28\u001b[39;49m))\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torchsummary/torchsummary.py:72\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     68\u001b[0m model\u001b[39m.\u001b[39mapply(register_hook)\n\u001b[1;32m     70\u001b[0m \u001b[39m# make a forward pass\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m# print(x.shape)\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m model(\u001b[39m*\u001b[39;49mx)\n\u001b[1;32m     74\u001b[0m \u001b[39m# remove these hooks\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[39mfor\u001b[39;00m h \u001b[39min\u001b[39;00m hooks:\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/venkatakrishnanvk/Desktop/ML & DL/Deep Learning/Pytorch-Tutorial/Tutorial 13.2 - FN-Residual Networks with Data Augmentation.ipynb Cell 19\u001b[0m in \u001b[0;36mmyResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/venkatakrishnanvk/Desktop/ML%20%26%20DL/Deep%20Learning/Pytorch-Tutorial/Tutorial%2013.2%20-%20FN-Residual%20Networks%20with%20Data%20Augmentation.ipynb#X23sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/venkatakrishnanvk/Desktop/ML%20%26%20DL/Deep%20Learning/Pytorch-Tutorial/Tutorial%2013.2%20-%20FN-Residual%20Networks%20with%20Data%20Augmentation.ipynb#X23sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     x_temp1 \u001b[39m=\u001b[39m x\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/venkatakrishnanvk/Desktop/ML%20%26%20DL/Deep%20Learning/Pytorch-Tutorial/Tutorial%2013.2%20-%20FN-Residual%20Networks%20with%20Data%20Augmentation.ipynb#X23sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(torch\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/venkatakrishnanvk/Desktop/ML%20%26%20DL/Deep%20Learning/Pytorch-Tutorial/Tutorial%2013.2%20-%20FN-Residual%20Networks%20with%20Data%20Augmentation.ipynb#X23sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     x_temp2 \u001b[39m=\u001b[39m x\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/venkatakrishnanvk/Desktop/ML%20%26%20DL/Deep%20Learning/Pytorch-Tutorial/Tutorial%2013.2%20-%20FN-Residual%20Networks%20with%20Data%20Augmentation.ipynb#X23sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(torch\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x)\u001b[39m+\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1to2(x_temp1))) \u001b[39m# Residual\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/module.py:1148\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks)\n\u001b[1;32m   1146\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(\u001b[39minput\u001b[39m)\n\u001b[0;32m-> 1148\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1149\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1150\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m (\u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mvalues(), \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 457\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/nn/modules/conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    450\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    451\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    452\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 453\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    454\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: The operator 'aten::_slow_conv2d_forward' is not current implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS."
     ]
    }
   ],
   "source": [
    "summary(resnet, (1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50; Loss = 0.058808; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 97.85%\n",
      "Dev Accuracy: 98.91%\n",
      "--------------------\n",
      "Epoch 2/50; Loss = 0.018057; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 98.59%\n",
      "Dev Accuracy: 99.02%\n",
      "--------------------\n",
      "Epoch 3/50; Loss = 0.023208; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 98.97%\n",
      "Dev Accuracy: 99.16%\n",
      "--------------------\n",
      "Epoch 4/50; Loss = 0.042027; LR = [0.001]\n",
      "Train Accuracy: 98.34%\n",
      "Dev Accuracy: 98.79%\n",
      "--------------------\n",
      "Epoch 5/50; Loss = 0.034740; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.13%\n",
      "Dev Accuracy: 99.28%\n",
      "--------------------\n",
      "Epoch 6/50; Loss = 0.018935; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.29%\n",
      "Dev Accuracy: 99.29%\n",
      "--------------------\n",
      "Epoch 7/50; Loss = 0.057783; LR = [0.001]\n",
      "Train Accuracy: 98.30%\n",
      "Dev Accuracy: 99.06%\n",
      "--------------------\n",
      "Epoch 8/50; Loss = 0.037227; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.41%\n",
      "Dev Accuracy: 99.40%\n",
      "--------------------\n",
      "Epoch 9/50; Loss = 0.014885; LR = [0.0005]\n",
      "Train Accuracy: 99.48%\n",
      "Dev Accuracy: 99.33%\n",
      "--------------------\n",
      "Epoch 10/50; Loss = 0.004668; LR = [0.0005]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.72%\n",
      "Dev Accuracy: 99.53%\n",
      "--------------------\n",
      "Epoch 11/50; Loss = 0.010917; LR = [0.0005]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.69%\n",
      "Dev Accuracy: 99.54%\n",
      "--------------------\n",
      "Epoch 12/50; Loss = 0.002157; LR = [0.0005]\n",
      "Train Accuracy: 99.74%\n",
      "Dev Accuracy: 99.47%\n",
      "--------------------\n",
      "Epoch 13/50; Loss = 0.006697; LR = [0.0005]\n",
      "Train Accuracy: 99.74%\n",
      "Dev Accuracy: 99.52%\n",
      "--------------------\n",
      "Epoch 14/50; Loss = 0.003920; LR = [0.0005]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.74%\n",
      "Dev Accuracy: 99.54%\n",
      "--------------------\n",
      "Epoch 15/50; Loss = 0.007763; LR = [0.0005]\n",
      "Train Accuracy: 99.70%\n",
      "Dev Accuracy: 99.50%\n",
      "--------------------\n",
      "Epoch 16/50; Loss = 0.004142; LR = [0.0005]\n",
      "Train Accuracy: 99.77%\n",
      "Dev Accuracy: 99.50%\n",
      "--------------------\n",
      "Epoch 17/50; Loss = 0.003160; LR = [0.0005]\n",
      "Train Accuracy: 99.66%\n",
      "Dev Accuracy: 99.39%\n",
      "--------------------\n",
      "Epoch 18/50; Loss = 0.009608; LR = [0.00025]\n",
      "Train Accuracy: 99.66%\n",
      "Dev Accuracy: 99.44%\n",
      "--------------------\n",
      "Epoch 19/50; Loss = 0.001180; LR = [0.00025]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.83%\n",
      "Dev Accuracy: 99.56%\n",
      "--------------------\n",
      "Epoch 20/50; Loss = 0.008929; LR = [0.00025]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.85%\n",
      "Dev Accuracy: 99.56%\n",
      "--------------------\n",
      "Epoch 21/50; Loss = 0.002664; LR = [0.00025]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.85%\n",
      "Dev Accuracy: 99.59%\n",
      "--------------------\n",
      "Epoch 22/50; Loss = 0.000696; LR = [0.00025]\n",
      "Train Accuracy: 99.83%\n",
      "Dev Accuracy: 99.51%\n",
      "--------------------\n",
      "Epoch 23/50; Loss = 0.001548; LR = [0.00025]\n",
      "Train Accuracy: 99.86%\n",
      "Dev Accuracy: 99.52%\n",
      "--------------------\n",
      "Epoch 24/50; Loss = 0.003776; LR = [0.00025]\n",
      "Train Accuracy: 99.81%\n",
      "Dev Accuracy: 99.45%\n",
      "--------------------\n",
      "Epoch 25/50; Loss = 0.000292; LR = [0.00025]\n",
      "Train Accuracy: 99.87%\n",
      "Dev Accuracy: 99.53%\n",
      "--------------------\n",
      "Epoch 26/50; Loss = 0.008090; LR = [0.00025]\n",
      "Train Accuracy: 99.86%\n",
      "Dev Accuracy: 99.51%\n",
      "--------------------\n",
      "Epoch 27/50; Loss = 0.000225; LR = [0.000125]\n",
      "Train Accuracy: 99.86%\n",
      "Dev Accuracy: 99.57%\n",
      "--------------------\n",
      "Epoch 28/50; Loss = 0.012639; LR = [0.000125]\n",
      "Train Accuracy: 99.89%\n",
      "Dev Accuracy: 99.53%\n",
      "--------------------\n",
      "Epoch 29/50; Loss = 0.000074; LR = [0.000125]\n",
      "Train Accuracy: 99.89%\n",
      "Dev Accuracy: 99.49%\n",
      "--------------------\n",
      "Epoch 30/50; Loss = 0.002470; LR = [0.000125]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.90%\n",
      "Dev Accuracy: 99.59%\n",
      "--------------------\n",
      "Epoch 31/50; Loss = 0.017960; LR = [0.000125]\n",
      "Train Accuracy: 99.90%\n",
      "Dev Accuracy: 99.54%\n",
      "--------------------\n",
      "Epoch 32/50; Loss = 0.003195; LR = [0.000125]\n",
      "Train Accuracy: 99.91%\n",
      "Dev Accuracy: 99.52%\n",
      "--------------------\n",
      "Epoch 33/50; Loss = 0.000790; LR = [0.000125]\n",
      "Train Accuracy: 99.91%\n",
      "Dev Accuracy: 99.56%\n",
      "--------------------\n",
      "Epoch 34/50; Loss = 0.008077; LR = [0.000125]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.90%\n",
      "Dev Accuracy: 99.61%\n",
      "--------------------\n",
      "Epoch 35/50; Loss = 0.000744; LR = [0.000125]\n",
      "Train Accuracy: 99.92%\n",
      "Dev Accuracy: 99.57%\n",
      "--------------------\n",
      "Epoch 36/50; Loss = 0.001243; LR = [6.25e-05]\n",
      "Train Accuracy: 99.92%\n",
      "Dev Accuracy: 99.59%\n",
      "--------------------\n",
      "Epoch 37/50; Loss = 0.000253; LR = [6.25e-05]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.92%\n",
      "Dev Accuracy: 99.64%\n",
      "--------------------\n",
      "Epoch 38/50; Loss = 0.000220; LR = [6.25e-05]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.93%\n",
      "Dev Accuracy: 99.64%\n",
      "--------------------\n",
      "Epoch 39/50; Loss = 0.013889; LR = [6.25e-05]\n",
      "Train Accuracy: 99.92%\n",
      "Dev Accuracy: 99.61%\n",
      "--------------------\n",
      "Epoch 40/50; Loss = 0.000562; LR = [6.25e-05]\n",
      "Train Accuracy: 99.93%\n",
      "Dev Accuracy: 99.62%\n",
      "--------------------\n",
      "Epoch 41/50; Loss = 0.000520; LR = [6.25e-05]\n",
      "Train Accuracy: 99.94%\n",
      "Dev Accuracy: 99.58%\n",
      "--------------------\n",
      "Epoch 42/50; Loss = 0.003861; LR = [6.25e-05]\n",
      "Train Accuracy: 99.93%\n",
      "Dev Accuracy: 99.58%\n",
      "--------------------\n",
      "Epoch 43/50; Loss = 0.004969; LR = [6.25e-05]\n",
      "Train Accuracy: 99.94%\n",
      "Dev Accuracy: 99.59%\n",
      "--------------------\n",
      "Epoch 44/50; Loss = 0.000612; LR = [6.25e-05]\n",
      "Train Accuracy: 99.92%\n",
      "Dev Accuracy: 99.57%\n",
      "--------------------\n",
      "Epoch 45/50; Loss = 0.000375; LR = [3.125e-05]\n",
      "Train Accuracy: 99.94%\n",
      "Dev Accuracy: 99.61%\n",
      "--------------------\n",
      "Epoch 46/50; Loss = 0.003061; LR = [3.125e-05]\n",
      "Train Accuracy: 99.94%\n",
      "Dev Accuracy: 99.57%\n",
      "--------------------\n",
      "Epoch 47/50; Loss = 0.000333; LR = [3.125e-05]\n",
      "Train Accuracy: 99.93%\n",
      "Dev Accuracy: 99.60%\n",
      "--------------------\n",
      "Epoch 48/50; Loss = 0.000085; LR = [3.125e-05]\n",
      "Train Accuracy: 99.94%\n",
      "Dev Accuracy: 99.58%\n",
      "--------------------\n",
      "Epoch 49/50; Loss = 0.000302; LR = [3.125e-05]\n",
      "Train Accuracy: 99.94%\n",
      "Dev Accuracy: 99.56%\n",
      "--------------------\n",
      "Epoch 50/50; Loss = 0.013291; LR = [3.125e-05]\n",
      "Train Accuracy: 99.94%\n",
      "Dev Accuracy: 99.60%\n",
      "--------------------\n",
      "Finished Training!\n",
      "Best Test Accuracy = 99.64\n",
      "Time Taken = 175.0m 16.69494891166687s\n"
     ]
    }
   ],
   "source": [
    "best_weights = copy.deepcopy(resnet.state_dict())\n",
    "max = 0\n",
    "val_acc = 0\n",
    "train_acc = 0\n",
    "tic = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    resnet.train()\n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        preds = resnet.forward(images)\n",
    "        loss = criterion(preds, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step() # Decaying learning rate per 25 epochs by 0.2 times\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}; Loss = {loss.item():.6f}; LR = {scheduler.get_last_lr()}')\n",
    "    with torch.no_grad():\n",
    "        n_samples = 0\n",
    "        n_correct = 0\n",
    "        resnet.eval()\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device) # From 128, 1, 28, 28 ---> 128, 784\n",
    "            labels = labels.to(device)\n",
    "            pred_outputs1 = resnet(images)\n",
    "            _, actual_preds1 = torch.max(pred_outputs1, 1) # Returns value, index\n",
    "            n_samples += labels.shape[0]\n",
    "            n_correct += (actual_preds1 == labels).sum().item()\n",
    "        val_acc = n_correct/n_samples * 100\n",
    "\n",
    "        if (max <= (n_correct/n_samples * 100)):\n",
    "            print('SAVED MODEL WEIGHTS')\n",
    "            max = val_acc\n",
    "            best_weights = copy.deepcopy(resnet.state_dict())\n",
    "\n",
    "        n_samples = 0\n",
    "        n_correct = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device) # From 128, 1, 28, 28 ---> 128, 784\n",
    "            labels = labels.to(device)\n",
    "            pred_outputs1 = resnet(images)\n",
    "            _, actual_preds1 = torch.max(pred_outputs1, 1) # Returns value, index\n",
    "            n_samples += labels.shape[0]\n",
    "            n_correct += (actual_preds1 == labels).sum().item()\n",
    "        train_acc = n_correct/n_samples * 100\n",
    "    \n",
    "    print(f'Train Accuracy: {train_acc:.2f}%')\n",
    "    print(f'Dev Accuracy: {val_acc:.2f}%')\n",
    "    print(\"-\"*20)\n",
    "print('Finished Training!')\n",
    "print(f'Best Test Accuracy = {max}')\n",
    "print(f'Time Taken = {(time.time()-tic)//60}m {(time.time()-tic)%60}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet.load_state_dict(best_weights)\n",
    "# torch.save(resnet, 'models/fully_nested_resnet_mnist.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected ResNet with Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullNestedResNet(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(FullNestedResNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1,4,5,1,'same') # 4, 28, 28\n",
    "        # self.act1 = nn.ReLU() \n",
    "        self.norm1 = nn.BatchNorm2d(4)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(4,16,5,1,'same') # 16, 28, 28\n",
    "        self.conv1to2 = nn.Conv2d(1,16,3,1,'same') # 16, 28, 28\n",
    "        self.norm1to2 = nn.BatchNorm2d(16)\n",
    "        # self.act2 = nn.ReLU()\n",
    "        self.norm2 = nn.BatchNorm2d(16)\n",
    "            \n",
    "        self.pool1 = nn.MaxPool2d(2, 2) # 16, 28, 28 --> 16, 14, 14\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(16,64,3,1,'same') # 64, 14, 14\n",
    "        self.conv1to3 = nn.Conv2d(1,64,3,2,1) # 64, 14, 14\n",
    "        self.norm1to3 = nn.BatchNorm2d(64) # 64, 14, 14\n",
    "\n",
    "        self.conv2to3 = nn.Conv2d(4,64,3,2,1)\n",
    "        self.norm2to3 = nn.BatchNorm2d(64)\n",
    "\n",
    "        # self.act3 = nn.ReLU()\n",
    "        self.norm3 = nn.BatchNorm2d(64)\n",
    "            \n",
    "        self.conv4 = nn.Conv2d(64,256,3,1,'same')  # 256, 14, 14\n",
    "        self.conv1to4 = nn.Conv2d(1,256,3,2,1) # 256, 14, 14\n",
    "        self.norm1to4 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.conv2to4 = nn.Conv2d(4,256,3,2,1) # 256, 14, 14\n",
    "        self.norm2to4 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.conv3to4 = nn.Conv2d(16,256,3,1,1) # 256, 14, 14 # Stride = 1\n",
    "        self.norm3to4 = nn.BatchNorm2d(256)\n",
    "\n",
    "        # self.act4 = nn.ReLU()\n",
    "        self.norm4 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.pool2 = nn.MaxPool2d(2, 2) # 256, 14, 14 --> 256, 7, 7\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.lin5 = nn.Linear(256*7*7, 200)\n",
    "        self.lin1to5 = nn.Linear(28*28*1, 200)\n",
    "        self.norm1to5 = nn.BatchNorm1d(200)\n",
    "\n",
    "        self.lin2to5 = nn.Linear(28*28*4, 200)\n",
    "        self.norm2to5 = nn.BatchNorm1d(200)\n",
    "\n",
    "        self.lin3to5 = nn.Linear(14*14*16, 200)\n",
    "        self.norm3to5 = nn.BatchNorm1d(200)\n",
    "\n",
    "        self.lin4to5 = nn.Linear(14*14*64, 200)\n",
    "        self.norm4to5 = nn.BatchNorm1d(200)\n",
    "        # self.act4 = nn.ReLU()\n",
    "        self.norm5 = nn.BatchNorm1d(200)\n",
    "\n",
    "        self.lin6 = nn.Linear(200, 85)\n",
    "        self.lin1to6 = nn.Linear(28*28*1, 85)\n",
    "        self.norm1to6 = nn.BatchNorm1d(85)\n",
    "\n",
    "        self.lin2to6 = nn.Linear(28*28*4, 85)\n",
    "        self.norm2to6 = nn.BatchNorm1d(85)\n",
    "\n",
    "        self.lin3to6 = nn.Linear(14*14*16, 85)\n",
    "        self.norm3to6 = nn.BatchNorm1d(85)\n",
    "\n",
    "        self.lin4to6 = nn.Linear(14*14*64, 85)\n",
    "        self.norm4to6 = nn.BatchNorm1d(85)\n",
    "\n",
    "        self.lin5to6 = nn.Linear(7*7*256, 85)\n",
    "        self.norm5to6 = nn.BatchNorm1d(85)\n",
    "        # self.act5 = nn.ReLU()\n",
    "        self.norm6 = nn.BatchNorm1d(85)\n",
    "\n",
    "        self.lin_fin = nn.Linear(85,10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_temp1 = x\n",
    "        x = self.norm1(torch.relu(self.conv1(x)))\n",
    "        \n",
    "        x_temp2 = x\n",
    "        x = self.conv2(x) + self.norm1to2(self.conv1to2(x_temp1))\n",
    "        x = self.norm2(torch.relu(x)) # Residual\n",
    "\n",
    "        x = self.pool1(x)\n",
    "        x_temp3 = x\n",
    "\n",
    "        x = self.conv3(x) + self.norm1to3(self.conv1to3(x_temp1)) + self.norm2to3(self.conv2to3(x_temp2))\n",
    "        x = self.norm3(torch.relu(x))\n",
    "\n",
    "        x_temp4 = x\n",
    "\n",
    "        x = self.conv4(x) + self.norm1to4(self.conv1to4(x_temp1)) + self.norm2to4(self.conv2to4(x_temp2)) + self.norm3to4(self.conv3to4(x_temp3))\n",
    "        x = self.norm4(torch.relu(x)) # Residual\n",
    "\n",
    "        x = self.pool2(x)\n",
    "        x_temp5 = x\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.lin5(x) + self.norm1to5(self.lin1to5(self.flatten(x_temp1))) + self.norm2to5(self.lin2to5(self.flatten(x_temp2))) + self.norm3to5(self.lin3to5(self.flatten(x_temp3))) + self.norm4to5(self.lin4to5(self.flatten(x_temp4)))\n",
    "        x = self.norm5(torch.relu(x))\n",
    "\n",
    "        x = self.lin6(x) + self.norm1to6(self.lin1to6(self.flatten(x_temp1))) + self.norm2to6(self.lin2to6(self.flatten(x_temp2))) + self.norm3to6(self.lin3to6(self.flatten(x_temp3))) + self.norm4to6(self.lin4to6(self.flatten(x_temp4))) + self.norm5to6(self.lin5to6(self.flatten(x_temp5)))\n",
    "        x = self.norm6(torch.relu(x))\n",
    "        x = self.lin_fin(x)\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullresnet = FullNestedResNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(fullresnet.parameters(), lr = learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 9, gamma = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 4, 28, 28]             104\n",
      "       BatchNorm2d-2            [-1, 4, 28, 28]               8\n",
      "            Conv2d-3           [-1, 16, 28, 28]           1,616\n",
      "            Conv2d-4           [-1, 16, 28, 28]             160\n",
      "       BatchNorm2d-5           [-1, 16, 28, 28]              32\n",
      "       BatchNorm2d-6           [-1, 16, 28, 28]              32\n",
      "         MaxPool2d-7           [-1, 16, 14, 14]               0\n",
      "            Conv2d-8           [-1, 64, 14, 14]           9,280\n",
      "            Conv2d-9           [-1, 64, 14, 14]             640\n",
      "      BatchNorm2d-10           [-1, 64, 14, 14]             128\n",
      "           Conv2d-11           [-1, 64, 14, 14]           2,368\n",
      "      BatchNorm2d-12           [-1, 64, 14, 14]             128\n",
      "      BatchNorm2d-13           [-1, 64, 14, 14]             128\n",
      "           Conv2d-14          [-1, 256, 14, 14]         147,712\n",
      "           Conv2d-15          [-1, 256, 14, 14]           2,560\n",
      "      BatchNorm2d-16          [-1, 256, 14, 14]             512\n",
      "           Conv2d-17          [-1, 256, 14, 14]           9,472\n",
      "      BatchNorm2d-18          [-1, 256, 14, 14]             512\n",
      "           Conv2d-19          [-1, 256, 14, 14]          37,120\n",
      "      BatchNorm2d-20          [-1, 256, 14, 14]             512\n",
      "      BatchNorm2d-21          [-1, 256, 14, 14]             512\n",
      "        MaxPool2d-22            [-1, 256, 7, 7]               0\n",
      "          Flatten-23                [-1, 12544]               0\n",
      "           Linear-24                  [-1, 200]       2,509,000\n",
      "          Flatten-25                  [-1, 784]               0\n",
      "           Linear-26                  [-1, 200]         157,000\n",
      "      BatchNorm1d-27                  [-1, 200]             400\n",
      "          Flatten-28                 [-1, 3136]               0\n",
      "           Linear-29                  [-1, 200]         627,400\n",
      "      BatchNorm1d-30                  [-1, 200]             400\n",
      "          Flatten-31                 [-1, 3136]               0\n",
      "           Linear-32                  [-1, 200]         627,400\n",
      "      BatchNorm1d-33                  [-1, 200]             400\n",
      "          Flatten-34                [-1, 12544]               0\n",
      "           Linear-35                  [-1, 200]       2,509,000\n",
      "      BatchNorm1d-36                  [-1, 200]             400\n",
      "      BatchNorm1d-37                  [-1, 200]             400\n",
      "           Linear-38                   [-1, 85]          17,085\n",
      "          Flatten-39                  [-1, 784]               0\n",
      "           Linear-40                   [-1, 85]          66,725\n",
      "      BatchNorm1d-41                   [-1, 85]             170\n",
      "          Flatten-42                 [-1, 3136]               0\n",
      "           Linear-43                   [-1, 85]         266,645\n",
      "      BatchNorm1d-44                   [-1, 85]             170\n",
      "          Flatten-45                 [-1, 3136]               0\n",
      "           Linear-46                   [-1, 85]         266,645\n",
      "      BatchNorm1d-47                   [-1, 85]             170\n",
      "          Flatten-48                [-1, 12544]               0\n",
      "           Linear-49                   [-1, 85]       1,066,325\n",
      "      BatchNorm1d-50                   [-1, 85]             170\n",
      "          Flatten-51                [-1, 12544]               0\n",
      "           Linear-52                   [-1, 85]       1,066,325\n",
      "      BatchNorm1d-53                   [-1, 85]             170\n",
      "      BatchNorm1d-54                   [-1, 85]             170\n",
      "           Linear-55                   [-1, 10]             860\n",
      "================================================================\n",
      "Total params: 9,396,966\n",
      "Trainable params: 9,396,966\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 4.70\n",
      "Params size (MB): 35.85\n",
      "Estimated Total Size (MB): 40.55\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(fullresnet, (1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50; Loss = 0.020829; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.37%\n",
      "Dev Accuracy: 98.95%\n",
      "--------------------\n",
      "Epoch 2/50; Loss = 0.067783; LR = [0.001]\n",
      "Train Accuracy: 99.62%\n",
      "Dev Accuracy: 98.84%\n",
      "--------------------\n",
      "Epoch 3/50; Loss = 0.004471; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.86%\n",
      "Dev Accuracy: 98.98%\n",
      "--------------------\n",
      "Epoch 4/50; Loss = 0.009092; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.90%\n",
      "Dev Accuracy: 98.98%\n",
      "--------------------\n",
      "Epoch 5/50; Loss = 0.034807; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.94%\n",
      "Dev Accuracy: 99.13%\n",
      "--------------------\n",
      "Epoch 6/50; Loss = 0.002638; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.96%\n",
      "Dev Accuracy: 99.17%\n",
      "--------------------\n",
      "Epoch 7/50; Loss = 0.001619; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.91%\n",
      "Dev Accuracy: 99.22%\n",
      "--------------------\n",
      "Epoch 8/50; Loss = 0.001177; LR = [0.001]\n",
      "Train Accuracy: 99.77%\n",
      "Dev Accuracy: 99.05%\n",
      "--------------------\n",
      "Epoch 9/50; Loss = 0.026646; LR = [0.0005]\n",
      "Train Accuracy: 99.50%\n",
      "Dev Accuracy: 98.72%\n",
      "--------------------\n",
      "Epoch 10/50; Loss = 0.000334; LR = [0.0005]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.97%\n",
      "Dev Accuracy: 99.26%\n",
      "--------------------\n",
      "Epoch 11/50; Loss = 0.001823; LR = [0.0005]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.38%\n",
      "--------------------\n",
      "Epoch 12/50; Loss = 0.000114; LR = [0.0005]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.41%\n",
      "--------------------\n",
      "Epoch 13/50; Loss = 0.000119; LR = [0.0005]\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.40%\n",
      "--------------------\n",
      "Epoch 14/50; Loss = 0.000111; LR = [0.0005]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.42%\n",
      "--------------------\n",
      "Epoch 15/50; Loss = 0.000119; LR = [0.0005]\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.39%\n",
      "--------------------\n",
      "Epoch 16/50; Loss = 0.000317; LR = [0.0005]\n",
      "Train Accuracy: 100.00%\n",
      "Dev Accuracy: 99.39%\n",
      "--------------------\n",
      "Epoch 17/50; Loss = 0.000072; LR = [0.0005]\n",
      "Train Accuracy: 100.00%\n",
      "Dev Accuracy: 99.39%\n",
      "--------------------\n",
      "Epoch 18/50; Loss = 0.000074; LR = [0.00025]\n",
      "Train Accuracy: 100.00%\n",
      "Dev Accuracy: 99.40%\n",
      "--------------------\n",
      "Epoch 19/50; Loss = 0.000156; LR = [0.00025]\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.41%\n",
      "--------------------\n",
      "Epoch 20/50; Loss = 0.000103; LR = [0.00025]\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.41%\n",
      "--------------------\n",
      "Epoch 21/50; Loss = 0.000140; LR = [0.00025]\n",
      "Train Accuracy: 100.00%\n",
      "Dev Accuracy: 99.41%\n",
      "--------------------\n",
      "Epoch 22/50; Loss = 0.000160; LR = [0.00025]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.42%\n",
      "--------------------\n",
      "Epoch 23/50; Loss = 0.000028; LR = [0.00025]\n",
      "Train Accuracy: 100.00%\n",
      "Dev Accuracy: 99.40%\n",
      "--------------------\n",
      "Epoch 24/50; Loss = 0.000064; LR = [0.00025]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.42%\n",
      "--------------------\n",
      "Epoch 25/50; Loss = 0.000019; LR = [0.00025]\n",
      "Train Accuracy: 100.00%\n",
      "Dev Accuracy: 99.40%\n",
      "--------------------\n",
      "Epoch 26/50; Loss = 0.000085; LR = [0.00025]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 100.00%\n",
      "Dev Accuracy: 99.42%\n",
      "--------------------\n",
      "Epoch 27/50; Loss = 0.000037; LR = [0.000125]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 100.00%\n",
      "Dev Accuracy: 99.43%\n",
      "--------------------\n",
      "Epoch 28/50; Loss = 0.000016; LR = [0.000125]\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.40%\n",
      "--------------------\n",
      "Epoch 29/50; Loss = 0.000020; LR = [0.000125]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.43%\n",
      "--------------------\n",
      "Epoch 30/50; Loss = 0.000034; LR = [0.000125]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.43%\n",
      "--------------------\n",
      "Epoch 31/50; Loss = 0.000096; LR = [0.000125]\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.40%\n",
      "--------------------\n",
      "Epoch 32/50; Loss = 0.000055; LR = [0.000125]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.44%\n",
      "--------------------\n",
      "Epoch 33/50; Loss = 0.000032; LR = [0.000125]\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.41%\n",
      "--------------------\n",
      "Epoch 34/50; Loss = 0.000010; LR = [0.000125]\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.41%\n",
      "--------------------\n",
      "Epoch 35/50; Loss = 0.000006; LR = [0.000125]\n",
      "Train Accuracy: 100.00%\n",
      "Dev Accuracy: 99.41%\n",
      "--------------------\n",
      "Epoch 36/50; Loss = 0.000140; LR = [6.25e-05]\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.41%\n",
      "--------------------\n",
      "Epoch 37/50; Loss = 0.000021; LR = [6.25e-05]\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.42%\n",
      "--------------------\n",
      "Epoch 38/50; Loss = 0.000172; LR = [6.25e-05]\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.40%\n",
      "--------------------\n",
      "Epoch 39/50; Loss = 0.000015; LR = [6.25e-05]\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.40%\n",
      "--------------------\n",
      "Epoch 40/50; Loss = 0.000018; LR = [6.25e-05]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.44%\n",
      "--------------------\n",
      "Epoch 41/50; Loss = 0.000007; LR = [6.25e-05]\n",
      "Train Accuracy: 100.00%\n",
      "Dev Accuracy: 99.42%\n",
      "--------------------\n",
      "Epoch 42/50; Loss = 0.000021; LR = [6.25e-05]\n",
      "Train Accuracy: 100.00%\n",
      "Dev Accuracy: 99.42%\n",
      "--------------------\n",
      "Epoch 43/50; Loss = 0.000029; LR = [6.25e-05]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.45%\n",
      "--------------------\n",
      "Epoch 44/50; Loss = 0.000013; LR = [6.25e-05]\n",
      "Train Accuracy: 100.00%\n",
      "Dev Accuracy: 99.43%\n",
      "--------------------\n",
      "Epoch 45/50; Loss = 0.000004; LR = [3.125e-05]\n",
      "Train Accuracy: 100.00%\n",
      "Dev Accuracy: 99.43%\n",
      "--------------------\n",
      "Epoch 46/50; Loss = 0.000011; LR = [3.125e-05]\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.44%\n",
      "--------------------\n",
      "Epoch 47/50; Loss = 0.000006; LR = [3.125e-05]\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.42%\n",
      "--------------------\n",
      "Epoch 48/50; Loss = 0.000008; LR = [3.125e-05]\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.44%\n",
      "--------------------\n",
      "Epoch 49/50; Loss = 0.000007; LR = [3.125e-05]\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.42%\n",
      "--------------------\n",
      "Epoch 50/50; Loss = 0.000007; LR = [3.125e-05]\n",
      "Train Accuracy: 100.00%\n",
      "Dev Accuracy: 99.43%\n",
      "--------------------\n",
      "Finished Training!\n",
      "Time Taken = 30.0m 57.18664503097534s\n"
     ]
    }
   ],
   "source": [
    "best_weights = copy.deepcopy(fullresnet.state_dict())\n",
    "max = 0\n",
    "val_acc = 0\n",
    "train_acc = 0\n",
    "tic = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    fullresnet.train()\n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        preds = fullresnet.forward(images)\n",
    "        loss = criterion(preds, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step() # Decaying learning rate per 25 epochs by 0.2 times\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}; Loss = {loss.item():.6f}; LR = {scheduler.get_last_lr()}')\n",
    "    with torch.no_grad():\n",
    "        n_samples = 0\n",
    "        n_correct = 0\n",
    "        fullresnet.eval()\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device) # From 128, 1, 28, 28 ---> 128, 784\n",
    "            labels = labels.to(device)\n",
    "            pred_outputs1 = fullresnet(images)\n",
    "            _, actual_preds1 = torch.max(pred_outputs1, 1) # Returns value, index\n",
    "            n_samples += labels.shape[0]\n",
    "            n_correct += (actual_preds1 == labels).sum().item()\n",
    "        val_acc = n_correct/n_samples * 100\n",
    "\n",
    "        if (max <= (n_correct/n_samples * 100)):\n",
    "            print('SAVED MODEL WEIGHTS')\n",
    "            max = val_acc\n",
    "            best_weights = copy.deepcopy(fullresnet.state_dict())\n",
    "\n",
    "        n_samples = 0\n",
    "        n_correct = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device) # From 128, 1, 28, 28 ---> 128, 784\n",
    "            labels = labels.to(device)\n",
    "            pred_outputs1 = fullresnet(images)\n",
    "            _, actual_preds1 = torch.max(pred_outputs1, 1) # Returns value, index\n",
    "            n_samples += labels.shape[0]\n",
    "            n_correct += (actual_preds1 == labels).sum().item()\n",
    "        train_acc = n_correct/n_samples * 100\n",
    "    \n",
    "    print(f'Train Accuracy: {train_acc:.2f}%')\n",
    "    print(f'Dev Accuracy: {val_acc:.2f}%')\n",
    "    print(\"-\"*20)\n",
    "print('Finished Training!')\n",
    "print(f'Best Test Accuracy = {max}')\n",
    "print(f'Time Taken = {(time.time()-tic)//60}m {(time.time()-tic)%60}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time taken by connecting everything is also much LARGER and also **no improvement** from just connecting the input to every point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start connected longer ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myBigResNet(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(myBigResNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1,4,5,1,'same') # 4, 28, 28\n",
    "        # self.act1_1 = nn.ReLU() \n",
    "        self.norm1 = nn.BatchNorm2d(4)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(4,16,5,1,'same') # 16, 28, 28\n",
    "        self.conv1to2 = nn.Conv2d(1,16,3,1,'same') # 16, 28, 28\n",
    "        # self.act1_2 = nn.ReLU()\n",
    "        self.norm2 = nn.BatchNorm2d(16)\n",
    "            \n",
    "        self.pool1 = nn.MaxPool2d(2, 2) # 16, 28, 28 --> 16, 14, 14\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(16,64,3,1,'same') # 64, 14, 14\n",
    "        self.conv1to3 = nn.Conv2d(1,64,3,2,1) # 64, 14, 14\n",
    "        # self.act2_1 = nn.ReLU()\n",
    "        self.norm3 = nn.BatchNorm2d(64)\n",
    "            \n",
    "        self.conv4 = nn.Conv2d(64,256,3,1,'same')  # 256, 14, 14\n",
    "        self.conv1to4 = nn.Conv2d(1,256,3,2,1) # 256, 14, 14\n",
    "        # self.act2_2 = nn.ReLU()\n",
    "        self.norm4 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.pool2 = nn.MaxPool2d(2, 2) # 256, 14, 14 --> 256, 7, 7\n",
    "\n",
    "        self.conv5 = nn.Conv2d(256,512,5,1,'same') # 512, 7, 7\n",
    "        self.conv1to5 = nn.Conv2d(1,512,3,4,1) # 1024, 7, 7\n",
    "        # self.act1_1 = nn.ReLU() \n",
    "        self.norm5 = nn.BatchNorm2d(512)\n",
    "\n",
    "        self.conv6 = nn.Conv2d(512,1024,5,1,'same') # 1024, 7, 7\n",
    "        self.conv1to6 = nn.Conv2d(1,1024,3,4,1) # 1024, 7, 7\n",
    "        # self.act1_2 = nn.ReLU()\n",
    "        self.norm6 = nn.BatchNorm2d(1024)\n",
    "            \n",
    "        self.pool3 = nn.MaxPool2d(2, 2) # 1024, 7, 7 --> 1024, 3, 3\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.lin7 = nn.Linear(1024*3*3, 1024)\n",
    "        self.lin1to7 = nn.Linear(28*28*1, 1024)\n",
    "        # self.act4 = nn.ReLU()\n",
    "        self.norm7 = nn.BatchNorm1d(1024)\n",
    "\n",
    "        self.lin8 = nn.Linear(1024, 512)\n",
    "        self.lin1to8 = nn.Linear(28*28*1, 512)\n",
    "        # self.act5 = nn.ReLU()\n",
    "        self.norm8 = nn.BatchNorm1d(512)\n",
    "\n",
    "        self.lin9 = nn.Linear(512, 128)\n",
    "        self.lin1to9 = nn.Linear(28*28*1, 128)\n",
    "        # self.act5 = nn.ReLU()\n",
    "        self.norm9 = nn.BatchNorm1d(128)\n",
    "\n",
    "        self.lin10 = nn.Linear(128, 84)\n",
    "        self.lin1to10 = nn.Linear(28*28*1, 84)\n",
    "        # self.act5 = nn.ReLU()\n",
    "        self.norm10 = nn.BatchNorm1d(84)\n",
    "\n",
    "        self.lin_fin = nn.Linear(84,10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_temp1 = x\n",
    "        x = self.norm1(torch.relu(self.conv1(x)))\n",
    "        x = self.norm2(torch.relu(self.conv2(x)+self.conv1to2(x_temp1))) # Residual\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.norm3(torch.relu(self.conv3(x)+self.conv1to3(x_temp1)))\n",
    "        x = self.norm4(torch.relu(self.conv4(x)+self.conv1to4(x_temp1))) # Residual\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.norm5(torch.relu(self.conv5(x)+self.conv1to5(x_temp1)))\n",
    "        x = self.norm6(torch.relu(self.conv6(x)+self.conv1to6(x_temp1))) # Residual\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.norm7(torch.relu(self.lin7(x)+self.lin1to7(self.flatten(x_temp1))))\n",
    "        x = self.norm8(torch.relu(self.lin8(x)+self.lin1to8(self.flatten(x_temp1))))\n",
    "        x = self.norm9(torch.relu(self.lin9(x)+self.lin1to9(self.flatten(x_temp1))))\n",
    "        x = self.norm10(torch.relu(self.lin10(x)+self.lin1to10(self.flatten(x_temp1))))\n",
    "\n",
    "        x = self.lin_fin(x)\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigresnet = myBigResNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(bigresnet.parameters(), lr = learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 9, gamma = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 4, 28, 28]             104\n",
      "       BatchNorm2d-2            [-1, 4, 28, 28]               8\n",
      "            Conv2d-3           [-1, 16, 28, 28]           1,616\n",
      "            Conv2d-4           [-1, 16, 28, 28]             160\n",
      "       BatchNorm2d-5           [-1, 16, 28, 28]              32\n",
      "         MaxPool2d-6           [-1, 16, 14, 14]               0\n",
      "            Conv2d-7           [-1, 64, 14, 14]           9,280\n",
      "            Conv2d-8           [-1, 64, 14, 14]             640\n",
      "       BatchNorm2d-9           [-1, 64, 14, 14]             128\n",
      "           Conv2d-10          [-1, 256, 14, 14]         147,712\n",
      "           Conv2d-11          [-1, 256, 14, 14]           2,560\n",
      "      BatchNorm2d-12          [-1, 256, 14, 14]             512\n",
      "        MaxPool2d-13            [-1, 256, 7, 7]               0\n",
      "           Conv2d-14            [-1, 512, 7, 7]       3,277,312\n",
      "           Conv2d-15            [-1, 512, 7, 7]           5,120\n",
      "      BatchNorm2d-16            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-17           [-1, 1024, 7, 7]      13,108,224\n",
      "           Conv2d-18           [-1, 1024, 7, 7]          10,240\n",
      "      BatchNorm2d-19           [-1, 1024, 7, 7]           2,048\n",
      "        MaxPool2d-20           [-1, 1024, 3, 3]               0\n",
      "          Flatten-21                 [-1, 9216]               0\n",
      "           Linear-22                 [-1, 1024]       9,438,208\n",
      "          Flatten-23                  [-1, 784]               0\n",
      "           Linear-24                 [-1, 1024]         803,840\n",
      "      BatchNorm1d-25                 [-1, 1024]           2,048\n",
      "           Linear-26                  [-1, 512]         524,800\n",
      "          Flatten-27                  [-1, 784]               0\n",
      "           Linear-28                  [-1, 512]         401,920\n",
      "      BatchNorm1d-29                  [-1, 512]           1,024\n",
      "           Linear-30                  [-1, 128]          65,664\n",
      "          Flatten-31                  [-1, 784]               0\n",
      "           Linear-32                  [-1, 128]         100,480\n",
      "      BatchNorm1d-33                  [-1, 128]             256\n",
      "           Linear-34                   [-1, 84]          10,836\n",
      "          Flatten-35                  [-1, 784]               0\n",
      "           Linear-36                   [-1, 84]          65,940\n",
      "      BatchNorm1d-37                   [-1, 84]             168\n",
      "           Linear-38                   [-1, 10]             850\n",
      "================================================================\n",
      "Total params: 27,982,754\n",
      "Trainable params: 27,982,754\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 3.82\n",
      "Params size (MB): 106.75\n",
      "Estimated Total Size (MB): 110.57\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(bigresnet, (1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50; Loss = 0.112526; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 94.98%\n",
      "Dev Accuracy: 98.06%\n",
      "--------------------\n",
      "Epoch 2/50; Loss = 0.088969; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 96.48%\n",
      "Dev Accuracy: 98.12%\n",
      "--------------------\n",
      "Epoch 3/50; Loss = 0.038057; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 98.23%\n",
      "Dev Accuracy: 99.16%\n",
      "--------------------\n",
      "Epoch 4/50; Loss = 0.064586; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 98.29%\n",
      "Dev Accuracy: 99.26%\n",
      "--------------------\n",
      "Epoch 5/50; Loss = 0.071916; LR = [0.001]\n",
      "Train Accuracy: 97.95%\n",
      "Dev Accuracy: 98.73%\n",
      "--------------------\n",
      "Epoch 6/50; Loss = 0.053622; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 98.93%\n",
      "Dev Accuracy: 99.31%\n",
      "--------------------\n",
      "Epoch 7/50; Loss = 0.024016; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 98.61%\n",
      "Dev Accuracy: 99.34%\n",
      "--------------------\n",
      "Epoch 8/50; Loss = 0.030245; LR = [0.001]\n",
      "Train Accuracy: 98.71%\n",
      "Dev Accuracy: 99.21%\n",
      "--------------------\n",
      "Epoch 9/50; Loss = 0.025527; LR = [0.0005]\n",
      "Train Accuracy: 99.09%\n",
      "Dev Accuracy: 99.22%\n",
      "--------------------\n",
      "Epoch 10/50; Loss = 0.012561; LR = [0.0005]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.46%\n",
      "Dev Accuracy: 99.50%\n",
      "--------------------\n",
      "Epoch 11/50; Loss = 0.013331; LR = [0.0005]\n",
      "Train Accuracy: 99.43%\n",
      "Dev Accuracy: 99.48%\n",
      "--------------------\n",
      "Epoch 12/50; Loss = 0.078338; LR = [0.0005]\n",
      "Train Accuracy: 99.45%\n",
      "Dev Accuracy: 99.45%\n",
      "--------------------\n",
      "Epoch 13/50; Loss = 0.003808; LR = [0.0005]\n",
      "Train Accuracy: 99.49%\n",
      "Dev Accuracy: 99.44%\n",
      "--------------------\n",
      "Epoch 14/50; Loss = 0.061184; LR = [0.0005]\n",
      "Train Accuracy: 99.54%\n",
      "Dev Accuracy: 99.46%\n",
      "--------------------\n",
      "Epoch 15/50; Loss = 0.014300; LR = [0.0005]\n",
      "Train Accuracy: 99.53%\n",
      "Dev Accuracy: 99.48%\n",
      "--------------------\n",
      "Epoch 16/50; Loss = 0.002140; LR = [0.0005]\n",
      "Train Accuracy: 99.55%\n",
      "Dev Accuracy: 99.41%\n",
      "--------------------\n",
      "Epoch 17/50; Loss = 0.045664; LR = [0.0005]\n",
      "Train Accuracy: 99.41%\n",
      "Dev Accuracy: 99.46%\n",
      "--------------------\n",
      "Epoch 18/50; Loss = 0.001983; LR = [0.00025]\n",
      "Train Accuracy: 99.37%\n",
      "Dev Accuracy: 99.32%\n",
      "--------------------\n",
      "Epoch 19/50; Loss = 0.007371; LR = [0.00025]\n",
      "Train Accuracy: 99.67%\n",
      "Dev Accuracy: 99.44%\n",
      "--------------------\n",
      "Epoch 20/50; Loss = 0.004720; LR = [0.00025]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.67%\n",
      "Dev Accuracy: 99.54%\n",
      "--------------------\n",
      "Epoch 21/50; Loss = 0.107458; LR = [0.00025]\n",
      "Train Accuracy: 99.73%\n",
      "Dev Accuracy: 99.50%\n",
      "--------------------\n",
      "Epoch 22/50; Loss = 0.000879; LR = [0.00025]\n",
      "Train Accuracy: 99.75%\n",
      "Dev Accuracy: 99.44%\n",
      "--------------------\n",
      "Epoch 23/50; Loss = 0.002692; LR = [0.00025]\n",
      "Train Accuracy: 99.72%\n",
      "Dev Accuracy: 99.52%\n",
      "--------------------\n",
      "Epoch 24/50; Loss = 0.053709; LR = [0.00025]\n",
      "Train Accuracy: 99.76%\n",
      "Dev Accuracy: 99.44%\n",
      "--------------------\n",
      "Epoch 25/50; Loss = 0.000411; LR = [0.00025]\n",
      "Train Accuracy: 99.78%\n",
      "Dev Accuracy: 99.51%\n",
      "--------------------\n",
      "Epoch 26/50; Loss = 0.002066; LR = [0.00025]\n",
      "Train Accuracy: 99.66%\n",
      "Dev Accuracy: 99.41%\n",
      "--------------------\n",
      "Epoch 27/50; Loss = 0.006170; LR = [0.000125]\n",
      "Train Accuracy: 99.73%\n",
      "Dev Accuracy: 99.53%\n",
      "--------------------\n",
      "Epoch 28/50; Loss = 0.002022; LR = [0.000125]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.77%\n",
      "Dev Accuracy: 99.54%\n",
      "--------------------\n",
      "Epoch 29/50; Loss = 0.000360; LR = [0.000125]\n",
      "Train Accuracy: 99.80%\n",
      "Dev Accuracy: 99.53%\n",
      "--------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/venkatakrishnanvk/Desktop/ML & DL/Deep Learning/Pytorch-Tutorial/Tutorial 13.2 - FN-Residual Networks with Data Augmentation.ipynb Cell 33\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/venkatakrishnanvk/Desktop/ML%20%26%20DL/Deep%20Learning/Pytorch-Tutorial/Tutorial%2013.2%20-%20FN-Residual%20Networks%20with%20Data%20Augmentation.ipynb#X44sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/venkatakrishnanvk/Desktop/ML%20%26%20DL/Deep%20Learning/Pytorch-Tutorial/Tutorial%2013.2%20-%20FN-Residual%20Networks%20with%20Data%20Augmentation.ipynb#X44sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     bigresnet\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/venkatakrishnanvk/Desktop/ML%20%26%20DL/Deep%20Learning/Pytorch-Tutorial/Tutorial%2013.2%20-%20FN-Residual%20Networks%20with%20Data%20Augmentation.ipynb#X44sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, (images,labels) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/venkatakrishnanvk/Desktop/ML%20%26%20DL/Deep%20Learning/Pytorch-Tutorial/Tutorial%2013.2%20-%20FN-Residual%20Networks%20with%20Data%20Augmentation.ipynb#X44sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         images \u001b[39m=\u001b[39m images\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/venkatakrishnanvk/Desktop/ML%20%26%20DL/Deep%20Learning/Pytorch-Tutorial/Tutorial%2013.2%20-%20FN-Residual%20Networks%20with%20Data%20Augmentation.ipynb#X44sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torchvision/datasets/mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    142\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img\u001b[39m.\u001b[39mnumpy(), mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[1;32m    147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torchvision/transforms/transforms.py:94\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[1;32m     93\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> 94\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[1;32m     95\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torchvision/transforms/transforms.py:134\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[1;32m    127\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/torchvision/transforms/functional.py:164\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39m# handle PIL Image\u001b[39;00m\n\u001b[1;32m    163\u001b[0m mode_to_nptype \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mI\u001b[39m\u001b[39m\"\u001b[39m: np\u001b[39m.\u001b[39mint32, \u001b[39m\"\u001b[39m\u001b[39mI;16\u001b[39m\u001b[39m\"\u001b[39m: np\u001b[39m.\u001b[39mint16, \u001b[39m\"\u001b[39m\u001b[39mF\u001b[39m\u001b[39m\"\u001b[39m: np\u001b[39m.\u001b[39mfloat32}\n\u001b[0;32m--> 164\u001b[0m img \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(np\u001b[39m.\u001b[39;49marray(pic, mode_to_nptype\u001b[39m.\u001b[39;49mget(pic\u001b[39m.\u001b[39;49mmode, np\u001b[39m.\u001b[39;49muint8), copy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m))\n\u001b[1;32m    166\u001b[0m \u001b[39mif\u001b[39;00m pic\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m1\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    167\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39m255\u001b[39m \u001b[39m*\u001b[39m img\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/PIL/Image.py:513\u001b[0m, in \u001b[0;36mImage.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpyaccess \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    511\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exif \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 513\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, name):\n\u001b[1;32m    514\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcategory\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    515\u001b[0m         deprecate(\u001b[39m\"\u001b[39m\u001b[39mImage categories\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mis_animated\u001b[39m\u001b[39m\"\u001b[39m, plural\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_weights = copy.deepcopy(bigresnet.state_dict())\n",
    "max = 0\n",
    "val_acc = 0\n",
    "train_acc = 0\n",
    "tic = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    bigresnet.train()\n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        preds = bigresnet.forward(images)\n",
    "        loss = criterion(preds, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step() # Decaying learning rate per 25 epochs by 0.2 times\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}; Loss = {loss.item():.6f}; LR = {scheduler.get_last_lr()}')\n",
    "    with torch.no_grad():\n",
    "        n_samples = 0\n",
    "        n_correct = 0\n",
    "        bigresnet.eval()\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device) # From 128, 1, 28, 28 ---> 128, 784\n",
    "            labels = labels.to(device)\n",
    "            pred_outputs1 = bigresnet(images)\n",
    "            _, actual_preds1 = torch.max(pred_outputs1, 1) # Returns value, index\n",
    "            n_samples += labels.shape[0]\n",
    "            n_correct += (actual_preds1 == labels).sum().item()\n",
    "        val_acc = n_correct/n_samples * 100\n",
    "\n",
    "        if (max <= (n_correct/n_samples * 100)):\n",
    "            print('SAVED MODEL WEIGHTS')\n",
    "            max = val_acc\n",
    "            best_weights = copy.deepcopy(bigresnet.state_dict())\n",
    "\n",
    "        n_samples = 0\n",
    "        n_correct = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device) # From 128, 1, 28, 28 ---> 128, 784\n",
    "            labels = labels.to(device)\n",
    "            pred_outputs1 = bigresnet(images)\n",
    "            _, actual_preds1 = torch.max(pred_outputs1, 1) # Returns value, index\n",
    "            n_samples += labels.shape[0]\n",
    "            n_correct += (actual_preds1 == labels).sum().item()\n",
    "        train_acc = n_correct/n_samples * 100\n",
    "    \n",
    "    print(f'Train Accuracy: {train_acc:.2f}%')\n",
    "    print(f'Dev Accuracy: {val_acc:.2f}%')\n",
    "    print(\"-\"*20)\n",
    "print('Finished Training!')\n",
    "print(f'Best Test Accuracy = {max}')\n",
    "print(f'Time Taken = {(time.time()-tic)//60}m {(time.time()-tic)%60}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.has_mps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

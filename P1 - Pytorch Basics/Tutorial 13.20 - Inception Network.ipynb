{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(10)\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 0.5\n",
    "std_dev = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform1 = transforms.Compose([\n",
    "    transforms.AutoAugment(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean,std_dev)\n",
    "])\n",
    "transform2 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean,std_dev)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='../datasets',\n",
    "    train = True,\n",
    "    transform=transform2 #download is False in default\n",
    ")\n",
    "\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root='../datasets',\n",
    "    train = False,\n",
    "    transform=transform2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "batch_size = 256\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset = train_data,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset = test_data,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, label):\n",
    "    img = img * std_dev + mean  # unnormalize\n",
    "    plt.imshow(img.reshape(img.shape[1],img.shape[2],img.shape[0]))\n",
    "    plt.title(f'Label {label}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGxCAYAAADLfglZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAeb0lEQVR4nO3dfXRU9b3v8c9AwvBgGJtiMhOJMYeHagFpBeShqAFrrmnlqFGL2NVCa7moAUsj2lJaSbElLq3IPaVg67IRjlBYLhFp4YqxkFAv4gkcPFJqLSyDhGViSqqZgJoY+N0/OMxxSHjYwwzfTPJ+rbXXYvbs38wv241vdmZmj8855wQAgIFu1hMAAHRdRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIXd4zzzwjn8+nHTt2xOXxfD6fZs6cGZfH+uxjlpSUnHG7cDisefPmafDgwerdu7cuvvhi3X777dqzZ09c5wPES4r1BADEz6RJk7Rjxw6VlJRo5MiROnjwoBYsWKCxY8dq9+7dysnJsZ4iEIUIAZ3Evn37tHXrVv3kJz/RAw88EFk/cOBAjRs3TmvXrtUPfvADwxkCbfHrOOAsfPLJJ7r//vv1pS99SYFAQOnp6Ro7dqxefPHFU475zW9+o8GDB8vv9+uLX/yiVq9e3Waburo6zZgxQ/3791ePHj2Um5urn/3sZ2ptbfU8x9TUVElSIBCIWn/hhRdKknr27On5MYFE40wIOAvNzc365z//qTlz5ujiiy9WS0uLXnnlFRUWFqqsrEzf/va3o7Zfv369tmzZogULFqhPnz5aunSppkyZopSUFN12222SjgfoqquuUrdu3fTQQw9pwIABeu211/Tzn/9c+/fvV1lZmac55uTk6KabbtITTzyhESNGaNSoUTp48KDuu+8+XXLJJbrjjjvitj+AuHFAF1dWVuYkuaqqqrMe09ra6j799FN31113uS9/+ctR90lyvXr1cnV1dVHbX3bZZW7gwIGRdTNmzHAXXHCBe/fdd6PG//KXv3SS3J49e6Iec/78+WecV0tLi5s+fbqTFFmuuOIKV11dfdY/G3A+8es44Cw999xz+spXvqILLrhAKSkpSk1N1dNPP6233nqrzbbXXXedMjMzI7e7d++uyZMna9++fTp48KAk6Y9//KMmTJigrKwstba2RpaCggJJUmVlpec53nPPPXr++ef1xBNPqLKyUmvWrFGPHj00ceJEvfvuuzH+5EDi8Os44CysXbtW3/jGN3T77bfrgQceUDAYVEpKipYtW6bf/e53bbYPBoOnXNfQ0KD+/fvr/fff1x/+8IfIazknO3TokKc5vvTSS3r66af13HPPRX7lJ0n5+fm69NJLVVJS4vlXfECiESHgLDz77LPKzc3VmjVr5PP5Iuubm5vb3b6uru6U6z7/+c9Lkvr166crrrhCv/jFL9p9jKysLE9zfOONNyRJo0aNilp/4YUXauDAgfrLX/7i6fGA84EIAWfB5/OpR48eUQGqq6s75bvj/vSnP+n999+P/Eru6NGjWrNmjQYMGKD+/ftLkm688UZt3LhRAwYM0Oc+97lznuOJaG3fvj3q80ANDQ36+9//ruuuu+6cnwOINyIE/LfNmzdr//79bdZ/7Wtf04033qi1a9fq3nvv1W233aaamho9/PDDCoVC2rt3b5sx/fr108SJE/XTn/408u64v/3tb1Fv016wYIHKy8s1btw43XffffrCF76gTz75RPv379fGjRv15JNPRoJ1NgoLC/XQQw/pnnvu0cGDB3XllVeqtrZWjz32mD766CN9//vfj2m/AAll/c4IwNqJd8edajnxzrJHHnnEXXrppc7v97vLL7/cPfXUU27+/Pnu5L9GklxRUZFbunSpGzBggEtNTXWXXXaZW7lyZZvn/sc//uHuu+8+l5ub61JTU116erobMWKEmzdvnjt8+HDUY57Nu+Nqa2vdzJkz3cCBA13Pnj1dVlaW+/rXv+5ee+21c9pHQKL4nHPOKoAAgK6Nt2gDAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmOlwH1Y9duyY3nvvPaWlpUV9Oh0AkBycc2pqalJWVpa6dTv9uU6Hi9B7772n7Oxs62kAAM5RTU3NGa/60eEilJaWJkkar68pRe1fXRgA0HG16lO9qo2R/5+fTsIitHTpUj322GOqra3VkCFDtHjxYl199dVnHHfiV3ApSlWKjwgBQNL57+vwnM1LKgl5Y8KaNWs0e/ZszZs3T7t27dLVV1+tgoICHThwIBFPBwBIUgmJ0KJFi3TXXXfpe9/7ni6//HItXrxY2dnZWrZsWSKeDgCQpOIeoZaWFu3cuVP5+flR6/Pz87Vt27Y22zc3NyscDkctAICuIe4ROnTokI4ePRr5Mq8TMjMz2/22ydLSUgUCgcjCO+MAoOtI2IdVT35ByjnX7otUc+fOVWNjY2SpqalJ1JQAAB1M3N8d169fP3Xv3r3NWU99fX2bsyNJ8vv98vv98Z4GACAJxP1MqEePHhoxYoTKy8uj1p/4GmMAAE5IyOeEiouL9a1vfUsjR47U2LFj9dvf/lYHDhzQ3XffnYinAwAkqYREaPLkyWpoaNCCBQtUW1uroUOHauPGjcrJyUnE0wEAkpTPOeesJ/FZ4XBYgUBAebqJKyYAQBJqdZ+qQi+qsbFRffv2Pe22fJUDAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYCbFegJAR/LP74z1POabc/6v5zGzLnzH85hJf7/R85hjxZ/zPEaS3K49MY0DvOJMCABghggBAMzEPUIlJSXy+XxRSzAYjPfTAAA6gYS8JjRkyBC98sorkdvdu3dPxNMAAJJcQiKUkpLC2Q8A4IwS8prQ3r17lZWVpdzcXN1xxx16551TvxOoublZ4XA4agEAdA1xj9Do0aO1YsUKbdq0SU899ZTq6uo0btw4NTQ0tLt9aWmpAoFAZMnOzo73lAAAHVTcI1RQUKBbb71Vw4YN01e/+lVt2LBBkrR8+fJ2t587d64aGxsjS01NTbynBADooBL+YdU+ffpo2LBh2rt3b7v3+/1++f3+RE8DANABJfxzQs3NzXrrrbcUCoUS/VQAgCQT9wjNmTNHlZWVqq6u1uuvv67bbrtN4XBYU6dOjfdTAQCSXNx/HXfw4EFNmTJFhw4d0kUXXaQxY8Zo+/btysnJifdTAQCSXNwjtHr16ng/JODZ0bwrYxq3/ee/9jxmwl9u9Txm3QPXex7zwL/9u+cxJQ//q+cxkpTu/VqpQEy4dhwAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYCbhX2oHWPjfv30+pnErmzI8j+lz2yHPY441VXse85N/+a7nMb+5//94HiNJP9WomMYBXnEmBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNcRRud0qWp3q9sLUnf+o+7vD9X05sxPZdXqYfdeXke4HziTAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMMMFTNEp/fg7M2Ia99Lyf/M8pugL0zyPOfr2Ps9jYtFdXPQUHRtnQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGS5gik6pe8V/xjRu4ubvex4zcGm95zEpX+/peUwsjsp3Xp4HiBVnQgAAM0QIAGDGc4S2bt2qSZMmKSsrSz6fT+vWrYu63zmnkpISZWVlqVevXsrLy9OePXviNV8AQCfiOUJHjhzR8OHDtWTJknbvf/TRR7Vo0SItWbJEVVVVCgaDuv7669XU1HTOkwUAdC6e35hQUFCggoKCdu9zzmnx4sWaN2+eCgsLJUnLly9XZmamVq1apRkzYvu2SwBA5xTX14Sqq6tVV1en/Pz8yDq/369rr71W27Zta3dMc3OzwuFw1AIA6BriGqG6ujpJUmZmZtT6zMzMyH0nKy0tVSAQiCzZ2dnxnBIAoANLyLvjfL7ozyY459qsO2Hu3LlqbGyMLDU1NYmYEgCgA4rrh1WDwaCk42dEoVAosr6+vr7N2dEJfr9ffr8/ntMAACSJuJ4J5ebmKhgMqry8PLKupaVFlZWVGjduXDyfCgDQCXg+Ezp8+LD27dsXuV1dXa033nhD6enpuuSSSzR79mwtXLhQgwYN0qBBg7Rw4UL17t1bd955Z1wnDgBIfp4jtGPHDk2YMCFyu7i4WJI0depUPfPMM3rwwQf18ccf695779UHH3yg0aNH6+WXX1ZaWlr8Zg0A6BR8zjlnPYnPCofDCgQCytNNSvGlWk8HXUy3GP6x9J2db3oe8/Bvv+l5TK9D3v+qfu+HL3oeI0nPX54R0zhAklrdp6rQi2psbFTfvn1Puy3XjgMAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAICZuH6zKpDsjjU1eR4TyxWxf3XPk57HfKf8e57HPP7mVz2PkaRL5f3K4EAsOBMCAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMxwAVN0St16945pXN13v+R5THbZ37w/z/SA5zH7Jnm/6OngLXd5HgOcT5wJAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmuIApOqWjwwfFNO5n33/G85ilr9/qecxD/5ntecyt1/zO85jPv9LT8xjgfOJMCABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwwwVM0Sn5XvuvmMb98N+neR7z5rpfxfRc50Of2k+tpwCcFmdCAAAzRAgAYMZzhLZu3apJkyYpKytLPp9P69ati7p/2rRp8vl8UcuYMWPiNV8AQCfiOUJHjhzR8OHDtWTJklNuc8MNN6i2tjaybNy48ZwmCQDonDy/MaGgoEAFBQWn3cbv9ysYDMY8KQBA15CQ14QqKiqUkZGhwYMHa/r06aqvrz/lts3NzQqHw1ELAKBriHuECgoKtHLlSm3evFmPP/64qqqqNHHiRDU3N7e7fWlpqQKBQGTJzs6O95QAAB1U3D8nNHny5Mifhw4dqpEjRyonJ0cbNmxQYWFhm+3nzp2r4uLiyO1wOEyIAKCLSPiHVUOhkHJycrR379527/f7/fL7/YmeBgCgA0r454QaGhpUU1OjUCiU6KcCACQZz2dChw8f1r59+yK3q6ur9cYbbyg9PV3p6ekqKSnRrbfeqlAopP379+vHP/6x+vXrp1tuuSWuEwcAJD/PEdqxY4cmTJgQuX3i9ZypU6dq2bJl2r17t1asWKEPP/xQoVBIEyZM0Jo1a5SWlha/WQMAOgXPEcrLy5Nz7pT3b9q06ZwmBFga//XYLnzq1Ter8z2PWZqz3vOYA/8rtpd9B/LXGOcJ144DAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAmYR/sypgoVvv3jGNeyr7/3keM7jyu57H5E7xfrXuX/3XVZ7HpFz8kecxwPnEmRAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYLmKJTemfu8JjG1ba+7HnMwJ9/4nnMUc8jpI01Q2IYBXRsnAkBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGa4gCk6p8FHYhpWc9TveczRPW/H9Fxe/XrISs9jvvUfdyVgJkD8cCYEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzHiKUGlpqUaNGqW0tDRlZGTo5ptv1ttvR3+XinNOJSUlysrKUq9evZSXl6c9e/bEddIAgM7BU4QqKytVVFSk7du3q7y8XK2trcrPz9eRI//zBWKPPvqoFi1apCVLlqiqqkrBYFDXX3+9mpqa4j55AEBy8/TNqi+99FLU7bKyMmVkZGjnzp265ppr5JzT4sWLNW/ePBUWFkqSli9frszMTK1atUozZsyI38wBAEnvnF4TamxslCSlp6dLkqqrq1VXV6f8/PzINn6/X9dee622bdvW7mM0NzcrHA5HLQCAriHmCDnnVFxcrPHjx2vo0KGSpLq6OklSZmZm1LaZmZmR+05WWlqqQCAQWbKzs2OdEgAgycQcoZkzZ+rNN9/U73//+zb3+Xy+qNvOuTbrTpg7d64aGxsjS01NTaxTAgAkGU+vCZ0wa9YsrV+/Xlu3blX//v0j64PBoKTjZ0ShUCiyvr6+vs3Z0Ql+v19+vz+WaQAAkpynMyHnnGbOnKm1a9dq8+bNys3Njbo/NzdXwWBQ5eXlkXUtLS2qrKzUuHHj4jNjAECn4elMqKioSKtWrdKLL76otLS0yOs8gUBAvXr1ks/n0+zZs7Vw4UINGjRIgwYN0sKFC9W7d2/deeedCfkBAADJy1OEli1bJknKy8uLWl9WVqZp06ZJkh588EF9/PHHuvfee/XBBx9o9OjRevnll5WWlhaXCQMAOg9PEXLOnXEbn8+nkpISlZSUxDon4Jz5X78gpnHdrzrzMR4XVw3zPGRQSvsfcwCSGdeOAwCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgJmYvlkV6OhCi2K74vRFs1s8j/GNHOp5TPhf+ngec0E3799AHOvVxIHzhTMhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMFzAFPmPC83M8j3l01aoEzCQ+ev7TWU8BOC3OhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM1zAFPiMwT/Z7XnMA6lTPI/517E7PY/5YdUwz2MGrd7leYwkHYtpFOAdZ0IAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkuYAp8xrEjRzyPGTTzdc9j3vI8Qhog7xcj5UKk6Og4EwIAmCFCAAAzniJUWlqqUaNGKS0tTRkZGbr55pv19ttvR20zbdo0+Xy+qGXMmDFxnTQAoHPwFKHKykoVFRVp+/btKi8vV2trq/Lz83XkpN+j33DDDaqtrY0sGzdujOukAQCdg6c3Jrz00ktRt8vKypSRkaGdO3fqmmuuiaz3+/0KBoPxmSEAoNM6p9eEGhsbJUnp6elR6ysqKpSRkaHBgwdr+vTpqq+vP+VjNDc3KxwORy0AgK4h5gg551RcXKzx48dr6NChkfUFBQVauXKlNm/erMcff1xVVVWaOHGimpub232c0tJSBQKByJKdnR3rlAAAScbnnHOxDCwqKtKGDRv06quvqn///qfcrra2Vjk5OVq9erUKCwvb3N/c3BwVqHA4rOzsbOXpJqX4UmOZGgDAUKv7VBV6UY2Njerbt+9pt43pw6qzZs3S+vXrtXXr1tMGSJJCoZBycnK0d+/edu/3+/3y+/2xTAMAkOQ8Rcg5p1mzZumFF15QRUWFcnNzzzimoaFBNTU1CoVCMU8SANA5eXpNqKioSM8++6xWrVqltLQ01dXVqa6uTh9//LEk6fDhw5ozZ45ee+017d+/XxUVFZo0aZL69eunW265JSE/AAAgeXk6E1q2bJkkKS8vL2p9WVmZpk2bpu7du2v37t1asWKFPvzwQ4VCIU2YMEFr1qxRWlpa3CYNAOgcPP867nR69eqlTZs2ndOEAABdB9eOAwCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYSbGewMmcc5KkVn0qOePJAAA8a9Wnkv7n/+en0+Ei1NTUJEl6VRuNZwIAOBdNTU0KBAKn3cbnziZV59GxY8f03nvvKS0tTT6fL+q+cDis7Oxs1dTUqG/fvkYztMd+OI79cBz74Tj2w3EdYT8459TU1KSsrCx163b6V3063JlQt27d1L9//9Nu07dv3y59kJ3AfjiO/XAc++E49sNx1vvhTGdAJ/DGBACAGSIEADCTVBHy+/2aP3++/H6/9VRMsR+OYz8cx344jv1wXLLthw73xgQAQNeRVGdCAIDOhQgBAMwQIQCAGSIEADBDhAAAZpIqQkuXLlVubq569uypESNG6M9//rP1lM6rkpIS+Xy+qCUYDFpPK+G2bt2qSZMmKSsrSz6fT+vWrYu63zmnkpISZWVlqVevXsrLy9OePXtsJptAZ9oP06ZNa3N8jBkzxmayCVJaWqpRo0YpLS1NGRkZuvnmm/X2229HbdMVjoez2Q/JcjwkTYTWrFmj2bNna968edq1a5euvvpqFRQU6MCBA9ZTO6+GDBmi2trayLJ7927rKSXckSNHNHz4cC1ZsqTd+x999FEtWrRIS5YsUVVVlYLBoK6//vrIxXA7izPtB0m64YYboo6PjRs714WAKysrVVRUpO3bt6u8vFytra3Kz8/XkSNHItt0hePhbPaDlCTHg0sSV111lbv77ruj1l122WXuRz/6kdGMzr/58+e74cOHW0/DlCT3wgsvRG4fO3bMBYNB98gjj0TWffLJJy4QCLgnn3zSYIbnx8n7wTnnpk6d6m666SaT+Vipr693klxlZaVzruseDyfvB+eS53hIijOhlpYW7dy5U/n5+VHr8/PztW3bNqNZ2di7d6+ysrKUm5urO+64Q++88471lExVV1errq4u6tjw+/269tpru9yxIUkVFRXKyMjQ4MGDNX36dNXX11tPKaEaGxslSenp6ZK67vFw8n44IRmOh6SI0KFDh3T06FFlZmZGrc/MzFRdXZ3RrM6/0aNHa8WKFdq0aZOeeuop1dXVady4cWpoaLCempkT//27+rEhSQUFBVq5cqU2b96sxx9/XFVVVZo4caKam5utp5YQzjkVFxdr/PjxGjp0qKSueTy0tx+k5DkeOtxXOZzOyd8v5Jxrs64zKygoiPx52LBhGjt2rAYMGKDly5eruLjYcGb2uvqxIUmTJ0+O/Hno0KEaOXKkcnJytGHDBhUWFhrOLDFmzpypN998U6+++mqb+7rS8XCq/ZAsx0NSnAn169dP3bt3b/Mvmfr6+jb/4ulK+vTpo2HDhmnv3r3WUzFz4t2BHBtthUIh5eTkdMrjY9asWVq/fr22bNkS9f1jXe14ONV+aE9HPR6SIkI9evTQiBEjVF5eHrW+vLxc48aNM5qVvebmZr311lsKhULWUzGTm5urYDAYdWy0tLSosrKySx8bktTQ0KCamppOdXw45zRz5kytXbtWmzdvVm5ubtT9XeV4ONN+aE+HPR4M3xThyerVq11qaqp7+umn3V//+lc3e/Zs16dPH7d//37rqZ03999/v6uoqHDvvPOO2759u7vxxhtdWlpap98HTU1NbteuXW7Xrl1Oklu0aJHbtWuXe/fdd51zzj3yyCMuEAi4tWvXut27d7spU6a4UCjkwuGw8czj63T7oampyd1///1u27Ztrrq62m3ZssWNHTvWXXzxxZ1qP9xzzz0uEAi4iooKV1tbG1k++uijyDZd4Xg4035IpuMhaSLknHO//vWvXU5OjuvRo4e78soro96O2BVMnjzZhUIhl5qa6rKyslxhYaHbs2eP9bQSbsuWLU5Sm2Xq1KnOueNvy50/f74LBoPO7/e7a665xu3evdt20glwuv3w0Ucfufz8fHfRRRe51NRUd8kll7ipU6e6AwcOWE87rtr7+SW5srKyyDZd4Xg4035IpuOB7xMCAJhJiteEAACdExECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADP/H+v8MOwfAvROAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "imshow(images[2],labels[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 1, 28, 28])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyInceptionNetwork(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(MyInceptionNetwork, self).__init__()\n",
    "        self.conv11 = nn.Conv2d(1,16,3,1,'same')\n",
    "        self.conv12 = nn.Conv2d(1,20,5,1,'same')\n",
    "        self.conv13 = nn.Conv2d(1,12,7,1,'same')\n",
    "\n",
    "        # Adding a Batch norm at every point, brings a HUGE IMPROVEMENT in ACCURACY \n",
    "        self.norm11 = nn.BatchNorm2d(12+20+16)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(12+20+16, 12+20+16, 1, 1) # 28, 28, 48\n",
    "\n",
    "        self.norm12 = nn.BatchNorm2d(12+20+16)\n",
    "\n",
    "        self.conv21 = nn.Conv2d(12+20+16, 64, 3, 2, 1)\n",
    "        self.conv22 = nn.Conv2d(12+20+16, 32, 5, 2, 2)\n",
    "        self.conv23 = nn.Conv2d(12+20+16, 16, 7, 2, 3)\n",
    "\n",
    "        self.norm21 = nn.BatchNorm2d(64+32+16)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(64+32+16, 64+32+16, 1, 1) # 14, 14, 112\n",
    "\n",
    "        self.norm22 = nn.BatchNorm2d(64+32+16)\n",
    "\n",
    "        self.conv31 = nn.Conv2d(64+32+16, 100, 1, 1, 0)\n",
    "        self.conv32 = nn.Conv2d(64+32+16, 100, 3, 1, 1)\n",
    "        self.conv33 = nn.Conv2d(64+32+16, 50, 5, 1, 2)\n",
    "        self.conv34 = nn.Conv2d(64+32+16, 50, 7, 1, 3)\n",
    "        self.maxpool1 = nn.MaxPool2d(3,1,padding = 1) # Stride = 1\n",
    "        self.conv_maxpool = nn.Conv2d(64+32+16, 32, 1, 1, 0)\n",
    "\n",
    "        self.norm31 = nn.BatchNorm2d(332)\n",
    "        self.conv3 = nn.Conv2d(332, 332, 7, 2) # 4, 4, 332\n",
    "        self.norm32 = nn.BatchNorm2d(332)\n",
    "\n",
    "        self.maxpool_final = nn.MaxPool2d(2,2) # 2, 2, 332\n",
    "\n",
    "        self.linear1 = nn.Linear(332*4,500)\n",
    "        self.norm4 = nn.BatchNorm1d(500)\n",
    "        self.linear2 = nn.Linear(500,100)\n",
    "        self.norm5 = nn.BatchNorm1d(100)\n",
    "        self.linear3 = nn.Linear(100,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = torch.relu(self.conv11(x))\n",
    "        x2 = torch.relu(self.conv12(x))\n",
    "        x3 = torch.relu(self.conv13(x))\n",
    "        x = x1\n",
    "        x = torch.cat((x,x2),1)\n",
    "        x = torch.cat((x,x3),1)\n",
    "\n",
    "        x = self.norm12(torch.relu(self.conv1(self.norm11(x))))\n",
    "\n",
    "        x1 = torch.relu(self.conv21(x))\n",
    "        x2 = torch.relu(self.conv22(x))\n",
    "        x3 = torch.relu(self.conv23(x))\n",
    "        x = x1\n",
    "        x = torch.cat((x,x2),1)\n",
    "        x = torch.cat((x,x3),1)\n",
    "\n",
    "        x = self.norm22(torch.relu(self.conv2(self.norm21(x))))\n",
    "\n",
    "        x1 = torch.relu(self.conv31(x))\n",
    "        x2 = torch.relu(self.conv32(x))\n",
    "        x3 = torch.relu(self.conv33(x))\n",
    "        x4 = torch.relu(self.conv34(x))\n",
    "        x5 = torch.relu(self.conv_maxpool(self.maxpool1(x)))\n",
    "        x = x1\n",
    "        x = torch.cat((x,x2),1)\n",
    "        x = torch.cat((x,x3),1)\n",
    "        x = torch.cat((x,x4),1)\n",
    "        x = torch.cat((x,x5),1)\n",
    "\n",
    "        x = self.maxpool_final(self.norm32(torch.relu(self.conv3(self.norm31(x)))))\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.norm4(torch.relu(self.linear1(x)))\n",
    "        x = self.norm5(torch.relu(self.linear2(x)))\n",
    "        x = torch.relu(self.linear3(x))\n",
    "\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "incnet = MyInceptionNetwork().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(incnet.parameters(), lr = learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 6, gamma = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 28, 28]             160\n",
      "            Conv2d-2           [-1, 20, 28, 28]             520\n",
      "            Conv2d-3           [-1, 12, 28, 28]             600\n",
      "       BatchNorm2d-4           [-1, 48, 28, 28]              96\n",
      "            Conv2d-5           [-1, 48, 28, 28]           2,352\n",
      "       BatchNorm2d-6           [-1, 48, 28, 28]              96\n",
      "            Conv2d-7           [-1, 64, 14, 14]          27,712\n",
      "            Conv2d-8           [-1, 32, 14, 14]          38,432\n",
      "            Conv2d-9           [-1, 16, 14, 14]          37,648\n",
      "      BatchNorm2d-10          [-1, 112, 14, 14]             224\n",
      "           Conv2d-11          [-1, 112, 14, 14]          12,656\n",
      "      BatchNorm2d-12          [-1, 112, 14, 14]             224\n",
      "           Conv2d-13          [-1, 100, 14, 14]          11,300\n",
      "           Conv2d-14          [-1, 100, 14, 14]         100,900\n",
      "           Conv2d-15           [-1, 50, 14, 14]         140,050\n",
      "           Conv2d-16           [-1, 50, 14, 14]         274,450\n",
      "        MaxPool2d-17          [-1, 112, 14, 14]               0\n",
      "           Conv2d-18           [-1, 32, 14, 14]           3,616\n",
      "      BatchNorm2d-19          [-1, 332, 14, 14]             664\n",
      "           Conv2d-20            [-1, 332, 4, 4]       5,401,308\n",
      "      BatchNorm2d-21            [-1, 332, 4, 4]             664\n",
      "        MaxPool2d-22            [-1, 332, 2, 2]               0\n",
      "           Linear-23                  [-1, 500]         664,500\n",
      "      BatchNorm1d-24                  [-1, 500]           1,000\n",
      "           Linear-25                  [-1, 100]          50,100\n",
      "      BatchNorm1d-26                  [-1, 100]             200\n",
      "           Linear-27                   [-1, 10]           1,010\n",
      "================================================================\n",
      "Total params: 6,770,482\n",
      "Trainable params: 6,770,482\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 3.08\n",
      "Params size (MB): 25.83\n",
      "Estimated Total Size (MB): 28.91\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(copy.deepcopy(incnet).to('cpu'), (1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50; Loss = 0.064370; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Dev Accuracy: 98.98%\n",
      "--------------------\n",
      "Epoch 2/50; Loss = 0.010853; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Dev Accuracy: 99.08%\n",
      "--------------------\n",
      "Epoch 3/50; Loss = 0.058730; LR = [0.001]\n",
      "Dev Accuracy: 97.41%\n",
      "--------------------\n",
      "Epoch 4/50; Loss = 0.001263; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Dev Accuracy: 99.30%\n",
      "--------------------\n",
      "Epoch 5/50; Loss = 0.003657; LR = [0.001]\n",
      "Dev Accuracy: 99.28%\n",
      "--------------------\n",
      "Epoch 6/50; Loss = 0.008851; LR = [0.001]\n",
      "Dev Accuracy: 99.13%\n",
      "--------------------\n",
      "Epoch 7/50; Loss = 0.010107; LR = [0.001]\n",
      "Dev Accuracy: 99.06%\n",
      "--------------------\n",
      "Epoch 8/50; Loss = 0.129500; LR = [0.001]\n",
      "Dev Accuracy: 99.28%\n",
      "--------------------\n",
      "Epoch 9/50; Loss = 0.001096; LR = [0.0005]\n",
      "Dev Accuracy: 99.19%\n",
      "--------------------\n",
      "Epoch 10/50; Loss = 0.000528; LR = [0.0005]\n",
      "SAVED MODEL WEIGHTS\n",
      "Dev Accuracy: 99.46%\n",
      "--------------------\n",
      "Epoch 11/50; Loss = 0.000085; LR = [0.0005]\n",
      "SAVED MODEL WEIGHTS\n",
      "Dev Accuracy: 99.55%\n",
      "--------------------\n",
      "Epoch 12/50; Loss = 0.000491; LR = [0.0005]\n",
      "SAVED MODEL WEIGHTS\n",
      "Dev Accuracy: 99.55%\n",
      "--------------------\n",
      "Epoch 13/50; Loss = 0.000060; LR = [0.0005]\n",
      "SAVED MODEL WEIGHTS\n",
      "Dev Accuracy: 99.56%\n",
      "--------------------\n",
      "Epoch 14/50; Loss = 0.000102; LR = [0.0005]\n",
      "Dev Accuracy: 99.54%\n",
      "--------------------\n",
      "Epoch 15/50; Loss = 0.000040; LR = [0.0005]\n",
      "Dev Accuracy: 99.55%\n",
      "--------------------\n",
      "Epoch 16/50; Loss = 0.000052; LR = [0.0005]\n",
      "Dev Accuracy: 99.53%\n",
      "--------------------\n",
      "Epoch 17/50; Loss = 0.000052; LR = [0.0005]\n",
      "SAVED MODEL WEIGHTS\n",
      "Dev Accuracy: 99.59%\n",
      "--------------------\n",
      "Epoch 18/50; Loss = 0.000094; LR = [0.00025]\n",
      "Dev Accuracy: 99.55%\n",
      "--------------------\n",
      "Epoch 19/50; Loss = 0.000034; LR = [0.00025]\n",
      "Dev Accuracy: 99.58%\n",
      "--------------------\n",
      "Epoch 20/50; Loss = 0.000026; LR = [0.00025]\n",
      "Dev Accuracy: 99.57%\n",
      "--------------------\n",
      "Epoch 21/50; Loss = 0.001128; LR = [0.00025]\n",
      "Dev Accuracy: 99.58%\n",
      "--------------------\n",
      "Epoch 22/50; Loss = 0.000010; LR = [0.00025]\n",
      "Dev Accuracy: 99.56%\n",
      "--------------------\n",
      "Epoch 23/50; Loss = 0.000009; LR = [0.00025]\n",
      "Dev Accuracy: 99.58%\n",
      "--------------------\n",
      "Epoch 24/50; Loss = 0.000030; LR = [0.00025]\n",
      "Dev Accuracy: 99.54%\n",
      "--------------------\n",
      "Epoch 25/50; Loss = 0.000015; LR = [0.00025]\n",
      "Dev Accuracy: 99.56%\n",
      "--------------------\n",
      "Epoch 26/50; Loss = 0.000028; LR = [0.00025]\n",
      "Dev Accuracy: 99.58%\n",
      "--------------------\n",
      "Epoch 27/50; Loss = 0.000023; LR = [0.000125]\n",
      "Dev Accuracy: 99.58%\n",
      "--------------------\n",
      "Epoch 28/50; Loss = 0.000033; LR = [0.000125]\n",
      "Dev Accuracy: 99.58%\n",
      "--------------------\n",
      "Epoch 29/50; Loss = 0.000009; LR = [0.000125]\n",
      "Dev Accuracy: 99.58%\n",
      "--------------------\n",
      "Epoch 30/50; Loss = 0.000008; LR = [0.000125]\n",
      "Dev Accuracy: 99.57%\n",
      "--------------------\n",
      "Epoch 31/50; Loss = 0.000011; LR = [0.000125]\n",
      "Dev Accuracy: 99.56%\n",
      "--------------------\n",
      "Epoch 32/50; Loss = 0.000033; LR = [0.000125]\n",
      "Dev Accuracy: 99.57%\n",
      "--------------------\n",
      "Epoch 33/50; Loss = 0.000023; LR = [0.000125]\n",
      "Dev Accuracy: 99.56%\n",
      "--------------------\n",
      "Epoch 34/50; Loss = 0.000027; LR = [0.000125]\n",
      "Dev Accuracy: 99.56%\n",
      "--------------------\n",
      "Epoch 35/50; Loss = 0.000028; LR = [0.000125]\n",
      "Dev Accuracy: 99.56%\n",
      "--------------------\n",
      "Epoch 36/50; Loss = 0.000010; LR = [6.25e-05]\n",
      "Dev Accuracy: 99.58%\n",
      "--------------------\n",
      "Epoch 37/50; Loss = 0.000013; LR = [6.25e-05]\n",
      "SAVED MODEL WEIGHTS\n",
      "Dev Accuracy: 99.59%\n",
      "--------------------\n",
      "Epoch 38/50; Loss = 0.000006; LR = [6.25e-05]\n",
      "Dev Accuracy: 99.58%\n",
      "--------------------\n",
      "Epoch 39/50; Loss = 0.000017; LR = [6.25e-05]\n",
      "Dev Accuracy: 99.58%\n",
      "--------------------\n",
      "Epoch 40/50; Loss = 0.000015; LR = [6.25e-05]\n",
      "Dev Accuracy: 99.55%\n",
      "--------------------\n",
      "Epoch 41/50; Loss = 0.000006; LR = [6.25e-05]\n",
      "Dev Accuracy: 99.56%\n",
      "--------------------\n",
      "Epoch 42/50; Loss = 0.000004; LR = [6.25e-05]\n",
      "Dev Accuracy: 99.56%\n",
      "--------------------\n",
      "Epoch 43/50; Loss = 0.000008; LR = [6.25e-05]\n",
      "Dev Accuracy: 99.54%\n",
      "--------------------\n",
      "Epoch 44/50; Loss = 0.000078; LR = [6.25e-05]\n",
      "Dev Accuracy: 99.56%\n",
      "--------------------\n",
      "Epoch 45/50; Loss = 0.000010; LR = [3.125e-05]\n",
      "Dev Accuracy: 99.55%\n",
      "--------------------\n",
      "Epoch 46/50; Loss = 0.000004; LR = [3.125e-05]\n",
      "SAVED MODEL WEIGHTS\n",
      "Dev Accuracy: 99.59%\n",
      "--------------------\n",
      "Epoch 47/50; Loss = 0.000009; LR = [3.125e-05]\n",
      "Dev Accuracy: 99.57%\n",
      "--------------------\n",
      "Epoch 48/50; Loss = 0.000006; LR = [3.125e-05]\n",
      "Dev Accuracy: 99.57%\n",
      "--------------------\n",
      "Epoch 49/50; Loss = 0.000006; LR = [3.125e-05]\n",
      "Dev Accuracy: 99.55%\n",
      "--------------------\n",
      "Epoch 50/50; Loss = 0.000005; LR = [3.125e-05]\n",
      "Dev Accuracy: 99.56%\n",
      "--------------------\n",
      "Finished Training!\n",
      "Best Test Accuracy = 99.59%\n",
      "Time Taken = 96.0m 34.00414705276489s\n"
     ]
    }
   ],
   "source": [
    "best_weights = copy.deepcopy(incnet.state_dict())\n",
    "max = 0\n",
    "val_acc = 0\n",
    "train_acc = 0\n",
    "tic = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    incnet.train()\n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        preds = incnet.forward(images)\n",
    "        loss = criterion(preds, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step() # Decaying learning rate per 25 epochs by 0.2 times\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}; Loss = {loss.item():.6f}; LR = {scheduler.get_last_lr()}')\n",
    "    with torch.no_grad():\n",
    "        n_samples = 0\n",
    "        n_correct = 0\n",
    "        incnet.eval()\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device) # From 128, 1, 28, 28 ---> 128, 784\n",
    "            labels = labels.to(device)\n",
    "            pred_outputs1 = incnet(images)\n",
    "            _, actual_preds1 = torch.max(pred_outputs1, 1) # Returns value, index\n",
    "            n_samples += labels.shape[0]\n",
    "            n_correct += (actual_preds1 == labels).sum().item()\n",
    "        val_acc = n_correct/n_samples * 100\n",
    "\n",
    "        if (max <= (n_correct/n_samples * 100)):\n",
    "            print('SAVED MODEL WEIGHTS')\n",
    "            max = val_acc\n",
    "            best_weights = copy.deepcopy(incnet.state_dict())\n",
    "        \n",
    "        if((epoch+1) % 10 == 0):\n",
    "            n_samples = 0\n",
    "            n_correct = 0\n",
    "            \n",
    "            for images, labels in train_loader:\n",
    "                images = images.to(device) # From 128, 1, 28, 28 ---> 128, 784\n",
    "                labels = labels.to(device)\n",
    "                pred_outputs1 = incnet(images)\n",
    "                _, actual_preds1 = torch.max(pred_outputs1, 1) # Returns value, index\n",
    "                n_samples += labels.shape[0]\n",
    "                n_correct += (actual_preds1 == labels).sum().item()\n",
    "            train_acc = n_correct/n_samples * 100\n",
    "            print(f'Train Accuracy: {train_acc:.2f}%')\n",
    "    print(f'Dev Accuracy: {val_acc:.2f}%')\n",
    "    print(\"-\"*20)\n",
    "print('Finished Training!')\n",
    "print(f'Best Test Accuracy = {max}%')\n",
    "print(f'Time Taken = {(time.time()-tic)//60:.0f}m {(time.time()-tic)%60:.0f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "incnet.load_state_dict(best_weights)\n",
    "torch.save(incnet, 'models/simple_incnet_mnist.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy = 99.93%\n"
     ]
    }
   ],
   "source": [
    "incnet.eval()\n",
    "for images, labels in train_loader: # Train Accuracy\n",
    "    images = images.to(device) # From 128, 1, 28, 28 ---> 128, 784\n",
    "    labels = labels.to(device)\n",
    "    pred_outputs1 = incnet(images)\n",
    "    _, actual_preds1 = torch.max(pred_outputs1, 1) # Returns value, index\n",
    "    n_samples += labels.shape[0]\n",
    "    n_correct += (actual_preds1 == labels).sum().item()\n",
    "train_acc = n_correct/n_samples * 100\n",
    "print(f'Training Accuracy = {train_acc:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "193f6b5c64d175a70f8bc370a8e28557b54eddf9787b8dde324aa4d68183bc16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

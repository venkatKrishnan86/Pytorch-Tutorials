{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(10)\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 0.5\n",
    "std_dev = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform1 = transforms.Compose([\n",
    "    transforms.AutoAugment(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean,std_dev)\n",
    "])\n",
    "transform2 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean,std_dev)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='../datasets',\n",
    "    train = True,\n",
    "    transform=transform2 #download is False in default\n",
    ")\n",
    "\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root='../datasets',\n",
    "    train = False,\n",
    "    transform=transform2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "batch_size = 256\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset = train_data,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset = test_data,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, label):\n",
    "    img = img * std_dev + mean  # unnormalize\n",
    "    plt.imshow(img.reshape(img.shape[1],img.shape[2],img.shape[0]), cmap = 'gray')\n",
    "    plt.title(f'Label {label}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "imshow(images[2],labels[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 1, 28, 28])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myResNet(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(myResNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1,4,5,1,'same') # 4, 28, 28\n",
    "        # self.act1_1 = nn.ReLU() \n",
    "        self.norm1 = nn.BatchNorm2d(4)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(4,16,5,1,'same') # 16, 28, 28\n",
    "        self.conv1to2 = nn.Conv2d(1,16,3,1,'same') # 16, 28, 28\n",
    "        # self.act1_2 = nn.ReLU()\n",
    "        self.norm2 = nn.BatchNorm2d(16)\n",
    "            \n",
    "        self.pool1 = nn.MaxPool2d(2, 2) # 16, 28, 28 --> 16, 14, 14\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(16,64,3,1,'same') # 64, 14, 14\n",
    "        self.conv1to3 = nn.Conv2d(1,64,3,2,1) # 64, 14, 14\n",
    "        # self.act2_1 = nn.ReLU()\n",
    "        self.norm3 = nn.BatchNorm2d(64)\n",
    "            \n",
    "        self.conv4 = nn.Conv2d(64,256,3,1,'same')  # 256, 14, 14\n",
    "        self.conv1to4 = nn.Conv2d(1,256,3,2,1) # 256, 14, 14\n",
    "        # self.act2_2 = nn.ReLU()\n",
    "        self.norm4 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.pool2 = nn.MaxPool2d(2, 2) # 256, 14, 14 --> 256, 7, 7\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.lin5 = nn.Linear(256*7*7, 200)\n",
    "        self.lin1to5 = nn.Linear(28*28*1, 200)\n",
    "        # self.act4 = nn.ReLU()\n",
    "        self.norm5 = nn.BatchNorm1d(200)\n",
    "\n",
    "        self.lin6 = nn.Linear(200, 85)\n",
    "        self.lin1to6 = nn.Linear(28*28*1, 85)\n",
    "        # self.act5 = nn.ReLU()\n",
    "        self.norm6 = nn.BatchNorm1d(85)\n",
    "\n",
    "        self.lin_fin = nn.Linear(85,10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_temp1 = x\n",
    "        x = self.norm1(torch.relu(self.conv1(x)))\n",
    "        \n",
    "        x_temp2 = x\n",
    "        x = self.norm2(torch.relu(self.conv2(x)+self.conv1to2(x_temp1))) # Residual\n",
    "\n",
    "        x_temp3 = x\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.norm3(torch.relu(self.conv3(x)+self.conv1to3(x_temp1)))\n",
    "\n",
    "        x_temp4 = x\n",
    "        x = self.norm4(torch.relu(self.conv4(x)+self.conv1to4(x_temp1))) # Residual\n",
    "\n",
    "        x_temp5 = x\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.norm5(torch.relu(self.lin5(x)+self.lin1to5(self.flatten(x_temp1))))\n",
    "\n",
    "        x_temp6 = x\n",
    "        x = self.norm6(torch.relu(self.lin6(x)+self.lin1to6(self.flatten(x_temp1))))\n",
    "        x = self.lin_fin(x)\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = myResNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(resnet.parameters(), lr = learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 9, gamma = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 4, 28, 28]             104\n",
      "       BatchNorm2d-2            [-1, 4, 28, 28]               8\n",
      "            Conv2d-3           [-1, 16, 28, 28]           1,616\n",
      "            Conv2d-4           [-1, 16, 28, 28]             160\n",
      "       BatchNorm2d-5           [-1, 16, 28, 28]              32\n",
      "         MaxPool2d-6           [-1, 16, 14, 14]               0\n",
      "            Conv2d-7           [-1, 64, 14, 14]           9,280\n",
      "            Conv2d-8           [-1, 64, 14, 14]             640\n",
      "       BatchNorm2d-9           [-1, 64, 14, 14]             128\n",
      "           Conv2d-10          [-1, 256, 14, 14]         147,712\n",
      "           Conv2d-11          [-1, 256, 14, 14]           2,560\n",
      "      BatchNorm2d-12          [-1, 256, 14, 14]             512\n",
      "        MaxPool2d-13            [-1, 256, 7, 7]               0\n",
      "          Flatten-14                [-1, 12544]               0\n",
      "           Linear-15                  [-1, 200]       2,509,000\n",
      "          Flatten-16                  [-1, 784]               0\n",
      "           Linear-17                  [-1, 200]         157,000\n",
      "      BatchNorm1d-18                  [-1, 200]             400\n",
      "           Linear-19                   [-1, 85]          17,085\n",
      "          Flatten-20                  [-1, 784]               0\n",
      "           Linear-21                   [-1, 85]          66,725\n",
      "      BatchNorm1d-22                   [-1, 85]             170\n",
      "           Linear-23                   [-1, 10]             860\n",
      "================================================================\n",
      "Total params: 2,913,992\n",
      "Trainable params: 2,913,992\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 2.00\n",
      "Params size (MB): 11.12\n",
      "Estimated Total Size (MB): 13.12\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(resnet, (1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50; Loss = 0.117283; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 98.65%\n",
      "Dev Accuracy: 98.13%\n",
      "--------------------\n",
      "Epoch 2/50; Loss = 0.014636; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.33%\n",
      "Dev Accuracy: 98.86%\n",
      "--------------------\n",
      "Epoch 3/50; Loss = 0.010203; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.59%\n",
      "Dev Accuracy: 99.00%\n",
      "--------------------\n",
      "Epoch 4/50; Loss = 0.044522; LR = [0.001]\n",
      "Train Accuracy: 99.52%\n",
      "Dev Accuracy: 98.75%\n",
      "--------------------\n",
      "Epoch 5/50; Loss = 0.057145; LR = [0.001]\n",
      "Train Accuracy: 99.54%\n",
      "Dev Accuracy: 98.93%\n",
      "--------------------\n",
      "Epoch 6/50; Loss = 0.001099; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.87%\n",
      "Dev Accuracy: 99.10%\n",
      "--------------------\n",
      "Epoch 7/50; Loss = 0.002718; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.75%\n",
      "Dev Accuracy: 99.14%\n",
      "--------------------\n",
      "Epoch 8/50; Loss = 0.001473; LR = [0.001]\n",
      "Train Accuracy: 99.79%\n",
      "Dev Accuracy: 99.06%\n",
      "--------------------\n",
      "Epoch 9/50; Loss = 0.011545; LR = [0.0005]\n",
      "Train Accuracy: 99.62%\n",
      "Dev Accuracy: 98.96%\n",
      "--------------------\n",
      "Epoch 10/50; Loss = 0.000550; LR = [0.0005]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.95%\n",
      "Dev Accuracy: 99.29%\n",
      "--------------------\n",
      "Epoch 11/50; Loss = 0.000985; LR = [0.0005]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.98%\n",
      "Dev Accuracy: 99.38%\n",
      "--------------------\n",
      "Epoch 12/50; Loss = 0.000188; LR = [0.0005]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.98%\n",
      "Dev Accuracy: 99.38%\n",
      "--------------------\n",
      "Epoch 13/50; Loss = 0.000238; LR = [0.0005]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.96%\n",
      "Dev Accuracy: 99.38%\n",
      "--------------------\n",
      "Epoch 14/50; Loss = 0.000160; LR = [0.0005]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.96%\n",
      "Dev Accuracy: 99.39%\n",
      "--------------------\n",
      "Epoch 15/50; Loss = 0.000052; LR = [0.0005]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.98%\n",
      "Dev Accuracy: 99.41%\n",
      "--------------------\n",
      "Epoch 16/50; Loss = 0.000106; LR = [0.0005]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.98%\n",
      "Dev Accuracy: 99.42%\n",
      "--------------------\n",
      "Epoch 17/50; Loss = 0.000049; LR = [0.0005]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.97%\n",
      "Dev Accuracy: 99.42%\n",
      "--------------------\n",
      "Epoch 18/50; Loss = 0.000065; LR = [0.00025]\n",
      "Train Accuracy: 99.94%\n",
      "Dev Accuracy: 99.41%\n",
      "--------------------\n",
      "Epoch 19/50; Loss = 0.000158; LR = [0.00025]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.97%\n",
      "Dev Accuracy: 99.42%\n",
      "--------------------\n",
      "Epoch 20/50; Loss = 0.000083; LR = [0.00025]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.96%\n",
      "Dev Accuracy: 99.43%\n",
      "--------------------\n",
      "Epoch 21/50; Loss = 0.000099; LR = [0.00025]\n",
      "Train Accuracy: 99.98%\n",
      "Dev Accuracy: 99.42%\n",
      "--------------------\n",
      "Epoch 22/50; Loss = 0.000053; LR = [0.00025]\n",
      "Train Accuracy: 99.98%\n",
      "Dev Accuracy: 99.41%\n",
      "--------------------\n",
      "Epoch 23/50; Loss = 0.000052; LR = [0.00025]\n",
      "Train Accuracy: 99.96%\n",
      "Dev Accuracy: 99.42%\n",
      "--------------------\n",
      "Epoch 24/50; Loss = 0.000088; LR = [0.00025]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.98%\n",
      "Dev Accuracy: 99.43%\n",
      "--------------------\n",
      "Epoch 25/50; Loss = 0.000027; LR = [0.00025]\n",
      "Train Accuracy: 99.98%\n",
      "Dev Accuracy: 99.42%\n",
      "--------------------\n",
      "Epoch 26/50; Loss = 0.000041; LR = [0.00025]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.97%\n",
      "Dev Accuracy: 99.43%\n",
      "--------------------\n",
      "Epoch 27/50; Loss = 0.000051; LR = [0.000125]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.98%\n",
      "Dev Accuracy: 99.43%\n",
      "--------------------\n",
      "Epoch 28/50; Loss = 0.000047; LR = [0.000125]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.98%\n",
      "Dev Accuracy: 99.44%\n",
      "--------------------\n",
      "Epoch 29/50; Loss = 0.000012; LR = [0.000125]\n",
      "Train Accuracy: 99.97%\n",
      "Dev Accuracy: 99.43%\n",
      "--------------------\n",
      "Epoch 30/50; Loss = 0.000154; LR = [0.000125]\n",
      "Train Accuracy: 99.96%\n",
      "Dev Accuracy: 99.43%\n",
      "--------------------\n",
      "Epoch 31/50; Loss = 0.000017; LR = [0.000125]\n",
      "Train Accuracy: 99.98%\n",
      "Dev Accuracy: 99.42%\n",
      "--------------------\n",
      "Epoch 32/50; Loss = 0.000016; LR = [0.000125]\n",
      "Train Accuracy: 99.95%\n",
      "Dev Accuracy: 99.43%\n",
      "--------------------\n",
      "Epoch 33/50; Loss = 0.000099; LR = [0.000125]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.98%\n",
      "Dev Accuracy: 99.44%\n",
      "--------------------\n",
      "Epoch 34/50; Loss = 0.000014; LR = [0.000125]\n",
      "Train Accuracy: 99.97%\n",
      "Dev Accuracy: 99.43%\n",
      "--------------------\n",
      "Epoch 35/50; Loss = 0.000010; LR = [0.000125]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.96%\n",
      "Dev Accuracy: 99.45%\n",
      "--------------------\n",
      "Epoch 36/50; Loss = 0.000025; LR = [6.25e-05]\n",
      "Train Accuracy: 99.97%\n",
      "Dev Accuracy: 99.38%\n",
      "--------------------\n",
      "Epoch 37/50; Loss = 0.000023; LR = [6.25e-05]\n",
      "Train Accuracy: 99.97%\n",
      "Dev Accuracy: 99.44%\n",
      "--------------------\n",
      "Epoch 38/50; Loss = 0.000010; LR = [6.25e-05]\n",
      "Train Accuracy: 99.97%\n",
      "Dev Accuracy: 99.44%\n",
      "--------------------\n",
      "Epoch 39/50; Loss = 0.000008; LR = [6.25e-05]\n",
      "Train Accuracy: 99.97%\n",
      "Dev Accuracy: 99.42%\n",
      "--------------------\n",
      "Epoch 40/50; Loss = 0.000020; LR = [6.25e-05]\n",
      "Train Accuracy: 99.96%\n",
      "Dev Accuracy: 99.44%\n",
      "--------------------\n",
      "Epoch 41/50; Loss = 0.000017; LR = [6.25e-05]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.98%\n",
      "Dev Accuracy: 99.45%\n",
      "--------------------\n",
      "Epoch 42/50; Loss = 0.000018; LR = [6.25e-05]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.98%\n",
      "Dev Accuracy: 99.46%\n",
      "--------------------\n",
      "Epoch 43/50; Loss = 0.000008; LR = [6.25e-05]\n",
      "Train Accuracy: 99.98%\n",
      "Dev Accuracy: 99.43%\n",
      "--------------------\n",
      "Epoch 44/50; Loss = 0.000004; LR = [6.25e-05]\n",
      "Train Accuracy: 99.97%\n",
      "Dev Accuracy: 99.45%\n",
      "--------------------\n",
      "Epoch 45/50; Loss = 0.000004; LR = [3.125e-05]\n",
      "Train Accuracy: 99.96%\n",
      "Dev Accuracy: 99.45%\n",
      "--------------------\n",
      "Epoch 46/50; Loss = 0.000008; LR = [3.125e-05]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.98%\n",
      "Dev Accuracy: 99.47%\n",
      "--------------------\n",
      "Epoch 47/50; Loss = 0.000012; LR = [3.125e-05]\n",
      "Train Accuracy: 99.98%\n",
      "Dev Accuracy: 99.41%\n",
      "--------------------\n",
      "Epoch 48/50; Loss = 0.000009; LR = [3.125e-05]\n",
      "Train Accuracy: 99.98%\n",
      "Dev Accuracy: 99.46%\n",
      "--------------------\n",
      "Epoch 49/50; Loss = 0.000034; LR = [3.125e-05]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.98%\n",
      "Dev Accuracy: 99.48%\n",
      "--------------------\n",
      "Epoch 50/50; Loss = 0.000007; LR = [3.125e-05]\n",
      "Train Accuracy: 99.98%\n",
      "Dev Accuracy: 99.45%\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "best_weights = copy.deepcopy(resnet.state_dict())\n",
    "max = 0\n",
    "val_acc = 0\n",
    "train_acc = 0\n",
    "for epoch in range(num_epochs):\n",
    "    resnet.train()\n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        preds = resnet.forward(images)\n",
    "        loss = criterion(preds, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step() # Decaying learning rate per 25 epochs by 0.2 times\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}; Loss = {loss.item():.6f}; LR = {scheduler.get_last_lr()}')\n",
    "    with torch.no_grad():\n",
    "        n_samples = 0\n",
    "        n_correct = 0\n",
    "        resnet.eval()\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device) # From 128, 1, 28, 28 ---> 128, 784\n",
    "            labels = labels.to(device)\n",
    "            pred_outputs1 = resnet(images)\n",
    "            _, actual_preds1 = torch.max(pred_outputs1, 1) # Returns value, index\n",
    "            n_samples += labels.shape[0]\n",
    "            n_correct += (actual_preds1 == labels).sum().item()\n",
    "        val_acc = n_correct/n_samples * 100\n",
    "\n",
    "        if (max <= (n_correct/n_samples * 100)):\n",
    "            print('SAVED MODEL WEIGHTS')\n",
    "            max = val_acc\n",
    "            best_weights = copy.deepcopy(resnet.state_dict())\n",
    "\n",
    "        n_samples = 0\n",
    "        n_correct = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device) # From 128, 1, 28, 28 ---> 128, 784\n",
    "            labels = labels.to(device)\n",
    "            pred_outputs1 = resnet(images)\n",
    "            _, actual_preds1 = torch.max(pred_outputs1, 1) # Returns value, index\n",
    "            n_samples += labels.shape[0]\n",
    "            n_correct += (actual_preds1 == labels).sum().item()\n",
    "        train_acc = n_correct/n_samples * 100\n",
    "    \n",
    "    print(f'Train Accuracy: {train_acc:.2f}%')\n",
    "    print(f'Dev Accuracy: {val_acc:.2f}%')\n",
    "    print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet.load_state_dict(best_weights)\n",
    "# torch.save(resnet, 'models/fully_nested_resnet_mnist.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected ResNet (DenseNet) with Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullNestedResNet(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(FullNestedResNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1,4,5,1,'same') # 4, 28, 28\n",
    "        # self.act1 = nn.ReLU() \n",
    "        self.norm1 = nn.BatchNorm2d(4)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(4,16,5,1,'same') # 16, 28, 28\n",
    "        self.conv1to2 = nn.Conv2d(1,16,3,1,'same') # 16, 28, 28\n",
    "        self.norm1to2 = nn.BatchNorm2d(16)\n",
    "        # self.act2 = nn.ReLU()\n",
    "        self.norm2 = nn.BatchNorm2d(16)\n",
    "            \n",
    "        self.pool1 = nn.MaxPool2d(2, 2) # 16, 28, 28 --> 16, 14, 14\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(16,64,3,1,'same') # 64, 14, 14\n",
    "        self.conv1to3 = nn.Conv2d(1,64,3,2,1) # 64, 14, 14\n",
    "        self.norm1to3 = nn.BatchNorm2d(64) # 64, 14, 14\n",
    "\n",
    "        self.conv2to3 = nn.Conv2d(4,64,3,2,1)\n",
    "        self.norm2to3 = nn.BatchNorm2d(64)\n",
    "\n",
    "        # self.act3 = nn.ReLU()\n",
    "        self.norm3 = nn.BatchNorm2d(64)\n",
    "            \n",
    "        self.conv4 = nn.Conv2d(64,256,3,1,'same')  # 256, 14, 14\n",
    "        self.conv1to4 = nn.Conv2d(1,256,3,2,1) # 256, 14, 14\n",
    "        self.norm1to4 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.conv2to4 = nn.Conv2d(4,256,3,2,1) # 256, 14, 14\n",
    "        self.norm2to4 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.conv3to4 = nn.Conv2d(16,256,3,1,1) # 256, 14, 14 # Stride = 1\n",
    "        self.norm3to4 = nn.BatchNorm2d(256)\n",
    "\n",
    "        # self.act4 = nn.ReLU()\n",
    "        self.norm4 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.pool2 = nn.MaxPool2d(2, 2) # 256, 14, 14 --> 256, 7, 7\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.lin5 = nn.Linear(256*7*7, 200)\n",
    "        self.lin1to5 = nn.Linear(28*28*1, 200)\n",
    "        self.norm1to5 = nn.BatchNorm1d(200)\n",
    "\n",
    "        self.lin2to5 = nn.Linear(28*28*4, 200)\n",
    "        self.norm2to5 = nn.BatchNorm1d(200)\n",
    "\n",
    "        self.lin3to5 = nn.Linear(14*14*16, 200)\n",
    "        self.norm3to5 = nn.BatchNorm1d(200)\n",
    "\n",
    "        self.lin4to5 = nn.Linear(14*14*64, 200)\n",
    "        self.norm4to5 = nn.BatchNorm1d(200)\n",
    "        # self.act4 = nn.ReLU()\n",
    "        self.norm5 = nn.BatchNorm1d(200)\n",
    "\n",
    "        self.lin6 = nn.Linear(200, 85)\n",
    "        self.lin1to6 = nn.Linear(28*28*1, 85)\n",
    "        self.norm1to6 = nn.BatchNorm1d(85)\n",
    "\n",
    "        self.lin2to6 = nn.Linear(28*28*4, 85)\n",
    "        self.norm2to6 = nn.BatchNorm1d(85)\n",
    "\n",
    "        self.lin3to6 = nn.Linear(14*14*16, 85)\n",
    "        self.norm3to6 = nn.BatchNorm1d(85)\n",
    "\n",
    "        self.lin4to6 = nn.Linear(14*14*64, 85)\n",
    "        self.norm4to6 = nn.BatchNorm1d(85)\n",
    "\n",
    "        self.lin5to6 = nn.Linear(7*7*256, 85)\n",
    "        self.norm5to6 = nn.BatchNorm1d(85)\n",
    "        # self.act5 = nn.ReLU()\n",
    "        self.norm6 = nn.BatchNorm1d(85)\n",
    "\n",
    "        self.lin_fin = nn.Linear(85,10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_temp1 = x\n",
    "        x = self.norm1(torch.relu(self.conv1(x)))\n",
    "        \n",
    "        x_temp2 = x\n",
    "        x = self.conv2(x) + self.norm1to2(self.conv1to2(x_temp1))\n",
    "        x = self.norm2(torch.relu(x)) # Residual\n",
    "\n",
    "        x = self.pool1(x)\n",
    "        x_temp3 = x\n",
    "\n",
    "        x = self.conv3(x) + self.norm1to3(self.conv1to3(x_temp1)) + self.norm2to3(self.conv2to3(x_temp2))\n",
    "        x = self.norm3(torch.relu(x))\n",
    "\n",
    "        x_temp4 = x\n",
    "\n",
    "        x = self.conv4(x) + self.norm1to4(self.conv1to4(x_temp1)) + self.norm2to4(self.conv2to4(x_temp2)) + self.norm3to4(self.conv3to4(x_temp3))\n",
    "        x = self.norm4(torch.relu(x)) # Residual\n",
    "\n",
    "        x = self.pool2(x)\n",
    "        x_temp5 = x\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.lin5(x) + self.norm1to5(self.lin1to5(self.flatten(x_temp1))) + self.norm2to5(self.lin2to5(self.flatten(x_temp2))) + self.norm3to5(self.lin3to5(self.flatten(x_temp3))) + self.norm4to5(self.lin4to5(self.flatten(x_temp4)))\n",
    "        x = self.norm5(torch.relu(x))\n",
    "\n",
    "        x = self.lin6(x) + self.norm1to6(self.lin1to6(self.flatten(x_temp1))) + self.norm2to6(self.lin2to6(self.flatten(x_temp2))) + self.norm3to6(self.lin3to6(self.flatten(x_temp3))) + self.norm4to6(self.lin4to6(self.flatten(x_temp4))) + self.norm5to6(self.lin5to6(self.flatten(x_temp5)))\n",
    "        x = self.norm6(torch.relu(x))\n",
    "        x = self.lin_fin(x)\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullresnet = FullNestedResNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(fullresnet.parameters(), lr = learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 9, gamma = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 4, 28, 28]             104\n",
      "       BatchNorm2d-2            [-1, 4, 28, 28]               8\n",
      "            Conv2d-3           [-1, 16, 28, 28]           1,616\n",
      "            Conv2d-4           [-1, 16, 28, 28]             160\n",
      "       BatchNorm2d-5           [-1, 16, 28, 28]              32\n",
      "       BatchNorm2d-6           [-1, 16, 28, 28]              32\n",
      "         MaxPool2d-7           [-1, 16, 14, 14]               0\n",
      "            Conv2d-8           [-1, 64, 14, 14]           9,280\n",
      "            Conv2d-9           [-1, 64, 14, 14]             640\n",
      "      BatchNorm2d-10           [-1, 64, 14, 14]             128\n",
      "           Conv2d-11           [-1, 64, 14, 14]           2,368\n",
      "      BatchNorm2d-12           [-1, 64, 14, 14]             128\n",
      "      BatchNorm2d-13           [-1, 64, 14, 14]             128\n",
      "           Conv2d-14          [-1, 256, 14, 14]         147,712\n",
      "           Conv2d-15          [-1, 256, 14, 14]           2,560\n",
      "      BatchNorm2d-16          [-1, 256, 14, 14]             512\n",
      "           Conv2d-17          [-1, 256, 14, 14]           9,472\n",
      "      BatchNorm2d-18          [-1, 256, 14, 14]             512\n",
      "           Conv2d-19          [-1, 256, 14, 14]          37,120\n",
      "      BatchNorm2d-20          [-1, 256, 14, 14]             512\n",
      "      BatchNorm2d-21          [-1, 256, 14, 14]             512\n",
      "        MaxPool2d-22            [-1, 256, 7, 7]               0\n",
      "          Flatten-23                [-1, 12544]               0\n",
      "           Linear-24                  [-1, 200]       2,509,000\n",
      "          Flatten-25                  [-1, 784]               0\n",
      "           Linear-26                  [-1, 200]         157,000\n",
      "      BatchNorm1d-27                  [-1, 200]             400\n",
      "          Flatten-28                 [-1, 3136]               0\n",
      "           Linear-29                  [-1, 200]         627,400\n",
      "      BatchNorm1d-30                  [-1, 200]             400\n",
      "          Flatten-31                 [-1, 3136]               0\n",
      "           Linear-32                  [-1, 200]         627,400\n",
      "      BatchNorm1d-33                  [-1, 200]             400\n",
      "          Flatten-34                [-1, 12544]               0\n",
      "           Linear-35                  [-1, 200]       2,509,000\n",
      "      BatchNorm1d-36                  [-1, 200]             400\n",
      "      BatchNorm1d-37                  [-1, 200]             400\n",
      "           Linear-38                   [-1, 85]          17,085\n",
      "          Flatten-39                  [-1, 784]               0\n",
      "           Linear-40                   [-1, 85]          66,725\n",
      "      BatchNorm1d-41                   [-1, 85]             170\n",
      "          Flatten-42                 [-1, 3136]               0\n",
      "           Linear-43                   [-1, 85]         266,645\n",
      "      BatchNorm1d-44                   [-1, 85]             170\n",
      "          Flatten-45                 [-1, 3136]               0\n",
      "           Linear-46                   [-1, 85]         266,645\n",
      "      BatchNorm1d-47                   [-1, 85]             170\n",
      "          Flatten-48                [-1, 12544]               0\n",
      "           Linear-49                   [-1, 85]       1,066,325\n",
      "      BatchNorm1d-50                   [-1, 85]             170\n",
      "          Flatten-51                [-1, 12544]               0\n",
      "           Linear-52                   [-1, 85]       1,066,325\n",
      "      BatchNorm1d-53                   [-1, 85]             170\n",
      "      BatchNorm1d-54                   [-1, 85]             170\n",
      "           Linear-55                   [-1, 10]             860\n",
      "================================================================\n",
      "Total params: 9,396,966\n",
      "Trainable params: 9,396,966\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 4.70\n",
      "Params size (MB): 35.85\n",
      "Estimated Total Size (MB): 40.55\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(fullresnet, (1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50; Loss = 0.020829; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.37%\n",
      "Dev Accuracy: 98.95%\n",
      "--------------------\n",
      "Epoch 2/50; Loss = 0.067783; LR = [0.001]\n",
      "Train Accuracy: 99.62%\n",
      "Dev Accuracy: 98.84%\n",
      "--------------------\n",
      "Epoch 3/50; Loss = 0.004471; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.86%\n",
      "Dev Accuracy: 98.98%\n",
      "--------------------\n",
      "Epoch 4/50; Loss = 0.009092; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.90%\n",
      "Dev Accuracy: 98.98%\n",
      "--------------------\n",
      "Epoch 5/50; Loss = 0.034807; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.94%\n",
      "Dev Accuracy: 99.13%\n",
      "--------------------\n",
      "Epoch 6/50; Loss = 0.002638; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.96%\n",
      "Dev Accuracy: 99.17%\n",
      "--------------------\n",
      "Epoch 7/50; Loss = 0.001619; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.91%\n",
      "Dev Accuracy: 99.22%\n",
      "--------------------\n",
      "Epoch 8/50; Loss = 0.001177; LR = [0.001]\n",
      "Train Accuracy: 99.77%\n",
      "Dev Accuracy: 99.05%\n",
      "--------------------\n",
      "Epoch 9/50; Loss = 0.026646; LR = [0.0005]\n",
      "Train Accuracy: 99.50%\n",
      "Dev Accuracy: 98.72%\n",
      "--------------------\n",
      "Epoch 10/50; Loss = 0.000334; LR = [0.0005]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.97%\n",
      "Dev Accuracy: 99.26%\n",
      "--------------------\n",
      "Epoch 11/50; Loss = 0.001823; LR = [0.0005]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.38%\n",
      "--------------------\n",
      "Epoch 12/50; Loss = 0.000114; LR = [0.0005]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.41%\n",
      "--------------------\n",
      "Epoch 13/50; Loss = 0.000119; LR = [0.0005]\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.40%\n",
      "--------------------\n",
      "Epoch 14/50; Loss = 0.000111; LR = [0.0005]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.42%\n",
      "--------------------\n",
      "Epoch 15/50; Loss = 0.000119; LR = [0.0005]\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.39%\n",
      "--------------------\n",
      "Epoch 16/50; Loss = 0.000317; LR = [0.0005]\n",
      "Train Accuracy: 100.00%\n",
      "Dev Accuracy: 99.39%\n",
      "--------------------\n",
      "Epoch 17/50; Loss = 0.000072; LR = [0.0005]\n",
      "Train Accuracy: 100.00%\n",
      "Dev Accuracy: 99.39%\n",
      "--------------------\n",
      "Epoch 18/50; Loss = 0.000074; LR = [0.00025]\n",
      "Train Accuracy: 100.00%\n",
      "Dev Accuracy: 99.40%\n",
      "--------------------\n",
      "Epoch 19/50; Loss = 0.000156; LR = [0.00025]\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.41%\n",
      "--------------------\n",
      "Epoch 20/50; Loss = 0.000103; LR = [0.00025]\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.41%\n",
      "--------------------\n",
      "Epoch 21/50; Loss = 0.000140; LR = [0.00025]\n",
      "Train Accuracy: 100.00%\n",
      "Dev Accuracy: 99.41%\n",
      "--------------------\n",
      "Epoch 22/50; Loss = 0.000160; LR = [0.00025]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.42%\n",
      "--------------------\n",
      "Epoch 23/50; Loss = 0.000028; LR = [0.00025]\n",
      "Train Accuracy: 100.00%\n",
      "Dev Accuracy: 99.40%\n",
      "--------------------\n",
      "Epoch 24/50; Loss = 0.000064; LR = [0.00025]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.42%\n",
      "--------------------\n",
      "Epoch 25/50; Loss = 0.000019; LR = [0.00025]\n",
      "Train Accuracy: 100.00%\n",
      "Dev Accuracy: 99.40%\n",
      "--------------------\n",
      "Epoch 26/50; Loss = 0.000085; LR = [0.00025]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 100.00%\n",
      "Dev Accuracy: 99.42%\n",
      "--------------------\n",
      "Epoch 27/50; Loss = 0.000037; LR = [0.000125]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 100.00%\n",
      "Dev Accuracy: 99.43%\n",
      "--------------------\n",
      "Epoch 28/50; Loss = 0.000016; LR = [0.000125]\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.40%\n",
      "--------------------\n",
      "Epoch 29/50; Loss = 0.000020; LR = [0.000125]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.43%\n",
      "--------------------\n",
      "Epoch 30/50; Loss = 0.000034; LR = [0.000125]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.43%\n",
      "--------------------\n",
      "Epoch 31/50; Loss = 0.000096; LR = [0.000125]\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.40%\n",
      "--------------------\n",
      "Epoch 32/50; Loss = 0.000055; LR = [0.000125]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.44%\n",
      "--------------------\n",
      "Epoch 33/50; Loss = 0.000032; LR = [0.000125]\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.41%\n",
      "--------------------\n",
      "Epoch 34/50; Loss = 0.000010; LR = [0.000125]\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.41%\n",
      "--------------------\n",
      "Epoch 35/50; Loss = 0.000006; LR = [0.000125]\n",
      "Train Accuracy: 100.00%\n",
      "Dev Accuracy: 99.41%\n",
      "--------------------\n",
      "Epoch 36/50; Loss = 0.000140; LR = [6.25e-05]\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.41%\n",
      "--------------------\n",
      "Epoch 37/50; Loss = 0.000021; LR = [6.25e-05]\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.42%\n",
      "--------------------\n",
      "Epoch 38/50; Loss = 0.000172; LR = [6.25e-05]\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.40%\n",
      "--------------------\n",
      "Epoch 39/50; Loss = 0.000015; LR = [6.25e-05]\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.40%\n",
      "--------------------\n",
      "Epoch 40/50; Loss = 0.000018; LR = [6.25e-05]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.44%\n",
      "--------------------\n",
      "Epoch 41/50; Loss = 0.000007; LR = [6.25e-05]\n",
      "Train Accuracy: 100.00%\n",
      "Dev Accuracy: 99.42%\n",
      "--------------------\n",
      "Epoch 42/50; Loss = 0.000021; LR = [6.25e-05]\n",
      "Train Accuracy: 100.00%\n",
      "Dev Accuracy: 99.42%\n",
      "--------------------\n",
      "Epoch 43/50; Loss = 0.000029; LR = [6.25e-05]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.45%\n",
      "--------------------\n",
      "Epoch 44/50; Loss = 0.000013; LR = [6.25e-05]\n",
      "Train Accuracy: 100.00%\n",
      "Dev Accuracy: 99.43%\n",
      "--------------------\n",
      "Epoch 45/50; Loss = 0.000004; LR = [3.125e-05]\n",
      "Train Accuracy: 100.00%\n",
      "Dev Accuracy: 99.43%\n",
      "--------------------\n",
      "Epoch 46/50; Loss = 0.000011; LR = [3.125e-05]\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.44%\n",
      "--------------------\n",
      "Epoch 47/50; Loss = 0.000006; LR = [3.125e-05]\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.42%\n",
      "--------------------\n",
      "Epoch 48/50; Loss = 0.000008; LR = [3.125e-05]\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.44%\n",
      "--------------------\n",
      "Epoch 49/50; Loss = 0.000007; LR = [3.125e-05]\n",
      "Train Accuracy: 99.99%\n",
      "Dev Accuracy: 99.42%\n",
      "--------------------\n",
      "Epoch 50/50; Loss = 0.000007; LR = [3.125e-05]\n",
      "Train Accuracy: 100.00%\n",
      "Dev Accuracy: 99.43%\n",
      "--------------------\n",
      "Finished Training!\n",
      "Time Taken = 30.0m 57.18664503097534s\n"
     ]
    }
   ],
   "source": [
    "best_weights = copy.deepcopy(fullresnet.state_dict())\n",
    "max = 0\n",
    "val_acc = 0\n",
    "train_acc = 0\n",
    "tic = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    fullresnet.train()\n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        preds = fullresnet.forward(images)\n",
    "        loss = criterion(preds, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step() # Decaying learning rate per 25 epochs by 0.2 times\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}; Loss = {loss.item():.6f}; LR = {scheduler.get_last_lr()}')\n",
    "    with torch.no_grad():\n",
    "        n_samples = 0\n",
    "        n_correct = 0\n",
    "        fullresnet.eval()\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device) # From 128, 1, 28, 28 ---> 128, 784\n",
    "            labels = labels.to(device)\n",
    "            pred_outputs1 = fullresnet(images)\n",
    "            _, actual_preds1 = torch.max(pred_outputs1, 1) # Returns value, index\n",
    "            n_samples += labels.shape[0]\n",
    "            n_correct += (actual_preds1 == labels).sum().item()\n",
    "        val_acc = n_correct/n_samples * 100\n",
    "\n",
    "        if (max <= (n_correct/n_samples * 100)):\n",
    "            print('SAVED MODEL WEIGHTS')\n",
    "            max = val_acc\n",
    "            best_weights = copy.deepcopy(fullresnet.state_dict())\n",
    "\n",
    "        n_samples = 0\n",
    "        n_correct = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device) # From 128, 1, 28, 28 ---> 128, 784\n",
    "            labels = labels.to(device)\n",
    "            pred_outputs1 = fullresnet(images)\n",
    "            _, actual_preds1 = torch.max(pred_outputs1, 1) # Returns value, index\n",
    "            n_samples += labels.shape[0]\n",
    "            n_correct += (actual_preds1 == labels).sum().item()\n",
    "        train_acc = n_correct/n_samples * 100\n",
    "    \n",
    "    print(f'Train Accuracy: {train_acc:.2f}%')\n",
    "    print(f'Dev Accuracy: {val_acc:.2f}%')\n",
    "    print(\"-\"*20)\n",
    "print('Finished Training!')\n",
    "print(f'Time Taken = {(time.time()-tic)//60}m {(time.time()-tic)%60}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time taken by connecting everything is also much LARGER and also **no improvement** from just connecting the input to every point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start connected longer ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myBigResNet(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(myBigResNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1,4,5,1,'same') # 4, 28, 28\n",
    "        # self.act1_1 = nn.ReLU() \n",
    "        self.norm1 = nn.BatchNorm2d(4)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(4,16,5,1,'same') # 16, 28, 28\n",
    "        self.conv1to2 = nn.Conv2d(1,16,3,1,'same') # 16, 28, 28\n",
    "        # self.act1_2 = nn.ReLU()\n",
    "        self.norm2 = nn.BatchNorm2d(16)\n",
    "            \n",
    "        self.pool1 = nn.MaxPool2d(2, 2) # 16, 28, 28 --> 16, 14, 14\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(16,64,3,1,'same') # 64, 14, 14\n",
    "        self.conv1to3 = nn.Conv2d(1,64,3,2,1) # 64, 14, 14\n",
    "        # self.act2_1 = nn.ReLU()\n",
    "        self.norm3 = nn.BatchNorm2d(64)\n",
    "            \n",
    "        self.conv4 = nn.Conv2d(64,256,3,1,'same')  # 256, 14, 14\n",
    "        self.conv1to4 = nn.Conv2d(1,256,3,2,1) # 256, 14, 14\n",
    "        # self.act2_2 = nn.ReLU()\n",
    "        self.norm4 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.pool2 = nn.MaxPool2d(2, 2) # 256, 14, 14 --> 256, 7, 7\n",
    "\n",
    "        self.conv5 = nn.Conv2d(256,512,5,1,'same') # 512, 7, 7\n",
    "        self.conv1to5 = nn.Conv2d(1,512,3,4,1) # 1024, 7, 7\n",
    "        # self.act1_1 = nn.ReLU() \n",
    "        self.norm5 = nn.BatchNorm2d(512)\n",
    "\n",
    "        self.conv6 = nn.Conv2d(512,1024,5,1,'same') # 1024, 7, 7\n",
    "        self.conv1to6 = nn.Conv2d(1,1024,3,4,1) # 1024, 7, 7\n",
    "        # self.act1_2 = nn.ReLU()\n",
    "        self.norm6 = nn.BatchNorm2d(1024)\n",
    "            \n",
    "        self.pool3 = nn.MaxPool2d(2, 2) # 1024, 7, 7 --> 1024, 3, 3\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.lin7 = nn.Linear(1024*3*3, 1024)\n",
    "        self.lin1to7 = nn.Linear(28*28*1, 1024)\n",
    "        # self.act4 = nn.ReLU()\n",
    "        self.norm7 = nn.BatchNorm1d(1024)\n",
    "\n",
    "        self.lin8 = nn.Linear(1024, 512)\n",
    "        self.lin1to8 = nn.Linear(28*28*1, 512)\n",
    "        # self.act5 = nn.ReLU()\n",
    "        self.norm8 = nn.BatchNorm1d(512)\n",
    "\n",
    "        self.lin9 = nn.Linear(512, 128)\n",
    "        self.lin1to9 = nn.Linear(28*28*1, 128)\n",
    "        # self.act5 = nn.ReLU()\n",
    "        self.norm9 = nn.BatchNorm1d(128)\n",
    "\n",
    "        self.lin10 = nn.Linear(128, 84)\n",
    "        self.lin1to10 = nn.Linear(28*28*1, 84)\n",
    "        # self.act5 = nn.ReLU()\n",
    "        self.norm10 = nn.BatchNorm1d(84)\n",
    "\n",
    "        self.lin_fin = nn.Linear(84,10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_temp1 = x\n",
    "        x = self.norm1(torch.relu(self.conv1(x)))\n",
    "        x = self.norm2(torch.relu(self.conv2(x)+self.conv1to2(x_temp1))) # Residual\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.norm3(torch.relu(self.conv3(x)+self.conv1to3(x_temp1)))\n",
    "        x = self.norm4(torch.relu(self.conv4(x)+self.conv1to4(x_temp1))) # Residual\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.norm5(torch.relu(self.conv5(x)+self.conv1to5(x_temp1)))\n",
    "        x = self.norm6(torch.relu(self.conv6(x)+self.conv1to6(x_temp1))) # Residual\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.norm7(torch.relu(self.lin7(x)+self.lin1to7(self.flatten(x_temp1))))\n",
    "        x = self.norm8(torch.relu(self.lin8(x)+self.lin1to8(self.flatten(x_temp1))))\n",
    "        x = self.norm9(torch.relu(self.lin9(x)+self.lin1to9(self.flatten(x_temp1))))\n",
    "        x = self.norm10(torch.relu(self.lin10(x)+self.lin1to10(self.flatten(x_temp1))))\n",
    "\n",
    "        x = self.lin_fin(x)\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigresnet = myBigResNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(bigresnet.parameters(), lr = learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 9, gamma = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 4, 28, 28]             104\n",
      "       BatchNorm2d-2            [-1, 4, 28, 28]               8\n",
      "            Conv2d-3           [-1, 16, 28, 28]           1,616\n",
      "            Conv2d-4           [-1, 16, 28, 28]             160\n",
      "       BatchNorm2d-5           [-1, 16, 28, 28]              32\n",
      "         MaxPool2d-6           [-1, 16, 14, 14]               0\n",
      "            Conv2d-7           [-1, 64, 14, 14]           9,280\n",
      "            Conv2d-8           [-1, 64, 14, 14]             640\n",
      "       BatchNorm2d-9           [-1, 64, 14, 14]             128\n",
      "           Conv2d-10          [-1, 256, 14, 14]         147,712\n",
      "           Conv2d-11          [-1, 256, 14, 14]           2,560\n",
      "      BatchNorm2d-12          [-1, 256, 14, 14]             512\n",
      "        MaxPool2d-13            [-1, 256, 7, 7]               0\n",
      "           Conv2d-14            [-1, 512, 7, 7]       3,277,312\n",
      "           Conv2d-15            [-1, 512, 7, 7]           5,120\n",
      "      BatchNorm2d-16            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-17           [-1, 1024, 7, 7]      13,108,224\n",
      "           Conv2d-18           [-1, 1024, 7, 7]          10,240\n",
      "      BatchNorm2d-19           [-1, 1024, 7, 7]           2,048\n",
      "        MaxPool2d-20           [-1, 1024, 3, 3]               0\n",
      "          Flatten-21                 [-1, 9216]               0\n",
      "           Linear-22                 [-1, 1024]       9,438,208\n",
      "          Flatten-23                  [-1, 784]               0\n",
      "           Linear-24                 [-1, 1024]         803,840\n",
      "      BatchNorm1d-25                 [-1, 1024]           2,048\n",
      "           Linear-26                  [-1, 512]         524,800\n",
      "          Flatten-27                  [-1, 784]               0\n",
      "           Linear-28                  [-1, 512]         401,920\n",
      "      BatchNorm1d-29                  [-1, 512]           1,024\n",
      "           Linear-30                  [-1, 128]          65,664\n",
      "          Flatten-31                  [-1, 784]               0\n",
      "           Linear-32                  [-1, 128]         100,480\n",
      "      BatchNorm1d-33                  [-1, 128]             256\n",
      "           Linear-34                   [-1, 84]          10,836\n",
      "          Flatten-35                  [-1, 784]               0\n",
      "           Linear-36                   [-1, 84]          65,940\n",
      "      BatchNorm1d-37                   [-1, 84]             168\n",
      "           Linear-38                   [-1, 10]             850\n",
      "================================================================\n",
      "Total params: 27,982,754\n",
      "Trainable params: 27,982,754\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 3.82\n",
      "Params size (MB): 106.75\n",
      "Estimated Total Size (MB): 110.57\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(bigresnet, (1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50; Loss = 0.052776; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 98.00%\n",
      "Dev Accuracy: 97.77%\n",
      "--------------------\n",
      "Epoch 2/50; Loss = 0.020049; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.18%\n",
      "Dev Accuracy: 98.74%\n",
      "--------------------\n",
      "Epoch 3/50; Loss = 0.028687; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.66%\n",
      "Dev Accuracy: 99.08%\n",
      "--------------------\n",
      "Epoch 4/50; Loss = 0.008632; LR = [0.001]\n",
      "Train Accuracy: 99.59%\n",
      "Dev Accuracy: 98.99%\n",
      "--------------------\n",
      "Epoch 5/50; Loss = 0.008108; LR = [0.001]\n",
      "Train Accuracy: 99.44%\n",
      "Dev Accuracy: 98.84%\n",
      "--------------------\n",
      "Epoch 6/50; Loss = 0.014051; LR = [0.001]\n",
      "Train Accuracy: 99.00%\n",
      "Dev Accuracy: 98.30%\n",
      "--------------------\n",
      "Epoch 7/50; Loss = 0.073416; LR = [0.001]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.72%\n",
      "Dev Accuracy: 99.11%\n",
      "--------------------\n",
      "Epoch 8/50; Loss = 0.002062; LR = [0.001]\n",
      "Train Accuracy: 99.76%\n",
      "Dev Accuracy: 98.91%\n",
      "--------------------\n",
      "Epoch 9/50; Loss = 0.001346; LR = [0.0005]\n",
      "Train Accuracy: 99.75%\n",
      "Dev Accuracy: 98.95%\n",
      "--------------------\n",
      "Epoch 10/50; Loss = 0.000170; LR = [0.0005]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.94%\n",
      "Dev Accuracy: 99.39%\n",
      "--------------------\n",
      "Epoch 11/50; Loss = 0.000937; LR = [0.0005]\n",
      "Train Accuracy: 99.94%\n",
      "Dev Accuracy: 99.36%\n",
      "--------------------\n",
      "Epoch 12/50; Loss = 0.000525; LR = [0.0005]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.92%\n",
      "Dev Accuracy: 99.40%\n",
      "--------------------\n",
      "Epoch 13/50; Loss = 0.000118; LR = [0.0005]\n",
      "Train Accuracy: 99.91%\n",
      "Dev Accuracy: 99.38%\n",
      "--------------------\n",
      "Epoch 14/50; Loss = 0.000103; LR = [0.0005]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.94%\n",
      "Dev Accuracy: 99.45%\n",
      "--------------------\n",
      "Epoch 15/50; Loss = 0.000254; LR = [0.0005]\n",
      "Train Accuracy: 99.92%\n",
      "Dev Accuracy: 99.39%\n",
      "--------------------\n",
      "Epoch 16/50; Loss = 0.000338; LR = [0.0005]\n",
      "Train Accuracy: 99.93%\n",
      "Dev Accuracy: 99.37%\n",
      "--------------------\n",
      "Epoch 17/50; Loss = 0.000101; LR = [0.0005]\n",
      "Train Accuracy: 99.95%\n",
      "Dev Accuracy: 99.40%\n",
      "--------------------\n",
      "Epoch 18/50; Loss = 0.000150; LR = [0.00025]\n",
      "Train Accuracy: 99.94%\n",
      "Dev Accuracy: 99.37%\n",
      "--------------------\n",
      "Epoch 19/50; Loss = 0.000055; LR = [0.00025]\n",
      "Train Accuracy: 99.93%\n",
      "Dev Accuracy: 99.38%\n",
      "--------------------\n",
      "Epoch 20/50; Loss = 0.000047; LR = [0.00025]\n",
      "Train Accuracy: 99.93%\n",
      "Dev Accuracy: 99.43%\n",
      "--------------------\n",
      "Epoch 21/50; Loss = 0.000051; LR = [0.00025]\n",
      "Train Accuracy: 99.95%\n",
      "Dev Accuracy: 99.42%\n",
      "--------------------\n",
      "Epoch 22/50; Loss = 0.000044; LR = [0.00025]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.95%\n",
      "Dev Accuracy: 99.45%\n",
      "--------------------\n",
      "Epoch 23/50; Loss = 0.000016; LR = [0.00025]\n",
      "Train Accuracy: 99.96%\n",
      "Dev Accuracy: 99.41%\n",
      "--------------------\n",
      "Epoch 24/50; Loss = 0.000235; LR = [0.00025]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.93%\n",
      "Dev Accuracy: 99.46%\n",
      "--------------------\n",
      "Epoch 25/50; Loss = 0.000069; LR = [0.00025]\n",
      "Train Accuracy: 99.92%\n",
      "Dev Accuracy: 99.43%\n",
      "--------------------\n",
      "Epoch 26/50; Loss = 0.000027; LR = [0.00025]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.94%\n",
      "Dev Accuracy: 99.46%\n",
      "--------------------\n",
      "Epoch 27/50; Loss = 0.000035; LR = [0.000125]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.95%\n",
      "Dev Accuracy: 99.46%\n",
      "--------------------\n",
      "Epoch 28/50; Loss = 0.000016; LR = [0.000125]\n",
      "Train Accuracy: 99.93%\n",
      "Dev Accuracy: 99.40%\n",
      "--------------------\n",
      "Epoch 29/50; Loss = 0.000012; LR = [0.000125]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.95%\n",
      "Dev Accuracy: 99.46%\n",
      "--------------------\n",
      "Epoch 30/50; Loss = 0.000015; LR = [0.000125]\n",
      "Train Accuracy: 99.95%\n",
      "Dev Accuracy: 99.43%\n",
      "--------------------\n",
      "Epoch 31/50; Loss = 0.000010; LR = [0.000125]\n",
      "Train Accuracy: 99.93%\n",
      "Dev Accuracy: 99.42%\n",
      "--------------------\n",
      "Epoch 32/50; Loss = 0.000061; LR = [0.000125]\n",
      "Train Accuracy: 99.95%\n",
      "Dev Accuracy: 99.41%\n",
      "--------------------\n",
      "Epoch 33/50; Loss = 0.000012; LR = [0.000125]\n",
      "Train Accuracy: 99.92%\n",
      "Dev Accuracy: 99.42%\n",
      "--------------------\n",
      "Epoch 34/50; Loss = 0.000011; LR = [0.000125]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.95%\n",
      "Dev Accuracy: 99.46%\n",
      "--------------------\n",
      "Epoch 35/50; Loss = 0.000029; LR = [0.000125]\n",
      "Train Accuracy: 99.95%\n",
      "Dev Accuracy: 99.44%\n",
      "--------------------\n",
      "Epoch 36/50; Loss = 0.000014; LR = [6.25e-05]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.95%\n",
      "Dev Accuracy: 99.47%\n",
      "--------------------\n",
      "Epoch 37/50; Loss = 0.000016; LR = [6.25e-05]\n",
      "Train Accuracy: 99.94%\n",
      "Dev Accuracy: 99.40%\n",
      "--------------------\n",
      "Epoch 38/50; Loss = 0.000027; LR = [6.25e-05]\n",
      "Train Accuracy: 99.94%\n",
      "Dev Accuracy: 99.42%\n",
      "--------------------\n",
      "Epoch 39/50; Loss = 0.000018; LR = [6.25e-05]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.95%\n",
      "Dev Accuracy: 99.47%\n",
      "--------------------\n",
      "Epoch 40/50; Loss = 0.000017; LR = [6.25e-05]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.97%\n",
      "Dev Accuracy: 99.48%\n",
      "--------------------\n",
      "Epoch 41/50; Loss = 0.000008; LR = [6.25e-05]\n",
      "Train Accuracy: 99.91%\n",
      "Dev Accuracy: 99.44%\n",
      "--------------------\n",
      "Epoch 42/50; Loss = 0.000007; LR = [6.25e-05]\n",
      "Train Accuracy: 99.94%\n",
      "Dev Accuracy: 99.47%\n",
      "--------------------\n",
      "Epoch 43/50; Loss = 0.000008; LR = [6.25e-05]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.94%\n",
      "Dev Accuracy: 99.48%\n",
      "--------------------\n",
      "Epoch 44/50; Loss = 0.000011; LR = [6.25e-05]\n",
      "Train Accuracy: 99.95%\n",
      "Dev Accuracy: 99.45%\n",
      "--------------------\n",
      "Epoch 45/50; Loss = 0.000028; LR = [3.125e-05]\n",
      "Train Accuracy: 99.93%\n",
      "Dev Accuracy: 99.47%\n",
      "--------------------\n",
      "Epoch 46/50; Loss = 0.000018; LR = [3.125e-05]\n",
      "Train Accuracy: 99.95%\n",
      "Dev Accuracy: 99.45%\n",
      "--------------------\n",
      "Epoch 47/50; Loss = 0.000010; LR = [3.125e-05]\n",
      "SAVED MODEL WEIGHTS\n",
      "Train Accuracy: 99.93%\n",
      "Dev Accuracy: 99.49%\n",
      "--------------------\n",
      "Epoch 48/50; Loss = 0.000022; LR = [3.125e-05]\n",
      "Train Accuracy: 99.93%\n",
      "Dev Accuracy: 99.42%\n",
      "--------------------\n",
      "Epoch 49/50; Loss = 0.000005; LR = [3.125e-05]\n",
      "Train Accuracy: 99.93%\n",
      "Dev Accuracy: 99.48%\n",
      "--------------------\n",
      "Epoch 50/50; Loss = 0.000006; LR = [3.125e-05]\n",
      "Train Accuracy: 99.94%\n",
      "Dev Accuracy: 99.47%\n",
      "--------------------\n",
      "Finished Training!\n",
      "Time Taken = 131.0m 9.399170160293579s\n"
     ]
    }
   ],
   "source": [
    "best_weights = copy.deepcopy(bigresnet.state_dict())\n",
    "max = 0\n",
    "val_acc = 0\n",
    "train_acc = 0\n",
    "tic = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    bigresnet.train()\n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        preds = bigresnet.forward(images)\n",
    "        loss = criterion(preds, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step() # Decaying learning rate per 25 epochs by 0.2 times\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}; Loss = {loss.item():.6f}; LR = {scheduler.get_last_lr()}')\n",
    "    with torch.no_grad():\n",
    "        n_samples = 0\n",
    "        n_correct = 0\n",
    "        bigresnet.eval()\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device) # From 128, 1, 28, 28 ---> 128, 784\n",
    "            labels = labels.to(device)\n",
    "            pred_outputs1 = bigresnet(images)\n",
    "            _, actual_preds1 = torch.max(pred_outputs1, 1) # Returns value, index\n",
    "            n_samples += labels.shape[0]\n",
    "            n_correct += (actual_preds1 == labels).sum().item()\n",
    "        val_acc = n_correct/n_samples * 100\n",
    "\n",
    "        if (max <= (n_correct/n_samples * 100)):\n",
    "            print('SAVED MODEL WEIGHTS')\n",
    "            max = val_acc\n",
    "            best_weights = copy.deepcopy(bigresnet.state_dict())\n",
    "\n",
    "        n_samples = 0\n",
    "        n_correct = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device) # From 128, 1, 28, 28 ---> 128, 784\n",
    "            labels = labels.to(device)\n",
    "            pred_outputs1 = bigresnet(images)\n",
    "            _, actual_preds1 = torch.max(pred_outputs1, 1) # Returns value, index\n",
    "            n_samples += labels.shape[0]\n",
    "            n_correct += (actual_preds1 == labels).sum().item()\n",
    "        train_acc = n_correct/n_samples * 100\n",
    "    \n",
    "    print(f'Train Accuracy: {train_acc:.2f}%')\n",
    "    print(f'Dev Accuracy: {val_acc:.2f}%')\n",
    "    print(\"-\"*20)\n",
    "print('Finished Training!')\n",
    "print(f'Time Taken = {(time.time()-tic)//60}m {(time.time()-tic)%60}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.has_mps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

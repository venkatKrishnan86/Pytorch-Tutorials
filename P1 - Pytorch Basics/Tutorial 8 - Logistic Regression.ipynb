{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "0) Collect data\n",
    "1) Model\n",
    "2) Loss\n",
    "3) Optimizer\n",
    "4) Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Collect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = datasets.load_breast_cancer()\n",
    "X_np, y_np = bc.data, bc.target\n",
    "\n",
    "# Convert to tensor\n",
    "X = torch.from_numpy(X_np.astype(np.float32))\n",
    "y = torch.from_numpy(y_np.astype(np.float32))\n",
    "\n",
    "# # Reshaping for outputs into rank 2 tensor\n",
    "y = y.reshape(y_np.shape[0],1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() # 0 mean and variance = 1 = std_dev\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(in_features = n_features, out_features = 1)\n",
    "        self.optim = None\n",
    "        self.loss_obj = None\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return(torch.sigmoid(self.linear(x)))               # Or create an object from nn.Sigmoid and use that instead of torch.sigmoid()\n",
    "\n",
    "    def loss_func(self, loss_func = nn.BCELoss):\n",
    "        self.loss_obj = loss_func()                         # Object of the loss function in torch.nn \n",
    "\n",
    "    def optimizer(self, optimizer, learning_rate = 0.01):\n",
    "        self.optim = optimizer(self.linear.parameters(),lr = learning_rate)\n",
    "\n",
    "    \n",
    "    def fit(self, X, y, epochs = 100, print_statements = False):\n",
    "        for epoch in range(epochs):\n",
    "            y_pred = self.forward(X)                        # Forward prop\n",
    "            loss = self.loss_obj(y_pred,y)                  # Compute loss\n",
    "            loss.backward()                                 # Compute local gradients\n",
    "            self.optim.step()                               # Update parameters\n",
    "            self.optim.zero_grad()                          # Zero the gradients\n",
    "            if(print_statements and epoch%(epochs//10)==0):\n",
    "                print(f'Epoch {epoch+1}; Loss = {loss.item():0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = LogisticRegression(n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2,3. Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict.loss_func(nn.BCELoss)\n",
    "predict.optimizer(torch.optim.SGD, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict.fit(X_train,y_train, epochs = 1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Check Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = predict.forward(X_train).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data metrics -\n",
      "Confusion Matrix\n",
      "[[157   3]\n",
      " [  7 288]]\n",
      "Accuracy = 97.80%\n"
     ]
    }
   ],
   "source": [
    "print('Training data metrics -\\nConfusion Matrix')\n",
    "print(confusion_matrix(np.round(y_predicted), y_train.detach().numpy()))\n",
    "print(f'Accuracy = {100*accuracy_score(np.round(y_predicted), y_train.detach().numpy()):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = predict.forward(X_test).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data metrics -\n",
      "Confusion Matrix\n",
      "[[47  0]\n",
      " [ 1 66]]\n",
      "Accuracy = 99.12%\n"
     ]
    }
   ],
   "source": [
    "print('Testing data metrics -\\nConfusion Matrix')\n",
    "print(confusion_matrix(np.round(y_predicted), y_test.detach().numpy()))\n",
    "print(f'Accuracy = {100*accuracy_score(np.round(y_predicted), y_test.detach().numpy()):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(predict,'models/logistic_regressor.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Many to One RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall treat one dimension of the image as the **feature size** and the other dimension as the **sequence**\n",
    "\n",
    "We would look at one row at a time, and each row being a sequence input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28 # One row at a time, hence input dimension would be (1,28)\n",
    "sequence_length = 28\n",
    "hidden_size = 128\n",
    "num_classes = 10 # 0 to 9 digits\n",
    "num_epochs = 8\n",
    "batch_size = 128 # Preferred to be a power of 2\n",
    "learning_rate = 0.001\n",
    "num_layers = 3 # Deep RNN layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root = '../datasets', \n",
    "    train = True, \n",
    "    transform = transforms.ToTensor(), \n",
    "    download = True\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root = '../datasets', \n",
    "    train = False, \n",
    "    transform = transforms.ToTensor(), \n",
    "    download = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset = train_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset = test_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs, labels = next(iter(train_loader))\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(inputs[i][0]) # 6 from batch-size of 128\n",
    "    plt.title(f'Label {labels[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network (RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes) -> None:\n",
    "        super(RNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first = True)\n",
    "        # batch_first = True means, batch size is the first dimension\n",
    "        # Would mean x --> (batch_size, seq, input_size)\n",
    "        # input_size is the feature size\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, num_classes) # Last cell unit output\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Dimensions (number of layers, batch_size, hidden_size)\n",
    "        # Reason - Each layer would have a different hidden state of size (batch_size, hidden_size)\n",
    "\n",
    "        out, _ = self.rnn(x, h0) # Returns output and hidden state of EACH cell\n",
    "        # out dimenions: (batch_size, sequence_length, hidden_size)\n",
    "        # out: (N, 28, 128)\n",
    "        out = out[:,-1,:] # Since we only want the output of the last cell\n",
    "        out = self.fc(out)\n",
    "        return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "469"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_total_steps = len(train_loader)\n",
    "n_total_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "RNN                                      [128, 10]                 --\n",
       "├─RNN: 1-1                               [128, 28, 128]            86,272\n",
       "├─Linear: 1-2                            [128, 10]                 1,290\n",
       "==========================================================================================\n",
       "Total params: 87,562\n",
       "Trainable params: 87,562\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 309.36\n",
       "==========================================================================================\n",
       "Input size (MB): 0.40\n",
       "Forward/backward pass size (MB): 3.68\n",
       "Params size (MB): 0.35\n",
       "Estimated Total Size (MB): 4.43\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(rnn, (batch_size, sequence_length, input_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8; Loss: 0.4875\n",
      "Epoch 2/8; Loss: 0.1731\n",
      "Epoch 3/8; Loss: 0.2080\n",
      "Epoch 4/8; Loss: 0.1113\n",
      "Epoch 5/8; Loss: 0.0170\n",
      "Epoch 6/8; Loss: 0.0222\n",
      "Epoch 7/8; Loss: 0.0487\n",
      "Epoch 8/8; Loss: 0.0604\n",
      "Finished Training in 1m 13s\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # original shape: [batch_size, 1, 28, 28]\n",
    "        # Resize: [batch_size, 28, 28]\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = rnn(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}; Loss: {loss.item():.4f}')\n",
    "print(f'Finished Training in {(time.time()-tic)//60:.0f}m {(time.time()-tic)%60:.0f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the RNN on the 10000 test images: 96.83 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = rnn(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the RNN on the 10000 test images: {acc} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gated Recurrent Unit (GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes) -> None:\n",
    "        super(GRU, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first = True)\n",
    "        # batch_first = True means, batch size is the first dimension\n",
    "        # Would mean x --> (batch_size, seq, input_size)\n",
    "        # input_size is the feature size\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, num_classes) # Last cell unit output\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        # Dimensions (number of layers, batch_size, hidden_size)\n",
    "        # Reason - Each layer would have a different hidden state of size (batch_size, hidden_size)\n",
    "\n",
    "        out, _ = self.gru(x, h0) # Returns output and hidden state of EACH cell\n",
    "        # out dimenions: (batch_size, sequence_length, hidden_size)\n",
    "        # out: (N, 28, 128)\n",
    "        out = out[:,-1,:] # Since we only want the output of the last cell\n",
    "        out = self.fc(out)\n",
    "        return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = GRU(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(gru.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "GRU                                      [128, 10]                 --\n",
       "├─GRU: 1-1                               [128, 28, 128]            258,816\n",
       "├─Linear: 1-2                            [128, 10]                 1,290\n",
       "==========================================================================================\n",
       "Total params: 260,106\n",
       "Trainable params: 260,106\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 927.76\n",
       "==========================================================================================\n",
       "Input size (MB): 0.40\n",
       "Forward/backward pass size (MB): 3.68\n",
       "Params size (MB): 1.04\n",
       "Estimated Total Size (MB): 5.12\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(gru, (batch_size, sequence_length, input_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8; Loss: 0.1865\n",
      "Epoch 2/8; Loss: 0.1154\n",
      "Epoch 3/8; Loss: 0.0415\n",
      "Epoch 4/8; Loss: 0.0533\n",
      "Epoch 5/8; Loss: 0.0067\n",
      "Epoch 6/8; Loss: 0.0139\n",
      "Epoch 7/8; Loss: 0.0018\n",
      "Epoch 8/8; Loss: 0.0255\n",
      "Finished Training in 4m 7s\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # original shape: [batch_size, 1, 28, 28]\n",
    "        # Resize: [batch_size, 28, 28]\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = gru(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}; Loss: {loss.item():.4f}')\n",
    "print(f'Finished Training in {(time.time()-tic)//60:.0f}m {(time.time()-tic)%60:.0f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the GRU on the 10000 test images: 98.72 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = gru(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the GRU on the 10000 test images: {acc} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Short-Term Memory (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes) -> None:\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first = True)\n",
    "        # batch_first = True means, batch size is the first dimension\n",
    "        # Would mean x --> (batch_size, seq, input_size)\n",
    "        # input_size is the feature size\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, num_classes) # Last cell unit output\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) # Initial hidden state\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) # Initial cell state\n",
    "        # Dimensions (number of layers, batch_size, hidden_size)\n",
    "        # Reason - Each layer would have a different hidden state of size (batch_size, hidden_size)\n",
    "\n",
    "        out, _ = self.lstm(x, (h0, c0)) # Returns output, (hidden state, cell_state) of EACH cell\n",
    "        # out dimenions: (batch_size, sequence_length, hidden_size)\n",
    "        # out: (N, 28, 128)\n",
    "        out = out[:,-1,:] # Since we only want the output of the last cell\n",
    "        out = self.fc(out)\n",
    "        return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTM(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "LSTM                                     [128, 10]                 --\n",
       "├─LSTM: 1-1                              [128, 28, 128]            345,088\n",
       "├─Linear: 1-2                            [128, 10]                 1,290\n",
       "==========================================================================================\n",
       "Total params: 346,378\n",
       "Trainable params: 346,378\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 1.24\n",
       "==========================================================================================\n",
       "Input size (MB): 0.40\n",
       "Forward/backward pass size (MB): 3.68\n",
       "Params size (MB): 1.39\n",
       "Estimated Total Size (MB): 5.47\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(lstm, (batch_size, sequence_length, input_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8; Loss: 0.1399\n",
      "Epoch 2/8; Loss: 0.0913\n",
      "Epoch 3/8; Loss: 0.0936\n",
      "Epoch 4/8; Loss: 0.0567\n",
      "Epoch 5/8; Loss: 0.0114\n",
      "Epoch 6/8; Loss: 0.0388\n",
      "Epoch 7/8; Loss: 0.0673\n",
      "Epoch 8/8; Loss: 0.0296\n",
      "Finished Training in 5m 9s\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # original shape: [batch_size, 1, 28, 28]\n",
    "        # Resize: [batch_size, 28, 28]\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = lstm(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}; Loss: {loss.item():.4f}')\n",
    "print(f'Finished Training in {(time.time()-tic)//60:.0f}m {(time.time()-tic)%60:.0f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the LSTM on the 10000 test images: 98.66 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = lstm(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the LSTM on the 10000 test images: {acc} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "193f6b5c64d175a70f8bc370a8e28557b54eddf9787b8dde324aa4d68183bc16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torchaudio\n",
    "Advantages over other audio libraries -\n",
    "- Feature extraction happens in GPU, hence it is very much more **efficient**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0.dev20221003\n",
      "0.13.0.dev20221003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/venkatakrishnanvk/miniforge3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading and Saving Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_DIR = '../datasets/audio_datasets'\n",
    "\n",
    "SAMPLE_WAV_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/steam-train-whistle-daniel_simon.wav\"\n",
    "SAMPLE_WAV_PATH = os.path.join(SAMPLE_DIR, \"steam.wav\")\n",
    "SAMPLE_MP3_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/steam-train-whistle-daniel_simon.mp3\"\n",
    "SAMPLE_MP3_PATH = os.path.join(SAMPLE_DIR, \"steam.mp3\")\n",
    "SAMPLE_WAV_SPEECH_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/source-16k/train/sp0307/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042.wav\"\n",
    "SAMPLE_WAV_SPEECH_PATH = os.path.join(SAMPLE_DIR, \"speech.wav\")\n",
    "SAMPLE_NOISE_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/distant-16k/distractors/rm1/babb/Lab41-SRI-VOiCES-rm1-babb-mc01-stu-clo.wav\"\n",
    "SAMPLE_NOISE_PATH = os.path.join(SAMPLE_DIR, \"bg.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(SAMPLE_DIR, exist_ok=True) # Create SAMPLE_DIR folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_audio_file(url, path):\n",
    "  with open(path, 'wb') as file_:\n",
    "    file_.write(requests.get(url).content) \n",
    "    # Will send http request to the urlwrite and download the files and store them locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What does `fetch_audio_file` do?\n",
    "- Sends http request to the url\n",
    "- Downloads and writes the audio files in the path specified\n",
    "- Stores them locally in the given path/folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_audio_file(SAMPLE_WAV_URL, SAMPLE_WAV_PATH)\n",
    "fetch_audio_file(SAMPLE_MP3_URL, SAMPLE_MP3_PATH)\n",
    "fetch_audio_file(SAMPLE_WAV_SPEECH_URL, SAMPLE_WAV_SPEECH_PATH)\n",
    "fetch_audio_file(SAMPLE_NOISE_URL, SAMPLE_NOISE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata collection\n",
    "#### From downloaded path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AudioMetaData(sample_rate=44100, num_frames=109368, num_channels=2, bits_per_sample=16, encoding=PCM_S)\n"
     ]
    }
   ],
   "source": [
    "metadata = torchaudio.info(SAMPLE_WAV_PATH)\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From raw file itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 8192 bytes\n",
      "AudioMetaData(sample_rate=44100, num_frames=109368, num_channels=2, bits_per_sample=16, encoding=PCM_S)\n"
     ]
    }
   ],
   "source": [
    "# Quering audio metadata directly from url\n",
    "with requests.get(SAMPLE_WAV_URL, stream = True) as response:\n",
    "    filedata = response.raw\n",
    "    metadata = torchaudio.info(filedata, format = \"wav\")\n",
    "    print(f'Fetched {filedata.tell()} bytes')\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Audio Files\n",
    "By default -\n",
    "- `dtype = torch.float32`\n",
    "- Range is **normalised** within [-1.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 54400]), 16000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform, sample_rate = torchaudio.load(SAMPLE_WAV_SPEECH_PATH) # Speech audio\n",
    "# x, fs is returned\n",
    "waveform.shape, sample_rate # PyTorch tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1**: Number of channels\n",
    "\n",
    "**54400**: Number of frames/samples\n",
    "\n",
    "**16000**: Sample rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "193f6b5c64d175a70f8bc370a8e28557b54eddf9787b8dde324aa4d68183bc16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
